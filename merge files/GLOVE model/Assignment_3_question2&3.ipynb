{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from IPython.display import display\n",
    "pd.set_option('display.max_rows',5)\n",
    "pd.set_option('precision',3)\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:100% !important;}</style>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_df(file_name):\n",
    "    #print(file_name)\n",
    "    with open(file_name, encoding='utf-8', errors='ignore') as f:\n",
    "        json_1 = json.load(f)\n",
    "    dict_1 = dict(json_1)\n",
    "    df_1 = pd.DataFrame.from_dict(dict_1)\n",
    "    return df_1\n",
    "def create_padded_docs(t,doc,max_length = 500):\n",
    "    encoded_docs = t.texts_to_sequences(doc)\n",
    "    #print(encoded_docs)\n",
    "    padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "    #print(padded_docs)\n",
    "    return padded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Could you catch us up on your latest thinking ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>We continue to ramp up the activities for the ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>98</td>\n",
       "      <td>And so it's -- that one is a little bit toughe...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>99</td>\n",
       "      <td>Thanks, Simeon. Rob, next question please?</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1644 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                               text sentiment    Id\n",
       "0        1  Could you catch us up on your latest thinking ...   neutral     0\n",
       "1       10  We continue to ramp up the activities for the ...   neutral     1\n",
       "...    ...                                                ...       ...   ...\n",
       "1642    98  And so it's -- that one is a little bit toughe...  positive  1642\n",
       "1643    99         Thanks, Simeon. Rob, next question please?   neutral  1643\n",
       "\n",
       "[1644 rows x 4 columns]"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_df['Id']=all_data_df.index\n",
    "all_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'all_group_data.pickle'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(all_data_df,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neutral' 'negative' 'positive']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Could you catch us up on your latest thinking ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>We continue to ramp up the activities for the ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>And so it's -- that one is a little bit toughe...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Thanks, Simeon. Rob, next question please?</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1644 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text sentiment\n",
       "1   Could you catch us up on your latest thinking ...   neutral\n",
       "10  We continue to ramp up the activities for the ...   neutral\n",
       "..                                                ...       ...\n",
       "98  And so it's -- that one is a little bit toughe...  positive\n",
       "99         Thanks, Simeon. Rob, next question please?   neutral\n",
       "\n",
       "[1644 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neutral' 'negative' 'positive']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "      <th>text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Yes, it was sort of just how the conversation ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Well, it's still kind of early introduction, r...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Yes, Simeon. I still remain -- feel good about...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>And so it's -- that one is a little bit toughe...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>809 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text sentiment  label  \\\n",
       "100  Yes, it was sort of just how the conversation ...  negative      0   \n",
       "110  Well, it's still kind of early introduction, r...  positive      1   \n",
       "..                                                 ...       ...    ...   \n",
       "96   Yes, Simeon. I still remain -- feel good about...  positive      1   \n",
       "98   And so it's -- that one is a little bit toughe...  positive      1   \n",
       "\n",
       "     text_len  \n",
       "100       310  \n",
       "110       320  \n",
       "..        ...  \n",
       "96        256  \n",
       "98        224  \n",
       "\n",
       "[809 rows x 4 columns]"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data=[]\n",
    "for file in os.listdir():\n",
    "    if file.startswith(\"Team\") and file.endswith(\".json\"):\n",
    "        df=json_to_df(file)\n",
    "        df.columns=['text','sentiment']\n",
    "        df['sentiment']=df['sentiment'].apply(lambda x: x.lower())\n",
    "        if sum(df.isnull().any(axis=1))>0:\n",
    "            print(file)\n",
    "            display(df[pd.isnull(df['Sentiment'])])\n",
    "        else:\n",
    "            all_data.append(df)\n",
    "all_data_df=pd.concat(all_data)\n",
    "all_data_df['sentiment']=all_data_df['sentiment'].apply(lambda x: 'neutral' if x in ['neutra;','negetive','neural'] else x)\n",
    "all_data_df['sentiment']=all_data_df['sentiment'].apply(lambda x: 'positive' if x in ['postive','positivem'] else x)\n",
    "print(all_data_df['sentiment'].unique())\n",
    "display(all_data_df)\n",
    "all_data_df_2type=all_data_df[all_data_df['sentiment'].isin(['positive','negative'])].copy()\n",
    "all_data_df=all_data_df.reset_index()\n",
    "all_data_df_2type_neu=all_data_df[~all_data_df['sentiment'].isin(['positive','negative'])].copy()\n",
    "all_data_df_2type['label']=all_data_df_2type['sentiment'].apply(lambda x: 1 if x=='positive' else 0)\n",
    "all_data_df_2type['text_len']=all_data_df_2type['text'].apply(lambda x: len(x))\n",
    "all_data_df_2type_pos=all_data_df_2type[all_data_df_2type['sentiment']=='positive'].copy()\n",
    "all_data_df_2type_neg=all_data_df_2type[all_data_df_2type['sentiment']=='negative'].copy()\n",
    "print(all_data_df['sentiment'].unique())\n",
    "all_data_df_2type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      98.000\n",
       "mean      534.459\n",
       "           ...   \n",
       "75%       652.250\n",
       "max      1181.000\n",
       "Name: text_len, Length: 8, dtype: float64"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_df_2type['text_len'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 100   |   vector length: 12\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_133 (Embedding)    (None, 100, 12)           62532     \n",
      "_________________________________________________________________\n",
      "flatten_133 (Flatten)        (None, 1200)              0         \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (None, 1)                 1201      \n",
      "=================================================================\n",
      "Total params: 63,733\n",
      "Trainable params: 63,733\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "647/647 [==============================] - 3s 5ms/step - loss: 0.6150 - acc: 0.7790\n",
      "Epoch 2/50\n",
      "647/647 [==============================] - 0s 94us/step - loss: 0.4998 - acc: 0.8083\n",
      "Epoch 3/50\n",
      "647/647 [==============================] - 0s 95us/step - loss: 0.4640 - acc: 0.8083\n",
      "Epoch 4/50\n",
      "647/647 [==============================] - 0s 93us/step - loss: 0.4403 - acc: 0.8083\n",
      "Epoch 5/50\n",
      "647/647 [==============================] - 0s 95us/step - loss: 0.4172 - acc: 0.8083\n",
      "Epoch 6/50\n",
      "647/647 [==============================] - 0s 94us/step - loss: 0.3940 - acc: 0.8083\n",
      "Epoch 7/50\n",
      "647/647 [==============================] - 0s 92us/step - loss: 0.3677 - acc: 0.8099\n",
      "Epoch 8/50\n",
      "647/647 [==============================] - 0s 91us/step - loss: 0.3405 - acc: 0.8145\n",
      "Epoch 9/50\n",
      "647/647 [==============================] - 0s 99us/step - loss: 0.3103 - acc: 0.8362\n",
      "Epoch 10/50\n",
      "647/647 [==============================] - 0s 96us/step - loss: 0.2806 - acc: 0.8532\n",
      "Epoch 11/50\n",
      "647/647 [==============================] - 0s 96us/step - loss: 0.2503 - acc: 0.8856\n",
      "Epoch 12/50\n",
      "647/647 [==============================] - 0s 105us/step - loss: 0.2208 - acc: 0.9134\n",
      "Epoch 13/50\n",
      "647/647 [==============================] - 0s 101us/step - loss: 0.1916 - acc: 0.9413\n",
      "Epoch 14/50\n",
      "647/647 [==============================] - 0s 90us/step - loss: 0.1666 - acc: 0.9505\n",
      "Epoch 15/50\n",
      "647/647 [==============================] - 0s 92us/step - loss: 0.1416 - acc: 0.9722\n",
      "Epoch 16/50\n",
      "647/647 [==============================] - 0s 99us/step - loss: 0.1192 - acc: 0.9845\n",
      "Epoch 17/50\n",
      "647/647 [==============================] - 0s 101us/step - loss: 0.1002 - acc: 0.9907\n",
      "Epoch 18/50\n",
      "647/647 [==============================] - 0s 103us/step - loss: 0.0839 - acc: 0.9923\n",
      "Epoch 19/50\n",
      "647/647 [==============================] - 0s 110us/step - loss: 0.0697 - acc: 0.9923\n",
      "Epoch 20/50\n",
      "647/647 [==============================] - 0s 98us/step - loss: 0.0576 - acc: 0.9923\n",
      "Epoch 21/50\n",
      "647/647 [==============================] - 0s 97us/step - loss: 0.0475 - acc: 0.9954\n",
      "Epoch 22/50\n",
      "647/647 [==============================] - 0s 99us/step - loss: 0.0393 - acc: 0.9954\n",
      "Epoch 23/50\n",
      "647/647 [==============================] - 0s 83us/step - loss: 0.0331 - acc: 0.9954\n",
      "Epoch 24/50\n",
      "647/647 [==============================] - 0s 87us/step - loss: 0.0272 - acc: 0.9969\n",
      "Epoch 25/50\n",
      "647/647 [==============================] - 0s 83us/step - loss: 0.0230 - acc: 0.9969\n",
      "Epoch 26/50\n",
      "647/647 [==============================] - 0s 90us/step - loss: 0.0193 - acc: 0.9969\n",
      "Epoch 27/50\n",
      "647/647 [==============================] - 0s 98us/step - loss: 0.0163 - acc: 0.9969\n",
      "Epoch 28/50\n",
      "647/647 [==============================] - 0s 102us/step - loss: 0.0136 - acc: 0.9969\n",
      "Epoch 29/50\n",
      "647/647 [==============================] - 0s 103us/step - loss: 0.0123 - acc: 0.9969\n",
      "Epoch 30/50\n",
      "647/647 [==============================] - 0s 105us/step - loss: 0.0108 - acc: 0.9969\n",
      "Epoch 31/50\n",
      "647/647 [==============================] - 0s 100us/step - loss: 0.0092 - acc: 0.9969\n",
      "Epoch 32/50\n",
      "647/647 [==============================] - 0s 89us/step - loss: 0.0085 - acc: 0.9969\n",
      "Epoch 33/50\n",
      "647/647 [==============================] - 0s 90us/step - loss: 0.0072 - acc: 0.9969\n",
      "Epoch 34/50\n",
      "647/647 [==============================] - 0s 84us/step - loss: 0.0069 - acc: 0.9969\n",
      "Epoch 35/50\n",
      "647/647 [==============================] - 0s 91us/step - loss: 0.0060 - acc: 0.9969\n",
      "Epoch 36/50\n",
      "647/647 [==============================] - 0s 89us/step - loss: 0.0057 - acc: 0.9969\n",
      "Epoch 37/50\n",
      "647/647 [==============================] - 0s 95us/step - loss: 0.0052 - acc: 0.9985\n",
      "Epoch 38/50\n",
      "647/647 [==============================] - 0s 98us/step - loss: 0.0043 - acc: 0.9985\n",
      "Epoch 39/50\n",
      "647/647 [==============================] - 0s 96us/step - loss: 0.0041 - acc: 0.9985\n",
      "Epoch 40/50\n",
      "647/647 [==============================] - 0s 97us/step - loss: 0.0038 - acc: 0.9985\n",
      "Epoch 41/50\n",
      "647/647 [==============================] - 0s 101us/step - loss: 0.0036 - acc: 0.9985\n",
      "Epoch 42/50\n",
      "647/647 [==============================] - 0s 97us/step - loss: 0.0035 - acc: 0.9985\n",
      "Epoch 43/50\n",
      "647/647 [==============================] - 0s 98us/step - loss: 0.0030 - acc: 0.9985\n",
      "Epoch 44/50\n",
      "647/647 [==============================] - 0s 96us/step - loss: 0.0029 - acc: 0.9985\n",
      "Epoch 45/50\n",
      "647/647 [==============================] - 0s 95us/step - loss: 0.0025 - acc: 0.9985\n",
      "Epoch 46/50\n",
      "647/647 [==============================] - 0s 103us/step - loss: 0.0024 - acc: 0.9985\n",
      "Epoch 47/50\n",
      "647/647 [==============================] - 0s 98us/step - loss: 0.0024 - acc: 0.9985\n",
      "Epoch 48/50\n",
      "647/647 [==============================] - 0s 96us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "647/647 [==============================] - 0s 91us/step - loss: 0.0020 - acc: 0.9985\n",
      "Epoch 50/50\n",
      "647/647 [==============================] - 0s 94us/step - loss: 0.0017 - acc: 1.0000\n",
      "Training Accuracy: 100.000000\n",
      "Testing Accuracy: 81.481481\n",
      "******************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(all_data_df_2type_pos[['text']], all_data_df_2type_pos[['label']], test_size=0.2, random_state=42)\n",
    "X_train_n, X_test_n, y_train_n, y_test_n = train_test_split(all_data_df_2type_neg[['text']], all_data_df_2type_neg[['label']], test_size=0.2, random_state=42)\n",
    "#display(X_train_p, X_test_p, y_train_p, y_test_p)\n",
    "#display(X_train_n, X_test_n, y_train_n, y_test_n)\n",
    "X_train=X_train_p.append(X_train_n).copy().reset_index(drop=True)\n",
    "X_test=X_test_p.append(X_test_n).copy().reset_index(drop=True)\n",
    "y_train=y_train_p.append(y_train_n).copy().reset_index(drop=True)\n",
    "y_test=y_test_p.append(y_test_n).copy().reset_index(drop=True)\n",
    "\n",
    "docs = all_data_df_2type['text'].tolist()\n",
    "max_words = 10000 \n",
    "t = Tokenizer(um_words=max_words)\n",
    "t.fit_on_texts(docs)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "for vector_len in [12]:\n",
    "    for m_len in [100]:\n",
    "        print(\"max length: \"+str(m_len)+\"   |   vector length: \"+str(vector_len))\n",
    "        x_train_doc=create_padded_docs(t,X_train['text'].tolist(),m_len)\n",
    "        x_test_doc=create_padded_docs(t,X_test['text'].tolist(),m_len)\n",
    "        y_train_label=y_train['label'].tolist()\n",
    "        y_test_label=y_test['label'].tolist()\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(vocab_size, vector_len, input_length=m_len))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        # compile the model\n",
    "        model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "        # summarize the model\n",
    "        print(model.summary())\n",
    "        # fit the model\n",
    "        model.fit(x_train_doc, y_train_label, epochs=50)#,validation_split=0.1)\n",
    "        # evaluate the model\n",
    "        loss, accuracy = model.evaluate(x_train_doc, y_train_label, verbose=0)\n",
    "        print('Training Accuracy: %f' % (accuracy*100))\n",
    "        y_train_label_predicted=model.predict(x_train_doc)\n",
    "        y_test_label_predicted=model.predict(x_test_doc)\n",
    "        y_train_label_predicted=[1 if y>=0.5 else 0 for y in y_train_label_predicted]\n",
    "        y_test_label_predicted=[1 if y>=0.5 else 0 for y in y_test_label_predicted]\n",
    "        loss, accuracy = model.evaluate(x_test_doc, y_test_label, verbose=0)\n",
    "        print('Testing Accuracy: %f' % (accuracy*100))\n",
    "        print('***'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_neg</th>\n",
       "      <th>predicted_pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_neg</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_pos</th>\n",
       "      <td>0</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          predicted_neg  predicted_pos\n",
       "                                      \n",
       "true_neg              1             30\n",
       "true_pos              0            131"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_neg</th>\n",
       "      <th>predicted_pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_neg</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_pos</th>\n",
       "      <td>0</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          predicted_neg  predicted_pos\n",
       "                                      \n",
       "true_neg              1             30\n",
       "true_pos              0            131"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_columns=['predicted_neg','predicted_pos']\n",
    "confusion_rows=['true_neg','true_pos']\n",
    "train_confusion_matrix=pd.DataFrame(confusion_matrix(y_test_label, y_test_label_predicted))\n",
    "train_confusion_matrix.columns=confusion_columns\n",
    "train_confusion_matrix['index']=confusion_rows\n",
    "train_confusion_matrix=train_confusion_matrix.set_index('index')\n",
    "train_confusion_matrix.index.name=''\n",
    "\n",
    "test_confusion_matrix=pd.DataFrame(confusion_matrix(y_test_label, y_test_label_predicted))\n",
    "test_confusion_matrix.columns=confusion_columns\n",
    "test_confusion_matrix['index']=confusion_rows\n",
    "test_confusion_matrix=test_confusion_matrix.set_index('index')\n",
    "test_confusion_matrix.index.name=''\n",
    "\n",
    "display(train_confusion_matrix)\n",
    "display(test_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "imdb_dir = 'aclImdb'\n",
    "def load_imdb_dir(imdb_dir,sub_folder):\n",
    "    train_dir = os.path.join(imdb_dir,sub_folder)\n",
    "    labels = []\n",
    "    texts = []\n",
    "    for label_type in ['neg', 'pos']:\n",
    "        dir_name = os.path.join(train_dir, label_type)\n",
    "        for fname in os.listdir(dir_name):\n",
    "            if fname[-4:] == '.txt':\n",
    "                f = open(os.path.join(dir_name, fname))\n",
    "                texts.append(f.read())\n",
    "                f.close()\n",
    "                if label_type == 'neg':\n",
    "                    labels.append(0)\n",
    "                else:\n",
    "                    labels.append(1)\n",
    "    return texts,labels\n",
    "x_train_imdb_raw,y_train_imdb_raw=load_imdb_dir(imdb_dir,\"train\")\n",
    "x_test_imdb_raw,y_test_imdb_raw=load_imdb_dir(imdb_dir,\"test\")\n",
    "\n",
    "\n",
    "x_train_imdb_raw_tot=x_train_imdb_raw+x_test_imdb_raw\n",
    "y_train_imdb_raw_tot=y_train_imdb_raw+y_test_imdb_raw\n",
    "\n",
    "max_words = 10000 \n",
    "docs = all_data_df_2type['text'].tolist()+x_train_imdb_raw_tot\n",
    "t = Tokenizer(num_words=max_words)\n",
    "t.fit_on_texts(docs)\n",
    "vocab_size = len(t.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 100   |   vector length: 12\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_144 (Embedding)    (None, 100, 12)           1492164   \n",
      "_________________________________________________________________\n",
      "flatten_144 (Flatten)        (None, 1200)              0         \n",
      "_________________________________________________________________\n",
      "dense_144 (Dense)            (None, 1)                 1201      \n",
      "=================================================================\n",
      "Total params: 1,493,365\n",
      "Trainable params: 1,493,365\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "45000/45000 [==============================] - 23s 519us/step - loss: 0.4630 - acc: 0.7714 - val_loss: 0.3638 - val_acc: 0.8390\n",
      "Epoch 2/5\n",
      "45000/45000 [==============================] - 20s 445us/step - loss: 0.2850 - acc: 0.8818 - val_loss: 0.3492 - val_acc: 0.8452\n",
      "Epoch 3/5\n",
      "45000/45000 [==============================] - 20s 440us/step - loss: 0.2495 - acc: 0.8988 - val_loss: 0.3622 - val_acc: 0.8412\n",
      "Epoch 4/5\n",
      "45000/45000 [==============================] - 19s 429us/step - loss: 0.2244 - acc: 0.9108 - val_loss: 0.2806 - val_acc: 0.8820\n",
      "Epoch 5/5\n",
      "45000/45000 [==============================] - 19s 433us/step - loss: 0.2001 - acc: 0.9226 - val_loss: 0.3303 - val_acc: 0.8640\n",
      "Training Accuracy: 93.006000\n",
      "Testing Accuracy: 62.244898\n",
      "******************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for vector_len in [12]:\n",
    "    for m_len in [100]:\n",
    "        print(\"max length: \"+str(m_len)+\"   |   vector length: \"+str(vector_len))\n",
    "        x_train_doc=create_padded_docs(t,x_train_imdb_raw_tot,m_len)\n",
    "        x_test_doc=create_padded_docs(t,all_data_df_2type['text'].tolist(),m_len)\n",
    "        y_train_label=y_train_imdb_raw_tot\n",
    "        y_test_label=all_data_df_2type['label'].tolist()\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(vocab_size, vector_len, input_length=m_len))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        # compile the model\n",
    "        model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "        # summarize the model\n",
    "        print(model.summary())\n",
    "        # fit the model\n",
    "        model.fit(x_train_doc, y_train_label, epochs=5,validation_split=0.1)\n",
    "        # evaluate the model\n",
    "        loss, accuracy = model.evaluate(x_train_doc, y_train_label, verbose=0)\n",
    "        print('Training Accuracy: %f' % (accuracy*100))\n",
    "        y_train_label_predicted=model.predict(x_train_doc)\n",
    "        y_test_label_predicted=model.predict(x_test_doc)\n",
    "        y_train_label_predicted=[1 if y>=0.5 else 0 for y in y_train_label_predicted]\n",
    "        y_test_label_predicted=[1 if y>=0.5 else 0 for y in y_test_label_predicted]\n",
    "        loss, accuracy = model.evaluate(x_test_doc, y_test_label, verbose=0)\n",
    "        print('Testing Accuracy: %f' % (accuracy*100))\n",
    "        print('***'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lovelife/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "all_data_df_2type['y_predicted']=y_test_label_predicted\n",
    "all_data_df_2type['label_predicted']=all_data_df_2type['y_predicted'].apply(lambda x: 'positive' if x==1 else \"negative\")\n",
    "all_data_df_2type_neu['label_predicted']='neutral'\n",
    "all_data_df_2type=all_data_df_2type.drop('y_predicted',axis=1)\n",
    "ge_df=all_data_df_2type.append(all_data_df_2type_neu)\n",
    "ge_df.to_json('GE_predicted.json',orient='split')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"text\":{\"1\":\"Good day, ladies and gentlemen and welcome to the General Electric Fourth Quarter 2018 Earnings Conference Call. At this time, all participants are in a listen-only mode. My name is Brandon and I\\'ll be your conference facilitator today. [Operator Instructions] As a reminder, this conference is being recorded\",\"10\":\"For the industrial portfolio in total, we will provide you with our outlook for organic growth and we\\'ll do so directionally on operating margins and free cash flow. We will give you a more detailed outlook in the near term but not today. For Power, we are resetting the baseline. We are reviewing every single project and contract and digging deeper to understand costs and benefits with respect to restructuring, market and commercial execution, improvement opportunities, legacy project issues and our service operations. We\\'re gaining more meaningful insights into the paths for near and long-term earnings and cash potential of this business. This work takes time especially with the new structure and leadership team.\",\"101\":\"Well, Jeff what I was referring to there was that, it\\'s really the statutory calculation not the GAAP that drives the statutory funding needs. We are right in the middle of that process. We continue to expect to contribute about $2 billion to the insurance entities in 2019. We\\'ll conclude that process over the next three to four weeks. But at this point that is what we expect.\",\"102\":\"Sorry about that Jeff.\",\"106\":\"Sure, sure. Let me do that and again this is very much a work in progress with a new team establishing new operating rhythms. But I would say that if we start on the service side of things, right? We\\'ve got a $62 billion backlog. We did take the charge in the fourth quarter $400 million on about a $3.7 billion contract asset book and we think that\\'s appropriate just given what we see in the marketplace. I think we\\'re encouraged though relative to the execution around pricing here. We have changed the way the folks in the field are compensated.\",\"107\":\"Transitioning them, if you will from volume to margin. But again, there\\'s a good bit of productivity post Alstom that we still need to get from the combined organizations here and that work is incomplete. But that\\'s part of that operating loss that you see here at year\\'s end. We are clearly dealing with lower demand in equipment, encouraged by some of the share points in the US market here in the back half. But again, we want to make sure we focused on profitable share. There we took $350 million of charges around the project book and we know that we have a lot of execution here to improve just in the way these projects are brought online.\",\"108\":\"I think when you look at the vintages, we\\'re encouraged by the progress that we see post the \\'16 underwriting class in terms of our margins on those projects. But that\\'s very much a work in progress. I think with respect to the change in the structure of Power, again part of it is a cost reduction. We shared some of that in the prepared remarks but we also are getting better visibility on the underlying businesses P&L-by-P&L. So we talk about gas, we\\'re combining services and equipment then we have the rest of our Power portfolio.\",\"109\":\"As Jamie mentioned, we now take on all the cost for grid now that we own all of it that doesn\\'t help us at all. But now we\\'ve got better line of sight on the discreet P&L\\'s grid, Steam, Power Conversion and Nuclear all four of those businesses have meaningful profit improvement potential and we\\'re going to manage them from the bottoms up accordingly. So clearly, we\\'re at a break even from our P&L perspective absence some other charges, a lot of work to do here and as we have better visibility and more conviction around those improvements, we\\'ll be back and we\\'ll be back here soon with respect to how that plays out in \\'19 and \\'20.\",\"11\":\"In the spirit of providing you with all the information we have as soon as we have it, I\\'ll speak to what I have found over the last 120 days. We were executing against the key priorities we laid out in June and again in October. Simply put deleveraging the balance sheet and strengthening our businesses starting with Power. Remember beyond Power, it\\'s important to recognize the underlying strengths in our businesses where the story is about enhancing our competitive advantage and delivering for customers and shareholders.\",\"110\":\"The other color I would just add there on negative free cash flow is as volume comes down in the factories and as our projects continue to work their way through, you see volume leveling but we\\'ve been in a declining frame here. So what\\'s really flowing through on cash in addition to some of the other items Larry mentioned is a burn down of our progress billings and a burn down of our project payables. Situations where we receive projects in advance of constructing new equipment or where we received progress on projects and now we\\'re in the phase of the project, where the payables and the costs are starting to come through. So that\\'s also pressuring the Power of free cash flow. And as that levels that also starts to level.\",\"112\":\"With respect to Aviation\\'s merger and mix you saw strong fourth quarter and when we look at the remixing that\\'s happening between CFM and LEAP significant increase in LEAP shipments in the quarter up 88% over the prior year. Year-over-year 2.4x up and you\\'re seeing CFM come down meaningfully over those same periods. Next year, CFM will come down again about I\\'d say more than 50% of CFM deliveries will be reduced next year but the LEAP also ramps from the 1,118 we had this year up to 1,800-plus. So that remixing continues to occur. We mentioned on the call that it was a drag in 2018 of 160 basis points. We do expect continued some small drag next year but again Aviation\\'s doing a really nice job offsetting that with services growth. They\\'re shifting in military and the company-funded R&D.\",\"117\":\"And Larry I don\\'t buy that you\\'re going to have a prom date. That\\'s nonsense. Even I had a prom date. I was bald at birth. All kidding aside, the one number you gave that was new, which was kind of eye-popping to me, it was just $1.6 billion Power headquarter number. Can you put some context around that? It seems just like such a insane number. But I don\\'t know really what you\\'re including in that I guess as far as talking about headquarter?\",\"118\":\"Well, there\\'s -- it\\'s a large number and again, I think we\\'ve got line of sight here in the near terms Scott to bring that down by about 300. And effectively, as you know, we\\'ve done a lot horizontally both at corporate and at the segment levels over time for the businesses. So it\\'s not as if it\\'s unhelpful or wasteful but there clearly is an adjustment we can take here as we move those activities into the businesses and I think over time as the businesses have true ownership for them that they are in their operating budgets as opposed to an allocation from corporate. They\\'re likely to find opportunities for further savings. But we don\\'t do it primarily for the cost reduction. I think we really do it to help drive visibility and accountability P&L-by-P&L. I think I\\'ve shared with some folks that early on in my tenure we would talk about Power as if it was one business. It\\'s obviously a number of businesses. Some better than others, different issues here and there. I think we\\'ve got better visibility on those issues. It\\'s not perfect today but as we get that visibility I think better position to take meaningful action to drive better results across that portfolio.\",\"119\":\"That make sense. And then the other thing is just not totally clear is, if the New World is 25 gigawatts to 30 gigawatts, which arguably a lot of people can say the New World is 25 or even a little lower but how do you get your capacity down anywhere close to that? I mean you\\'ve got big factories, lots of capital equipment, lot of pressure from governments and unions and everybody else. Is it realistic to be able to get that down in the next two years? it\\'s something that\\'s closer to 30?\",\"12\":\"With respect to delevering, we\\'ve taken the following actions: We\\'ve reduced the quarterly dividend retaining $4 billion per year; accelerated the sale of a portion of our BHGE ownership stake raising $3.7 billion; and changed the structure of our transaction with Wabtec enabling us to retain an incremental $2 billion stake. We\\'re demonstrating our seriousness and the flexibility with respect to our decisions to recut the BHGE and Wabtec deals in particular. We closed Distributed Power for $2.8 billion of net cash in the quarter.\",\"120\":\"Well, I think it is realistic, right? There are going to be a number of competing priorities and pressures but we took $1 billion of cost out last year. I think we are putting the -- we\\'re putting up the parameters of a program to build on what we did last year. So Scott, we have to do this. We absolutely have to do this. I think we know, it\\'s a multiyear effort but the challenge here around margins is not simply one of capacity. Right back to the earlier question around pricing. Productivity both in new equipment and in the field on services. It\\'s a whole host of things that I think give us the optimism that we can drive better margin and cash performance in this business. But we have to prove that to you.\",\"123\":\"I don\\'t think I would ever say, even on my last day here that we have found all the skeletons, right? I don\\'t tend to take absolute positions. But that said I think you\\'re spot on. The news today around WMC is good both with respect to a resolution and the fact that we came in right where we were reserved. So we can begin to move that episode behind us. I think we\\'re encouraged by the results that Jamie walked you through relative to the LRT.\",\"124\":\"But again, the cash requirements really come from the stat and not the GAAP test and that will still has a few more weeks to run. But in the absence of no new news again with a lot of fresh eyes and it\\'s not my fresh eyes we\\'ve got a new GC, we\\'ve got a new controller new to GE in their first years. I think that is a positive sign that we aren\\'t adding to the list. We\\'re going to be as open and transparent as we possibly can, when we find things. And we\\'re going to help you understand what we\\'re doing to address them but I\\'m encouraged by what I see and what has not arisen here in nearly four months time.\",\"125\":\"And Larry, you\\'re pretty clear about having no plans to sell GECAS. It sounds quite definitive but obviously there\\'s a lot of noise out there. So maybe I could step back and ask you how you weigh the urgency to get GE Capital debt down versus keeping the strong earnings stream in tact from GECAS that you have in the business?\",\"126\":\"Well, I think that we\\'re -- we\\'re frankly keen not to comment on every rumor on every innuendo that\\'s out there. GECAS is one business that we get inbounds on with some frequency. But frankly. We get inbounds on everything but my desk. I think it speaks to the quality of the assets. Again, I think we can delever and bring that net debt down from $55 billion to something closer to $25 billion. We\\'ve got a number of options. We are mindful of the trades when we move assets out and the impact on our earnings and cash capability. But again, you elevate to the strategic level, I think we are clear. We need to delever and we\\'re going to work the plan that we\\'ve outlined here today and that\\'s really is I think as simple and as straightforward as it gets.\",\"13\":\"For the year, we signed or completed substantially all of our $20 billion industrial asset sale plan, which had targeted roughly $10 billion in proceeds. We also announced the sale of ServiceMax in the fourth quarter. We completed $8 billion of capital asset sales and other actions in the quarter bringing our total for the year to $15 billion, which were executed at book value or better. We\\'re more than halfway through the total of $25 billion capital asset sale program, which we expect to complete this year.\",\"130\":\"So as we mentioned before, we had adjustments for utilization, some on pricing pressure and then just our standard cost updates. On the utilization side, when you look at the CSA book, utilization has been relatively flat and it\\'s demonstrating actually a fairly healthy profile. And I think it just continues to support the base that gas continues to be an important source of energy generation. Now some geographies are impacted more by some of the renewables adoptions. And as you look at our book, our concentration of geographies isn\\'t largely in those areas but we did see some true-ups that we took in places like California and Turkey just to make sure we were reflecting our best view on that.\",\"131\":\"On the pricing pressure, we are seeing that in some contracts. These are high margin long term contracts. And when we do go through renegotiation process on some of these, we are often able to offset that pricing with scope expansion and cost productivity. Having said that we wanted to make sure we had a realistic view of how we saw the portfolio, when we went through these reviews. We always do standard cost updating in our portfolio, that\\'s just like you do in manufacturing. Those standard cost roll through this quarter as well. And part of that also reflected a small impact from the stage one blade issue but that\\'s something that we had expected would happen, there as well.\",\"14\":\"Today, we have announced that we\\'ve reached an agreement in principle with the United States Department of Justice to settle the FIRREA investigation of WMC. GE will pay the United States a civil penalty of $1.5 billion consistent with our reserve recorded for this matter in the first quarter of last year. We\\'ve taken the following actions to strengthen our businesses.\",\"147\":\"Well, Dean again, I think we\\'re sharing today what we can in terms of not only the fourth quarter but the actions that are under way and how we see 2019 shaping up. We know we\\'re not answering every question that folks might have on their minds today. But we\\'re not going to answer any question without a grounding and a level of conviction that we expect of ourselves and I think folks like yourselves and investors expect of us as well but we are indicating that we\\'ll be back soon with more particularly as we work through some of the issues, we\\'ve talked about not only in our\",\"149\":\"Well, Dean, again I want to make sure everybody understands that the LRT results here are a positive data point. I think that the stat test is going to be more important and I think we don\\'t expect any major surprises but we\\'ll have those results to share with you in a few weeks. This is a long term liability right? And we have our commitments with respect to the permitted practice. We\\'re in a position to fulfill those. We certainly get inbounds here as well from folks, who\\'d like to take this book off of our hands. But not necessarily in a structure and at a value that would make sense for the GE shareholder. So I suspect that as we enhance our disclosures, they\\'ll be better understanding of what this is.\",\"15\":\"In 2018, our corporate headquarters cost was $1.2 billion down $400 million from $1.6 billion in 2017. We have begun transferring a significant portion of headcount and activities that were previously managed at corporate to the segments or to third parties with over 6,500 full-time employees transferred to-date. We\\'re confident that as we move more activity and headcount closer to those that are directly accountable, we will see additional savings.\",\"150\":\"Certainly I suspect there will still be some debate. But I\\'m optimistic that the transparency will lead to better understanding and we can talk about this in a fact-based way. People can understand what that means. Is it with us forever? Or is there a way to ring fence it is to use your word again, I\\'m not going to rule anything out. But I think right now, what we\\'re trying to do is to make sure that everyone understands, what it is and what our obligations are around the insurance book. So hopefully, some helpful disclosures in that regard today with more to come in the K once we\\'re on the other side of the stat test.\",\"151\":\"And from Gordon Haskett, we have John Inch. Please go ahead.\",\"157\":\"Well, with respect to GE Capital\\'s 2019 as Larry mentioned, we\\'re not offering 2019 guidance today. So that\\'s something that we will be sharing with you in the near term but not today. And with respect to Healthcare\\'s free cash flow, I think it\\'s well understood that that is a strong cash flow business. It\\'s a flow business unlike some of our long cycle and I think there\\'s been a lot of valuation maps that\\'s been out there. So while we\\'re not disclosing Healthcare\\'s free cash flow, I think you can probably come to a pretty reasonable conclusion there about what that is.\",\"158\":\"Okay. I think we were targeting break even in capital this year and we ended up losing money. I\\'m just wondering, what is -- what actually changed in the mix from Jamie, when you originally thought would be break even to the loss? And also in your cash walk on the fourth quarter cash walk, the Baker Hughes free cash flow is a positive $800 million. It looks like Baker actually generated positive free cash flow in the fourth quarter. So why would that be a positive? Why isn\\'t that a negative drawing it out, it\\'s just a technical question, I guess.\",\"159\":\"Well, first on GE Capital. We had the LRT results in the fourth quarter so that was $65 million. We actually had tax benefits of less than we expected as well. That impacted us by about $240 million. And then we had some other marks in the portfolio in the second half. So that was really the large difference between what we had expected and where we ended up. And then with respect to Baker Hughes. We are backing out free cash flow. So that might be a labeling issue on the slide there. It\\'s less Baker Hughes free cash flow. If you back it out and you have the dividend.\",\"16\":\"Good examples include the recently announced agreement with Genpact around our global operations activities and the delayering and reorganization of our Global Growth Organization. Our changes in Power followed a similar approach. We have $1.6 billion of cost at Power headquarters and expect to produce that amount by $300 million for headquarter\\'s overhead functions. And as we distribute the remaining cost to the business units, we expect that they will find additional savings over time.\",\"160\":\"Well, first on GE Capital. We had the LRT results in the fourth quarter so that was $65 million. We actually had tax benefits of less than we expected as well. That impacted us by about $240 million. And then we had some other marks in the portfolio in the second half. So that was really the large difference between what we had expected and where we ended up. And then with respect to Baker Hughes. We are backing out free cash flow. So that might be a labeling issue on the slide there. It\\'s less Baker Hughes free cash flow. If you back it out and you have the dividend.\",\"166\":\"I think we\\'re at a place, where we\\'re sharing with you today everything that we know, everything we can commit to. And again, we\\'ll be back with more detail particularly with respect to Power and cash soon. But we\\'re just, we\\'re not in a position where we\\'re able to do that. But clearly, again, hopefully the color around the $2.7 billion that we burned last year is helpful. With respect to framing the magnitude of the task and the challenge, when we understand and are serious about addressing.\",\"168\":\"Yes. Well the -- when we talk about the cost for the blade issue, it\\'s really a function of going out and effectively replacing these blades sooner than we were anticipating, right? Because the useful life is effectively shorter than we had anticipated unfortunately. But we think we understand that. That work is under way with respect to the installed base. And again, I think it\\'s regrettable. I think our customers when you talk to them understand, what\\'s happened how we\\'re going about remediating the issue in the field and I\\'d like to think that that is not something, we\\'re going to continue to site with respect to the margin pressure in the business here in \\'19.\",\"169\":\"Yeah. And just walking back from third quarter and maybe updating today. So third quarter, we had $240 million of warranty and other accruals related to the stage one blade. We also mentioned that that we expected to experience a similar amount of that over time as the worked outperformed in our services book. So part of what I mentioned earlier on those charges includes that stage one blade issue started to come through the services updates.\",\"17\":\"We announced this week that we will be delayering the headquarter levels at Renewable Energy. And yesterday announced that we are bringing GE\\'s grid, solar and storage assets into that business creating an end-to-end offering from renewables customers as the demand for renewable power generation and grid integration continues to grow globally. We\\'re strengthening our senior team. We\\'ve brought in fresh eyes that are already having an impact.\",\"170\":\"Yeah. And just walking back from third quarter and maybe updating today. So third quarter, we had $240 million of warranty and other accruals related to the stage one blade. We also mentioned that that we expected to experience a similar amount of that over time as the worked outperformed in our services book. So part of what I mentioned earlier on those charges includes that stage one blade issue started to come through the services updates.\",\"171\":\"But there are host of elements of that\",\"174\":\"Yeah. It\\'s a very small issue in the quarter. But it\\'s just part of that that bleed off as we do the work.\",\"18\":\"We\\'re combining new perspectives from strong external talent, proven GE leaders with domain expertise and entrepreneurial spirit, next-gen thinkers as well as leaders with deep customer relationships. From a governance perspective, Paula Reynolds joined our Board of Directors bringing extensive experience in both the Energy and Insurance industries. The majority of our Directors now are new since 2017 and I\\'m finding the Board deeply engaged in all matters of our business\",\"180\":\"Nothing that we can reference this morning.\",\"183\":\"Now as Larry mentioned earlier on the call, we\\'re not yet seeing all of that drop through primarily because of field execution issues and operational issues. But these are things that we believe are fixable. And over time as we really seek to increase our share in that book, it really capture the kind of work that we want to capture the higher margin work, the operational execution piece of that we think should flow through. But with the respect to the margin pressure generally, I should say pricing pressure, these are very competitive markets that have a lot of capacity. So I think that dynamic will continue as we go through the next couple of years and until the market levels out and until we see the capacity leveling out as well.\",\"19\":\"Our audit committee also announced that they will move forward with the tender process for the appointment of GE\\'s independent audit firm. And finally, we announced our plan to combine the digital businesses into an independently operated IoT Software business with employee equity a separate Board and the ability to raise capital and operate like a start-up. We\\'re on the precipice of something great. We\\'re getting a 100 years of domain and hardware expertise and growing out of our digital DNA over the last several decades.\",\"23\":\"Take quality. When I ask about quality internally, I often hear about our cost of quality, which measures our issues rather than how the customer experiences us. We\\'re shifting our perspectives so that we understand and measure ourselves the way customers do and work backwards from there. The third area is having fewer and more impactful priorities. GE has ambition like no other company I\\'ve ever seen and that\\'s mostly a good thing but we need to focus our attention to more of the things that matter most, so we can move them the furthest.\",\"24\":\"At a company level, we\\'ve committed to the two priorities I mentioned earlier: Deleveraging the balance sheet and strengthening the businesses starting with Power. I\\'d now like to address some of the areas of importance that are high on my priority list. First, our high-level financial results. We ended the year with adjusted EPS of $0.65. GAAP EPS of negative $2.43 and industrial free cash flow of $4.5 billion. Our backlog stands at $391 billion up 5% year-on-year with equipment at $89 billion up 4%; and service at $302 billion up 5%.\",\"25\":\"For the fourth quarter, our industrial free cash flow was $4.9 billion. While cash flow was negatively impacted by the weakness in Power, we were encouraged by the strong cash generation in the other businesses. We delivered adjusted EPS of $0.17 and GAAP EPS of $0.08. Jamie will take you through all this in more detail in a moment.\",\"26\":\"Next to the balance sheet. As I\\'ve stated already, we are reducing our debt levels both at Industrial and GE Capital. We know full well that our shareholders own all debt obligations across GE but these are two distinct sets of businesses with different financing needs and different capital structures and therefore we analyze their leverage separately. In industrial, we are targeting a net debt-to-EBITDA ratio of less than 2.5x over the next few years.\",\"28\":\"Overall our liquidity position remains strong with $16.8 billion of industrial cash and funding lines of $40 billion. Now on capital, we are targeting a debt-to-equity ratio of less than 4x by 2020. In 2018, we paid down capital\\'s external debt balance by $21 billion and we executed $15 billion in asset sales at book more than half of our $25 billion asset disposition program. Capital ended the year with a $124 billion of assets including $15 billion of liquidity in line with our goal to materially shrink this business.\",\"30\":\"First as I said, last quarter we were late to embrace the realities of the secular and cyclical pressures in the business. Recent data suggests that the market for new generating capacity is settling in to the 25 to 30 gigawatts range for the foreseeable future. We continue to believe gas will play an important role in global electrification but we have to resize our cost structure, our capital expenses and our supply chains to this new reality now.\",\"32\":\"Over the next few years, these effects should come down substantially. Third, we need to execute better. Running Power better means improved daily management in how we sell make and service our products. Let me give you a few examples. We had separate teams of managers commissioning new plants owning a warranty period and overseeing the services contracts after the warranty.\",\"33\":\"Now, we present one face to the customer, who is accountable for the best long-term economic answer both for the customer and GE. We put the sales organization under one leader with deep domain expertise and are coordinating better on contract negotiations. We now have more experienced people, owning negotiations and responsible for project cost. We performed risk assessments of our existing 400 equipment contracts to identify cost and execution risks. We also performed a similar assessment on the 750 CSA contracts to identify price and utilization risk.\",\"34\":\"We have overhauled our commercial underwriting processes to set more realistic commitments and returns from the start. This is hard work but I\\'m encouraged by the Power\\'s team\\'s dedication to proactively address these issues at their root cause. Fixing Power will take time and in turn will take time for the changes, we\\'re making to our daily operations to be reflected in our financial results but we are improving and I\\'m confident that those changes will come.\",\"35\":\"As I\\'ve met with customers around the world, I\\'m really been struck by their sentiment. They\\'re rooting for us. They want us to succeed and they want to know how they can help. So in summary, we\\'re taking action, taking action on the priorities we laid out to you, deleveraging our balance sheet and strengthening our businesses starting with Power.\",\"37\":\"Thanks. Larry. I\\'ll start with the fourth quarter summary. Orders were $34.1 billion down 1% reported and up 4% organically with particular strength in equipment orders up 7% organically driven by aviation commercial engines and renewables. The services orders were up 1% organically. Revenues were up 5%, industrial segment revenues were up 2% reported and 8% organically driven by renewables Aviation Oil & Gas Healthcare and Transportation.\",\"38\":\"Equipment revenues grew 10% and services were up 6% organically. Industrial profit margins were 7.5% in the quarter down 150 basis points year-over-year on a reported and organic basis driven by significant declines in Power and Renewables. For the year, margins were down 80 basis points organically. Industrial profit was down 16% in the quarter with Aviation, Healthcare and Baker Hughes GE all delivering strong profit growth offset mostly by Power. Specifically Aviation had another outstanding quarter and year expanding total year margins while shipping over 1,100 LEAP engines. Net earnings per share was $0.07, which includes losses from discontinued operations related to GE Capital. GAAP continuing EPS was $0.08 and adjusted EPS was $0.17.\",\"40\":\"Lastly, we realized a $0.01 negative impact from US tax reform as we updated our estimate of the transition tax and other aspects of the enactment of the new law. Our current accrual reflects the effects of tax reform enactment based on guidance issued through year-end. Excluding these items adjusted EPS was $0.17 in the quarter.\",\"41\":\"Moving to cash, adjusted industrial free cash flow was $4.9 billion for the quarter, $1.9 billion lower than the prior year driven primarily by a lower progress collections. Income depreciation and amortization totaled $2.3 billion. Working capital was positive $2.3 billion for the quarter as we reduced over $1 billion of inventory on a higher fourth quarter volume and grew progress collections by $500 million primarily in renewables from strong PTC-driven orders.\",\"44\":\"Earlier in the year, we assumed $6 billion of debt from GE Capital to fund the principal pension plan, which was completed in the third quarter. Alstom and GE exercised their JV redemption rights and call options, which we settled for $3.1 billion in the fourth quarter. These entities operate at a loss. So the consolidation of 100% of the financials negatively impacted fourth quarter and will be an income headwind for us of about $300 million in 2019. We also completed a secondary offering for approximately 100 million Baker Hughes GE shares as well as a direct stock buyback with Baker Hughes GE for 65 million shares bringing our ownership stake to 50.4% in the fourth quarter.\",\"45\":\"These actions combined with other Baker Hughes GE buybacks during the year totaled $4.4 billion in cash proceeds. The $2.5 billion of other cash includes a number of items including about $900 million of investments in our Aviation business primarily from the first half of the year; $900 million of short data derivative hedge settlements that we used to mitigate risks across the portfolio; and $400 million of FX translation on our non-US dollar-denominated cash. Running with a higher cash balance will help us address inter-quarter funding needs. In line with our goal to reduce reliance on short-term funding, peak short-term funding needs declined from $19.7 billion in the fourth quarter of \\'17 to $14.8 billion in the fourth quarter of \\'18. These were funded with commercial paper and some utilization of our credit facilities.\",\"46\":\"As we execute dispositions in 2019, we expect our intra-quarter funding needs to continue to decline and would expect to use a mix of commercial paper, credit facilities and excess cash at GE Capital to efficiently fund these needs. At the end of the year, commercial paper outstanding was $3 billion and we had access to $40 billion of committed revolving credit facilities with zero drawn. These lines are available to draw at any time and they don\\'t have financial covenants ratings triggers or material adverse change clauses. As you know, our credit rating was downgraded from A to BBB+ with a stable outlook in early fourth quarter.\",\"48\":\"Now, I\\'ll take you through financial policy and leverage. We remain committed to our financial policy of a target single A rating a leverage level of less than 2.5x net debt-to-EBITDA and ultimately a dividend level in line with our peers. Deleveraging both GE and GE Capital is a priority and we have significant sources to achieve our goals.\",\"49\":\"As Larry mentioned, we view these businesses differently with different balance sheets and capital structure needs and therefore we analyze their leverage separately. Our goal is leverage for the GE industrial businesses of less than 2.5x net debt-to-EBITDA. We plan to make significant progress toward this goal by the end of 2020 and as a reminder when we speak about net debt, we\\'re talking about debt adjusted for pensions, operating leases and a portion of preferred stock and cash. Measured on this basis, GE Industrial net debt at the end of 2018 was $55 billion. As we look out over the next couple of years, we expect to have roughly $50 billion of industrial sources that can be used to delever and derisk the company.\",\"51\":\"At GE Capital, we have a plan to reduce our debt to equity ratio to less than 4x by the end of 2020. GE Capital began the quarter with $70 billion of debt and ended with $66 billion while our total assets measure $124 billion. For the year, we made significant progress at GE Capital paying down $21 billion of external debt, taking down leverage by 1.4 turns including reducing commercial paper from $5 billion to zero.\",\"52\":\"GE Capital ended 2018 with $15 billion of liquidity. Over the next two years, we expect to generate additional sources of cash from asset sales, including $10 billion in 2019 from completing our GE Capital $25 billion asset reduction plan. We\\'ll have cash from the pay down of most of the debt transferred to GE and capital support from GE. We have reached an agreement in principle on WMC that we expect to conclude expeditiously. And in 2019 and 2020, GE Capital will pay down $25 billion of scheduled debt maturities and continue to contribute about $2 billion per year of capital to our insurance businesses as previously disclosed. We now don\\'t expect to issue new debt until 2021.\",\"53\":\"We are planning approximately $4 billion of capital contributions to GE Capital in 2019. This includes $1.5 billion for the WMC agreement in principal announced today and ensuring we have adequate risk-based capital levels for our current portfolio. Going forward, we anticipate funding any insurance capital requirements or strategic options through a combination of GE Capital earnings, asset sales, liquidity and GE parent support. While we have more work to do, we continue to make progress in strengthening the balance sheet.\",\"54\":\"Next on Power. Orders were down 19% in the quarter. Gas Power Systems orders were down 26%. For the year, Gas Power Systems orders were down 40%. We ended the year with a $9 billion backlog, which was down 8% year-over-year. This is consistent with our outlook for a 25 to 30 gigawatt market for the foreseeable future. Power Services orders were down 20%. Steam orders were up 61% and grid orders were down 13% for the year. Power revenue was down 25%. Gas Power Systems revenues were down 21%. Power Services revenue was also down 21%. During the quarter, we took $400 million of charges related to our CSA contracts, which impacts revenue. Excluding these charges Power Services revenue was down 11%. Steam revenue was down 30% on lower America\\'s and Europe volume and grid was flat.\",\"55\":\"Moving to profit. The segment loss $872 million in the fourth quarter. We performed our normal CSA reviews and while total utilization on the book is flat, we have seen lower utilization on some of our units in some geographies and some pricing pressure in contracts relative to ongoing market dynamics and we updated our assumptions to reflect a revised outlook in these areas.\",\"56\":\"In addition, we had our normal cost standard updates, which included updates to our cost standards including the impact of the stage-one blade issue as expected. This resulted in the $400 million of charges that I previously mentioned. In addition, we also incurred about $350 million of costs related to Gas Power Systems projects. Similar to the third quarter, we continue to experience project execution issues resulting in liquidated damages as well as partner execution issues. Grid profit was down year-over-year impacted negatively by the buyout of the Alstom share of the JV.\",\"57\":\"These items had a significant impact on Power\\'s results and overall, we see the heavy duty gas turbine market is flat over the next few years and see significant opportunity to improve our own execution. Next on Aviation, which had another great quarter. Orders of $8.8 billion were up 12%. Equipment orders grew 20%, driven by continued strong momentum of the LEAP engine program up 56% versus prior year. Military engine orders were up 69% driven by the F414 and service orders grew 7%. Revenues of $8.5 billion grew 21%. Equipment revenues were up 13% on higher commercial engine partially offset by lower military volume.\",\"58\":\"Specifically, we shipped 379 LEAP engines this quarter up 177 units year-over-year. And in total, we shipped 1,118 LEAP engines for the year. We\\'re still behind on deliveries by about four weeks but the business expects to be back on schedule by mid-2019. Services revenue grew 26% with spares rate up 10% driven by higher fleet utilization and spare parts consumption from strong air traffic. Segment profit of $1.7 billion was up 24% on higher volumes, improved price and operating productivity and compared to the fourth quarter of last year, we shipped almost 90% more LEAP engines.\",\"59\":\"Despite the negative mix from higher LEAP shipments operating profit margins of 20.4% expanded 60 basis points in the quarter and 130 basis points for the year. The LEAP engine continues to perform very well with a 58% win rate on the A320neo family and 81% win rate in the narrow-body segment when you add in Boeing 737 MAX and Comac C919. Utilization rates are over 95%. We continue to improve the cost position of the LEAP and over the last two years, we\\'ve taken out more than 40% of the cost of the engine and are ahead on the learning curve initially laid out for the program. The overall program will break even around 2021.\",\"60\":\"Now, I\\'ll provide some additional transparency on the engine transition in the narrow-body market. The mixing from CFM56 to LEAP resulted in a margin drag of approximately 160 basis points in 2018 and 130 basis points in the quarter. The business is successfully offsetting this margin pressure through continued growth in aftermarket services, military and changing the mix of company-funded R&D spend. In summary, another strong year for David and the aviation team. In renewables, renewables orders were up 19% versus prior year driven by onshore equipment up 9% and services up 32% on strong repower units.\",\"61\":\"We shipped 44% more megawatts and onshore wind and saw strong orders bookings 3 gigawatts in the fourth quarter and 8.6 gigawatts for the year and we gained share. Revenues of $3.4 billion were up 28% mainly driven by onshore wind up 34% on both higher new unit shipments and repowering volume. Segment margin of 2% was down 330 basis points for the quarter and profit of $67 million was down 51% mainly driven by negative price, liquidated damages for execution delays on a handful of complicated projects including some legacy Alstom projects and higher losses in hydro and offshore as we began fully consolidating these entities in the fourth quarter.\",\"62\":\"The consolidation presented a headwind of about 220 basis points. Recall that we had to book loss reserves at the time of the Alstom deal and we continue to burn through the negative cash flow impact of those projects. The business has seen favorable cash tailwinds from the PTC cycle, pricing is improving and we continue to see strong product cost reduction and while we\\'re seeing some adverse impacts from tariffs, we\\'re working to mitigate them with pricing and supply chain actions.\",\"63\":\"For Healthcare, orders of $5.8 billion were up 2% organically. On a product line basis, Life Sciences orders were up 13% organically with bioprocess up 20%. Healthcare Systems orders were down 1% organically, which was about what we expected as we were comping a very strong fourth quarter in 2017.\",\"64\":\"Revenue of $5.4 billion was up 6% organically. Healthcare Systems revenue grew 4% organically and Life Sciences was up 10%. Segment margin was 21.8% expanding 10 basis points reported and 110 basis points organically, which excluded costs incurred in preparation for a separation in 2019. Profit was $1.2 billion up 2% on a reported basis and 12% organically. Organic profit growth was driven by volume and cost productivity partially offset by inflation, price and higher program investment. As the Healthcare team continues to prepare for separation, they closed out a solid year.\",\"66\":\"Last week, we also announced amended transaction terms to further support our deleveraging plan. GE will increase its stake in Wabtec from approximately 10% to approximately 25% resulting in increased cash proceeds of approximately $2.2 billion as we sell down our stake. We will still receive $2.9 billion in cash from Wabtec at closing and both transactions are expected to close in early 2019 subject to customary closing conditions.\",\"67\":\"Finally, I\\'ll cover GE Capital. Net loss from continuing operations was $86 million in the quarter, including a tax reform adjustment of negative $128 million. Adjusted continuing net income was $43 million. We completed our annual GAAP loss recognition testing in our runoff insurance portfolio, which resulted in an after-tax charge of about $65 million to increase reserves.\",\"7\":\"First, I\\'d like to start by welcoming Steve to the GE team. I\\'ve known him for over a decade. Steve\\'s already had positive impact here at GE and I\\'m sure, he\\'ll do the same for you, our investors going forward. I\\'m here today because I believe in GE. There is no company on earth with a scale of GE\\'s global reach, brand, talent and long-term customer relationships. We have leading technology in key infrastructure markets with high barriers to entry and strong aftermarket streams. We\\'re poised to capture recurring revenues on a global installed base of almost 70,000 engines more than 70 -- 7,000 gas turbines and aero-derivatives, more than 40,000 onshore wind turbines and more than 4 million Healthcare Systems. In short, GE matters. We\\'ve identified clear opportunities to improve our performance and we are working to address them at root cause.\",\"71\":\"Jamie, thank you. So hopefully, by now you have a better sense of what I\\'m seeing at GE after nearly four months, our strengths, our challenges and our strategy for moving forward. I\\'d like to give you all the information and views on 2019 that we have today with more to come soon. We expect industrial organic revenue growth to be up low to mid-single digits on the back of a significant ramp in renewables and continued strength in Aviation and Healthcare.\",\"72\":\"Power will be down in a flat to slightly down market in 2019. We also expect our industrial operating margins to expand. On free cash flow, we expect to face operating headwinds such as the PTC progress cycle reversing in renewables and we will spend more cash on restructuring at both Corporate and Power. In addition, we have a number of nonrecurring investments and commitments that create a drag on our free cash flow in 2019 but which will meaningfully lessen in 2020 and \\'21. These include transitioning to GE Capital supply chain financing program to MUFG and reducing factoring with GE Capital, Alstom pension contributions and legal settlements and the costs related to the preparation for our Healthcare business for our public separation.\",\"73\":\"We anticipate cash flow to grow substantially in 2020 and 2021 as we make significant headway in addressing legacy and structural issues while simultaneously realizing the benefits from restructuring and stronger daily management of our businesses particularly in Power. In aviation, we see 75% to 80% of the 2019 commercial engine revenues secured in the backlog, with a largely recurring service revenue stream of approximately $15 billion. We are maintaining margin levels consistent with pre-LEAP periods despite mix changes with a healthy new order book. With these in mind, we see high single-digit revenue growth and low single-digit profit growth.\",\"74\":\"In Healthcare, we expect organic growth in margins in a similar range to last year. We see double-digit revenue growth in renewables. The business is coming through the PTC cycle and onshore wind, which contributed to strong cash performance in 2018, as a result of progress build. That progress cycle will begin reversing this year, as we transition to factory production and book revenue against those contracts. However, we see price declines moderating and within the level of our product cost reduction efforts going forward. This is our baseline today for 2019 as our plan continues to evolve. As we develop more conviction around the cash flow situation of Power, we will update you in the near term with respect to the outlook for the full year.\",\"75\":\"So my message for 2019 is that the more stable businesses of Aviation and Healthcare are healthy and growing. Renewables is moving through the PTC cycle. We are working on Power and capital is shrinking. 2019 is still very much a work in progress but the company is becoming stronger. As I said earlier, the how much is important here, but the how is far more fundamental. How is about understanding and fixing problems at root cause. How is about process not for processes sake but to ensure the sustainability of our results to create enduring shareholder value. I\\'m proud of the momentum, I see across this company and the changes we\\'re making to strengthen GE for the long run.\",\"8\":\"We have the right portfolio of strategy and I\\'m confident the company is capable of gaining profitable share and creating long-term value for our shareholders. So let me cover where we stand on providing an outlook. Then I\\'ll address some of the company changes followed by updates on our results, the balance sheet, capital and power. Jamie will take you through more details on the quarter and then I\\'ll wrap with some metrics and comments to help you frame the outlook for 2019 before Q&A.\",\"81\":\"Well, I think we\\'ve talked about that separation as the plan of record and that continues to be the case today. The team is very well along Nigel with respect to the preparation for a flotation. We don\\'t have a time frame per se to share with you today but we are spending a significant amount of money in \\'19 as we did last year in preparation. We\\'re obviously proud of what Karyn and the team are doing here. Very strong top line earnings and cash performance and we think this is a business that is going to be a strong resilient performer through cycles. So that is the plan.\",\"82\":\"Okay. And then my follow-on would be, you gave a lot of detail on what you\\'ve been doing for the last few months and lots of opportunities for improvement. One thing, you didn\\'t really touch on was pricing and pricing excellence and your one precedent of GE in the past has been may be trading price for market share. So I\\'m just curious, what your thoughts are in terms of improving the pricing realization going forward?\",\"83\":\"Nigel, forgive us, if we didn\\'t get into that in detail. We didn\\'t want to overstay our welcome with respect to our prepared remarks. But when you hear us refer to profitable market share that is both an external and internal recognition. And it can\\'t be share for share sake. And particularly in Power, I think we are acutely aware that we have opportunities both on new equipment and on the service book to basically value sell what we\\'re doing more frequently. I got the word last night for example within Power of a project that is looking very good where we\\'re frankly -- we are not the low bid, right? I think that just speaks to the way we\\'re able to communicate the value of our technology. We know in these businesses from Healthcare to renewables price is a reality. We want to be smarter around pricing, at the same time, frankly when you hear us talk about labor and material productivity, we really want to push that hard and do that in line with market realities, so that we can maintain margins in light of some of those pressures.\",\"84\":\"And Nigel, just to add a little bit more color there on the numbers. Orders pricing in total for the year was relatively flat. It was actually up just slightly and it was up more than that in the second half. And as Larry mentioned, we are seeing in the numbers the pressure moderating at Power and at renewables. Power really with respect to the enhanced discipline on new projects and bids as Larry talked about. In renewables, we\\'re seeing that pressure moderate as we move throughout the year as well primarily as we\\'re moving through that PTC cycle. The supply chains are more stretched and that price dynamic becomes a little bit more unbalanced. Aviation and Healthcare are running as you would expect, which is strongly as Larry mentioned.\",\"87\":\"Yes. So why don\\'t I talk through the components of 2018 first in terms of really walking you through the rounding out our fourth quarter performance and we can address some of those questions. So for 2018, if you really walk the changes, we obviously had earnings. We also had working capital, which for the year was basically zero impact of free cash flow. Fourth quarter was $2.3 billion positive. As we expected with large volumes coming through this quarter. Contract assets was basically flat.\",\"88\":\"Hey, sorry. I can see the slide. I just wanted to know like $4.5 billion. Is that -- there\\'s a lot of headwinds that Larry had talked about. I\\'m just curious as to maybe you can give us some color on the size of some of those headwinds? And obviously, it sounds like it will be down. Will you as an organization generate cash including GE Capital next year? I guess that\\'s the simple way to ask the question.\",\"9\":\"Let\\'s start with the outlook because investors want to know how we expect to perform financially and you should expect to come from a place of reality. Simply put the how much is important but the how is far more fundamental. We have a good line of sight in most of our businesses today including Aviation and Healthcare.\",\"90\":\"Clearly renewables was stronger from a cash perspective in \\'18 and is likely to be in \\'19 given the PTC dynamic. And we are going to go deep here on additional restructuring where we see opportunities to put that money to work and generate real returns. We also have some of these nonrecurring events or issues. Some of them are policy decisions like the move on the supply chain financing program. I think we\\'ve got better line of sight today on some of these legacy issues that come out of Alstom that we\\'re on the hook or those are real cash commitments in \\'19 that abate thereafter and we do have the cost relative in Healthcare IPO.\",\"91\":\"So again, I think the headline is, we finished strongly. We know we got some operating and non-operating pressures and think we work through that in \\'19 with an eye toward a stronger cash flow performance in \\'20 and \\'21 with more details to come soon.\",\"98\":\"Well Steve, I\\'d like to think that everything that we do is shareholder-friendly, right? I mean, we take a strong view here and you know, from seeing me in other roles that we want to create long-term shareholder value with the cumulative effect of everything that we do. I think with respect to Healthcare what we can confirm today is that we\\'re on the path toward an IPO here in 2019. Timing is still TBD. So we don\\'t have a date. Like me on my senior prom. I just don\\'t have a date for you today but I think in time, we\\'ll have more clarity.\",\"99\":\"With respect to Baker Hughes, I mean we talked about that as part of that $50 billion pool of options to go to. I think that the high probability there is for us is to sell our shares. We certainly are approached by various folks, who have an interest in a stake in that company. And again, we don\\'t have a timetable per se to share with you today but we want to reiterate our view to dispose of that stake in an orderly manner, which again we think is conducive to value creation for our shareholders.\",\"100\":\"Thanks. And just as a follow-up. I didn\\'t have a prom date and I\\'ve been called worse than Steve but as unrelated follow-up, if we think about what you\\'re going through in insurance right now, the comment about the statutory review. Is that to indicate Larry or Jamie that even if there is some adverse outcome as it relates to that statutory review, it would not affect your near-term funding needs and instead those would be tacked onto the tail, so to speak of what you\\'re planning from reserve build?\",\"103\":\"Thanks.\",\"104\":\"From Barclays, we have Julian Mitchell.\",\"105\":\"Morning. Maybe as the first question on Power. I understand, you\\'re reticent to give too much forward-looking color but perhaps give us a sense of, if you look at the reported 2018 numbers EBIT loss of $800 million free cash of minus $2.7 billion. How would you look at the or characterize to us the underlying figures for both of those two items, if you strip out charges and projects execution overruns and so on? And maybe also on that point, if you could give any color as to the separation of gas and non-gas within Power? What sort of financial conditions that separation has uncovered in each of the two pieces?\",\"111\":\"Thanks. And then my second question may be about a business, where there\\'s better medium term visibility Aviation. You talked about the LEAP operating margin headwind last year. How do you see that moving in 2019 relative to that 160 bps? And then looking out beyond just this year anything on the horizon in terms of let\\'s say 777X transition or NMA that you think could cause a major risk to the aviation free cash flow in margin profile?\",\"113\":\"We\\'re clearly in conversations with our major airframe customers about new platforms. I think at this point, it would be premature to suggest that we\\'re going to have a cash flow headwind a material cash flow headwind around any of those programs here in \\'19.\",\"114\":\"From Melius Research, we have Scott Davis. Please go ahead.\",\"115\":\"Hey. Good morning, guys.\",\"116\":\"Good morning, Scott.\",\"121\":\"And from Citi, we have Andrew Kaplowitz. Please go ahead.\",\"122\":\"Hey. Good morning, guys. Larry, one of the biggest issues I think that investors have had when GE is the concern that legacy liabilities will continue to surprise the company. The FIRREA agreement with the DOJ seems like a positive development in that regard, so does is the relatively small LTC adjustment. But at this point, do you feel reasonably confident that you\\'ve identified all the skeletons in the closet in a level of negative surprises are really going to start dropping moving forward?\",\"127\":\"From Bank of America Merrill Lynch, we have Andrew Obin. Please go ahead.\",\"128\":\"Hi, good morning. Just a question. You mentioned that you took $400 million of contract asset writedown in Power. And my understanding is that sort of culturally is a big deal. Shall we see more of these writedowns? How far along are we in the process of evaluating the book there?\",\"129\":\"We asked our new controller, when he started to take a clean look at everything across the company. And they -- as they went through their normal standards CSA reviewed this quarter did pay particular attention to higher risk contracts, just to make sure that we were thinking about them cleanly and the right way. What we talked about on the call, which was really comprised of three different buckets were the results of that review.\",\"132\":\"Got you. And just on GE Capital. How much incremental capital? You said $4 billion in \\'19 but how much incremental, do you need to put in 2020 to achieve your leverage targets? Thank you.\",\"133\":\"Yeah. So Andrew at this point, we\\'re talking about 2019, which is the $4 billion. And as we said as we get beyond 2019, we obviously understand. We will continue to put capital or expect to continue to put capital into the insurance subsidiaries. That will be funded through a combination of GE Capital earnings asset sales liquidity and GE parents support but at this point, we\\'re not prepared to talk more fully about that.\",\"134\":\"From Deutsche Bank, we have Nicole DeBlase. Please go ahead.\",\"135\":\"So, good morning. So I just want to start on Power kind of a two part question. You reduced headcount by 15%, you reduced footprint by 30%. I know that pricing is an important part of the equation of getting back to profitability here but I guess maybe what inning are you in with respect to what you need to do to get to the right level of capacity utilization? And then same topic different question. What exactly are you doing to improve Power execution since that keeps coming up as a driver of weaker profitability and when might we stop talking about that piece of the margin headwinds?\",\"136\":\"Well, Nicole I would say, we are in the very early innings relative to the turnaround at Power. I don\\'t know, how else to frame it. Again, a new team, a new structure, new operating rhythms. When we talk about execution, we talk about daily management. What I\\'m really referring to is making sure that every day the folks in the field, the folks in the factories, the folks in the labs understand what the key operating metrics are that they are responsible for that feed into better margins both at the growth in the operating level in this business. So that takes time because it\\'s not just a reporting exercise, right? It\\'s a management exercise and making sure they not understand not only how they\\'re being measured but how to go about actually getting better price, how to go about actually driving better material productivity. Execution in the field as well. Not only around cost but frankly more importantly around quality making sure we get into outages quickly and we solve issues for customers the first time and when we\\'re not going back. Those are the source of things. And it is a big organization. It\\'s a global organization. This is going to take a little while. But I\\'m optimistic that we\\'ll see it in our operating metrics over time and that will in turn translate into better performance. We\\'ll clearly get some lift sooner from the absence of the adjustments that we made at the end of the year but what I\\'m really focused on and what I think investors are to be focused on, are those underlying operating improvements.\",\"138\":\"Okay, got it. That\\'s helpful. Thanks, Larry. And just a really quick one to tie up. Good progress on corporate expense reduction this quarter. Would you say that the corporate expense that we saw in 4Q is indicative of the run rate for 2019? Or are there items there that we need to consider?\",\"139\":\"I\\'d say it\\'s roughly indicative. I think it\\'ll be down slightly from that. It was a little bit higher in the quarter due to some onetime expenses we had but it\\'s close. Little bit down from that in 2019.\",\"140\":\"From RBC Capital Markets, we have Deane Dray. Please go ahead.\",\"141\":\"From RBC Capital Markets, we have Deane Dray. Please go ahead.\",\"142\":\"Thank you. Good morning, everyone.\",\"143\":\"Hey, Dean. Good morning.\",\"144\":\"I\\'d also like to add our welcome to Steve Winoker and wish him all the best.\",\"145\":\"Thanks, Dean.\",\"146\":\"Looks like I have to burn one of my questions, what\\'s more of a housekeeping question Larry is in the third quarter earnings you talked about plans for an Analyst meeting in early 2019. Looks like, there\\'s still a lot of more specifics that have to get filled in in terms of guidance and especially on the cash flow side. Maybe you\\'re not ready yet to host that meeting. But just where does that stand and what would the timing be?\",\"148\":\"Okay. And Larry, I appreciate how you started off the call with all the changes in terms of the management approach and the accountability and voice of the customer. I mean that\\'s --that was all good color to hear upfront. And then my second question is on the insurance side. We\\'ve got good news, what I see is good news on the loss recognition certainly not a new surprise. How does that change? In the third quarter, there was lots of calls for how to ring fence the long term insurance risk and where that might be. Where does that stand today in terms of priorities?\",\"152\":\"Good morning, everybody. Good morning, Larry.\",\"153\":\"Hey, John. Good morning.\",\"154\":\"Hi, Steve.\",\"155\":\"Good morning, John.\",\"156\":\"Good morning, Steve. Just on the capital guide. I may have missed this Jamie and Larry but what is capital guide for 2019? What are you expecting? And what kind of, are we expecting from say gains from the $10 billion of asset sales? So it\\'s almost like, what\\'s the guide ex the $10 billion on earnings? And also Jamie, what was Healthcare\\'s free cash flow in 2018?\",\"161\":\"And from Goldman Sachs, we have Joe Ritchie. Please go ahead.\",\"162\":\"Thanks. Good morning.\",\"163\":\"Hey, Joe. Good morning.\",\"164\":\"Good morning, Joe.\",\"165\":\"Good morning, guys. And so just I know, you\\'re a little reluctant to answer much on the 2019 guide. But I could just may be ask on just Power free cash flow, the $2.7 billion burn this year. Do you expect \\'19 to be better than 2018 from a Power free cash flow perspective?\",\"167\":\"Getting the disclosure on the $2.7 billion definitely helpful and will hopefully get some more color on the path in the near term. But I guess, if I can maybe focus then on just the onetime issues that occurred in the second half of 2018. Specifically, around the blade issue. Is it fair to say that those issues are at least behind you? And how should we think about what the call it roughly, it sounds like it was like roughly $700 million or so in quantifiable charges there. What does that relate to? Does that relate to all orders that you received so far in each turbine. Just any color on that would be helpful?\",\"172\":\"Absolutely.\",\"173\":\"That update not just the very.\",\"175\":\"Thanks, Joe.\",\"176\":\"And our final question from Cowen and Company, we have Gautam Khanna. Please go ahead.\",\"177\":\"Yes. Thank you. Good morning, guys.\",\"178\":\"Good morning.\",\"179\":\"Two questions. First, I was wondering, if you have any changes being contemplated to the incentive comp triggers for senior management as we approach the whole proxy time frame? Any changes to the PSU triggers that you\\'re thinking about now?\",\"181\":\"Okay. And I was wondering, if you could talk about when you expect pricing to bottom and the transactional Power aftermarket? Or if it has already in your opinion? And how will that pricing now compares to maybe where it was a year ago?\",\"182\":\"I think that\\'s a question that depends on geography and it depends on the scope and the kinds of work, we\\'re really looking to do with our customers. Over the last year, as we\\'ve talked about before as Scott has come in. He has really refocused our transactional group, to focus more on in some cases less scope but higher margin work as we do it. You know, it\\'s a competitive market but even having said that that as we have our orders come in, we\\'re seeing order CM or margin rate up in some cases 10, 12, 15 points on our order book and it\\'s been consistently increasing throughout the year.\",\"184\":\"I know, we ran out of time before we could get to everyone in the queue. So you can reach me and my team through the day. But I want to thank everybody for joining us. The replay of today\\'s call will be available this afternoon on our Investor website. Thank you.\",\"185\":\"Thank you. Ladies and gentlemen, this concludes today\\'s conference. Thank you for joining. You may now disconnect.\",\"2\":\"I would now like to turn the program over to your host for today\\'s conference, Steve Winoker Vice President of Investor Communications. Please go ahead sir.\",\"20\":\"As my friend, Jim Collins of good-to-great fame might say, it\\'s a start. But we have much more work to do. So let me now share with you, how I\\'ve talked with our team about how we will do it. Number one, is managing first and foremost for operational performance. Preparing for the earnings call, my first month on the job showed me that we often start with corporate and bring in the business leaders including the CEO later. We turned that around this quarter holding operating reviews first and then preparing for this call. Those reviews were tightly focused on the how we can do and how do we get better, more so than how do we explain what just happened. Let me give you an example.\",\"21\":\"Previous P&L reviews focused on revenue, contribution margin and base cost and then, of course, operating profit. The same high-level framing I saw on the Board room. No more. We now get into much more operating detail, volume, price, mix, material and labor productivity overhead and operating expenses like R&D sales and marketing and G&A, all of which are critical to understanding and then improving the business.\",\"22\":\"The second is a focus on putting our customer at the center of all we do. Over the past few months, I\\'ve spent time with our customers in China, the Middle East, Europe and here in the US. I\\'ve learned that what they value is not always aligned with how we measure our own performance.\",\"27\":\"Our Healthcare, transportation and BHGE separations can provide sources of roughly $50 billion toward that goal. Our Healthcare team continues to prepare for public company separation and that is progressing very well. We expect to monetize up to just under 50% of our Healthcare business. I talked earlier to the GE Transportation merger with Wabtec and the amended terms to increase our cash proceeds and we will sell down our remaining 50% ownership in BHGE in an orderly manner over time building on the actions, we took in November.\",\"29\":\"To be clear, we have no plans to sell GECAS. We expect to contribute approximately $4 billion of parent support in 2019. We\\'ve listened to you on the insurance front and we\\'re preparing increased disclosures in line with peers, which will be available with our 10-K release. Jamie will cover some of that detail shortly. And then finally on Power. Let me share with you the root causes of our underperformance as I see them today and the actions we\\'re taking to address each one.\",\"3\":\"Thanks, Brandon and good morning and welcome to GE\\'s Fourth Quarter Earnings Webcast. I\\'m joined by our Chairman and CEO Larry Culp; and CFO, Jamie Miller. Before we start, I\\'d like to remind you that the press release, presentation and supplemental have been available since earlier today on our investor website at www.ge.com/investors.\",\"31\":\"As a result last year, we reduced headcount by 10,000 or 15% in the business, consolidated our footprint by 30% and took out $900 million of base cost exiting at a $1 billion lower run rate. Embracing market reality means a more appropriate revenue outlook, one that is further grounded in the reality of our $92 billion backlog rather than in the hope of new orders not yet won. Second Power faces a number of nonoperational headwinds and we expect a high water mark in this regard this year. These include legal settlements and legacy project erosion principally driven by the Alstom acquisition. There\\'s also the runoff of the effects of past long-term receivables factoring and other programs.\",\"36\":\"Jamie will now take you through the detailed financial results.\",\"39\":\"I\\'ll walk the GAAP continuing EPS to adjusted EPS on the right side of the page. Starting from GAAP. Continuing EPS was $0.08 and we had $0.06 of gains principally from the sale of Distributed Power. As you will recall in the third quarter, we booked the $22 billion impairment charge related to Power goodwill based on our best estimate at that time. And during the fourth quarter, we finalized our analysis and booked an incremental $69 million charge for Power following the third quarter charge. We also recorded a goodwill impairment charge of $94 million in renewables at our Hydro business. Combined these charges were $0.02 impact. On restructuring and other items, we incurred $0.07 of charges principally at Corporate and Power as we continue to resize those segments in line with our stated plan including $0.02 of charges related to business development transaction expenses and $0.01 for our share of Baker Hughes GE\\'s restructuring.\",\"4\":\"Please note that some of the statements we are making today are forward looking and are based on our best view of the world and our businesses as we see them today. As described in our SEC filings and on our website, those elements can change as the world changes.\",\"42\":\"Contract assets were a source of cash of $900 million as we saw higher services billings in aviation driven by higher fleet utilization and spare parts consumption from strong air traffic and we spent about $1 billion in gross CapEx or $600 million ex-Baker Hughes GE. For the year, we generated $4.5 billion of adjusted industrial free cash flow and we ended the year with higher volume in the fourth quarter as is typical for our businesses. And to provide you with more detail, Power used $2.7 billion in free cash flow for the year due to a combination of restructuring costs, nonoperational headwinds as well as execution and market issues.\",\"43\":\"Next, I\\'ll cover liquidity. On the left side of the page, you can see the walk of the GE cash balance. We ended the fourth quarter with $16.8 billion of industrial cash in the bank excluding Baker Hughes GE. And for the total year, we had industrial free cash flow of $4.5 billion. We paid dividends of $4.2 billion and as of the first quarter of 2019, you\\'ll recall that the dividend is decreasing to $0.01 per share per quarter, which will preserve about $4 billion of cash in 2019. We generated cash proceeds of $5.9 billion net of taxes related to our industrial disposition principally Industrial Solutions, Value-Based Care and Dis Power. And together with Wabtec that gets to the more than $10 billion we had talked about previously.\",\"47\":\"This impact has been manageable with less than $15 million of collateral postings and a smooth transition to a Tier two commercial paper program. We continue to target a sustainable rating in the single A range.\",\"5\":\"And now, I\\'ll turn the call over to Larry\",\"50\":\"These sources include $18 billion of debt and pension transfer to Healthcare and more than $30 billion of cash proceeds from the monetization of up to just under 50% of Healthcare, 100% of our remaining stake in Baker Hughes GE and our stake in transportation. These sources will be used in part to reduce GE net debt by more than $30 billion including repaying a significant part of the $14 billion of debt transferred from GE Capital and reducing commercial paper. The parent also plans to contribute $4 billion to GE Capital in 2019 to maintain adequate capital levels there.\",\"6\":\"Thank you, Steve. Good morning, everyone. And thank you for joining us. Our comments are going to be a bit longer than usual this morning to help you understand where we are and where we\\'re going. But rest assured, we\\'ll leave as much time as we can for questions at the end.\",\"65\":\"Moving to oil and gas. Baker Hughes GE released its financial results this morning and Lorenzo and Brian will hold their earnings call with investors today following ours. Next for Transportation and Lighting. Since we last spoke in October, we signed an agreement to sell Current to American Industrial Partners and the Justice Department has closed its review of the pending merger between GE Transportation and Wabtec.\",\"68\":\"As part of the test, we unlocked our future policy benefit reserve and updated key assumptions related to the book. The two largest drivers being the changes to our assumptions and morbidity improvement of a negative $1.2 billion offset by discount rate impact of $1.9 billion. Recall that statutory testing not GAAP drives funding. We expect to conclude the statutory testing in mid-to-late February and consistent with our existing insurance funding plan, we continue to expect required statutory funding of approximately $2 billion in the first quarter of 2019. We are managing this runoff portfolio with new management and increased board expertise and focus.\",\"69\":\"To provide additional information to further clarify our insurance obligations, we plan to include enhanced disclosures related to our insurance book in our 10-K, which will be released in mid-to-late February. We\\'ll include a wide range of items from the profile of our book to morbidity and mortality assumptions to lapse rates, premium increases and related sensitivities.\",\"70\":\"With that I\\'ll turn it back over to Larry.\",\"76\":\"With that we\\'ll open it up to your questions.\",\"77\":\"And from Wolfe Research, we have Nigel Coe.\",\"78\":\"Thanks. Good morning.\",\"79\":\"Good morning, Nigel.\",\"80\":\"Morning. Lots of questions. I mean, I\\'m sure a lot of my questions will be picked up by other analysts, but I just want to start on. It sounds like your plans on Healthcare now are pretty defined, Larry. It looks like you\\'re looking to monetize 50% putting an $18 billion of pension debts, via an IPO-type process. Is that now defined or are there still some moving pieces on that process?\",\"85\":\"And from JPMorgan, we have Steve Tusa. Please go ahead.\",\"86\":\"Hey, good morning. So you mentioned on the free cash flow dynamics, you mentioned the PTC headwind, a bit more restructuring cash, some other I guess nonrecurring investments. Can you maybe give us some color on that? In addition, just provide some color on how much of a, I think Jamie said before about $1 billion of headwind or so from divestitures. So maybe just help us with a bit of a rough bridge from the $4.5 you did in 2018? Because obviously that sounds like it\\'s going to be down.\",\"89\":\"Yeah, Steve. And I think the simple answer the question is, what we\\'re trying to communicate today is that we are going to see pressures both operational and nonrecurring. We are going to be back shortly when we can take you through a detailed walk in that regard. I think from an operating perspective, is worth acknowledging a lot of good performance in the number of businesses.\",\"92\":\"Great. And what do you expect GE cash to earn in 2019 and how much from an ongoing cash generation perspective, how much will they be generating?\",\"93\":\"Steve, as I said in both my prepared remarks and a moment ago when we have everything locked down to get into those specifics then we\\'ll do that soon. We\\'ll be back to you.\",\"94\":\"From Vertical Research we have Jeffrey Sprague\",\"95\":\"Thank you. Good morning, everyone.\",\"96\":\"Morning, Jeff.\",\"97\":\"Yeah. Two from me. Just thinking about the Healthcare exit in particular. Kind of, for lack of a better term, losing that cash flow near term seems like it would create some stress on the organization. Can you give us a sense of, what you foresee as kind of the timing of the exit? And then Larry, particularly interested also on, how you view exiting the remaining 50% stake. Do you see the potential for some kind of, equity-friendly exit with that piece the split-off for example, which you might shrink the share count of the remaining company?\"},\"sentiment\":{\"1\":\"positive\",\"10\":\"positive\",\"101\":\"positive\",\"102\":\"positive\",\"106\":\"negative\",\"107\":\"negative\",\"108\":\"positive\",\"109\":\"negative\",\"11\":\"positive\",\"110\":\"negative\",\"112\":\"negative\",\"117\":\"negative\",\"118\":\"positive\",\"119\":\"negative\",\"12\":\"negative\",\"120\":\"negative\",\"123\":\"positive\",\"124\":\"negative\",\"125\":\"positive\",\"126\":\"positive\",\"13\":\"negative\",\"130\":\"positive\",\"131\":\"positive\",\"14\":\"positive\",\"147\":\"positive\",\"149\":\"positive\",\"15\":\"positive\",\"150\":\"positive\",\"151\":\"positive\",\"157\":\"positive\",\"158\":\"negative\",\"159\":\"negative\",\"16\":\"positive\",\"160\":\"negative\",\"166\":\"positive\",\"168\":\"positive\",\"169\":\"positive\",\"17\":\"positive\",\"170\":\"positive\",\"171\":\"positive\",\"174\":\"positive\",\"18\":\"positive\",\"180\":\"negative\",\"183\":\"positive\",\"19\":\"positive\",\"23\":\"positive\",\"24\":\"positive\",\"25\":\"negative\",\"26\":\"positive\",\"28\":\"negative\",\"30\":\"positive\",\"32\":\"negative\",\"33\":\"positive\",\"34\":\"positive\",\"35\":\"positive\",\"37\":\"positive\",\"38\":\"negative\",\"40\":\"negative\",\"41\":\"positive\",\"44\":\"negative\",\"45\":\"negative\",\"46\":\"negative\",\"48\":\"positive\",\"49\":\"negative\",\"51\":\"positive\",\"52\":\"negative\",\"53\":\"positive\",\"54\":\"negative\",\"55\":\"positive\",\"56\":\"positive\",\"57\":\"positive\",\"58\":\"negative\",\"59\":\"negative\",\"60\":\"positive\",\"61\":\"positive\",\"62\":\"positive\",\"63\":\"positive\",\"64\":\"negative\",\"66\":\"positive\",\"67\":\"positive\",\"7\":\"negative\",\"71\":\"positive\",\"72\":\"negative\",\"73\":\"positive\",\"74\":\"positive\",\"75\":\"positive\",\"8\":\"positive\",\"81\":\"positive\",\"82\":\"positive\",\"83\":\"negative\",\"84\":\"positive\",\"87\":\"negative\",\"88\":\"negative\",\"9\":\"positive\",\"90\":\"negative\",\"91\":\"positive\",\"98\":\"positive\",\"99\":\"positive\",\"100\":\"neutral\",\"103\":\"neutral\",\"104\":\"neutral\",\"105\":\"neutral\",\"111\":\"neutral\",\"113\":\"neutral\",\"114\":\"neutral\",\"115\":\"neutral\",\"116\":\"neutral\",\"121\":\"neutral\",\"122\":\"neutral\",\"127\":\"neutral\",\"128\":\"neutral\",\"129\":\"neutral\",\"132\":\"neutral\",\"133\":\"neutral\",\"134\":\"neutral\",\"135\":\"neutral\",\"136\":\"neutral\",\"138\":\"neutral\",\"139\":\"neutral\",\"140\":\"neutral\",\"141\":\"neutral\",\"142\":\"neutral\",\"143\":\"neutral\",\"144\":\"neutral\",\"145\":\"neutral\",\"146\":\"neutral\",\"148\":\"neutral\",\"152\":\"neutral\",\"153\":\"neutral\",\"154\":\"neutral\",\"155\":\"neutral\",\"156\":\"neutral\",\"161\":\"neutral\",\"162\":\"neutral\",\"163\":\"neutral\",\"164\":\"neutral\",\"165\":\"neutral\",\"167\":\"neutral\",\"172\":\"neutral\",\"173\":\"neutral\",\"175\":\"neutral\",\"176\":\"neutral\",\"177\":\"neutral\",\"178\":\"neutral\",\"179\":\"neutral\",\"181\":\"neutral\",\"182\":\"neutral\",\"184\":\"neutral\",\"185\":\"neutral\",\"2\":\"neutral\",\"20\":\"neutral\",\"21\":\"neutral\",\"22\":\"neutral\",\"27\":\"neutral\",\"29\":\"neutral\",\"3\":\"neutral\",\"31\":\"neutral\",\"36\":\"neutral\",\"39\":\"neutral\",\"4\":\"neutral\",\"42\":\"neutral\",\"43\":\"neutral\",\"47\":\"neutral\",\"5\":\"neutral\",\"50\":\"neutral\",\"6\":\"neutral\",\"65\":\"neutral\",\"68\":\"neutral\",\"69\":\"neutral\",\"70\":\"neutral\",\"76\":\"neutral\",\"77\":\"neutral\",\"78\":\"neutral\",\"79\":\"neutral\",\"80\":\"neutral\",\"85\":\"neutral\",\"86\":\"neutral\",\"89\":\"neutral\",\"92\":\"neutral\",\"93\":\"neutral\",\"94\":\"neutral\",\"95\":\"neutral\",\"96\":\"neutral\",\"97\":\"neutral\"}}'"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output='''{\"text\":{'''\n",
    "senti='''},\"sentiment\":{'''\n",
    "for index, row in ge_df.iterrows():\n",
    "    output+='''\"'''+str(index)+'''\":\"'''+row['text']+'''\",'''\n",
    "    senti+='''\"'''+str(index)+'''\":\"'''+row['label_predicted']+'''\",'''\n",
    "output=output[:-1]\n",
    "senti=senti[:-1]+'}}'\n",
    "out_senti=output+senti\n",
    "out_senti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = open(\"GE_predicted.json\", \"w\")\n",
    "text_file.write(out_senti)\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_neg</th>\n",
       "      <th>predicted_pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_neg</th>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_pos</th>\n",
       "      <td>24</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          predicted_neg  predicted_pos\n",
       "                                      \n",
       "true_neg             11             13\n",
       "true_pos             24             50"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_neg</th>\n",
       "      <th>predicted_pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_neg</th>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_pos</th>\n",
       "      <td>24</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          predicted_neg  predicted_pos\n",
       "                                      \n",
       "true_neg             11             13\n",
       "true_pos             24             50"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_columns=['predicted_neg','predicted_pos']\n",
    "confusion_rows=['true_neg','true_pos']\n",
    "train_confusion_matrix=pd.DataFrame(confusion_matrix(y_test_label, y_test_label_predicted))\n",
    "train_confusion_matrix.columns=confusion_columns\n",
    "train_confusion_matrix['index']=confusion_rows\n",
    "train_confusion_matrix=train_confusion_matrix.set_index('index')\n",
    "train_confusion_matrix.index.name=''\n",
    "\n",
    "test_confusion_matrix=pd.DataFrame(confusion_matrix(y_test_label, y_test_label_predicted))\n",
    "test_confusion_matrix.columns=confusion_columns\n",
    "test_confusion_matrix['index']=confusion_rows\n",
    "test_confusion_matrix=test_confusion_matrix.set_index('index')\n",
    "test_confusion_matrix.index.name=''\n",
    "\n",
    "display(train_confusion_matrix)\n",
    "display(test_confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watson_developer_cloud import NaturalLanguageUnderstandingV1\n",
    "\n",
    "natural_language_understanding = NaturalLanguageUnderstandingV1(\n",
    "    version='{version}',\n",
    "    username='{username}',\n",
    "    password='{password}',\n",
    "    url='{url}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "WatsonApiException",
     "evalue": "Error: Unauthorized: Access is denied due to invalid credentials , Code: 401",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWatsonApiException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-396-265ff3479736>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mentities\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEntitiesOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memotion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentiment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         keywords=KeywordsOptions(emotion=True, sentiment=True,\n\u001b[0;32m---> 17\u001b[0;31m                                  limit=2))).get_result()\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/watson_developer_cloud/natural_language_understanding_v1.py\u001b[0m in \u001b[0;36manalyze\u001b[0;34m(self, features, text, html, url, clean, xpath, fallback_to_raw, return_analyzed_text, language, limit_text_characters, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             accept_json=True)\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/watson_developer_cloud/watson_service.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, accept_json, headers, params, json, data, files, **kwargs)\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0merror_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_error_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m             raise WatsonApiException(response.status_code, error_message,\n\u001b[0;32m--> 587\u001b[0;31m                                      info=error_info, httpResponse=response)\n\u001b[0m",
      "\u001b[0;31mWatsonApiException\u001b[0m: Error: Unauthorized: Access is denied due to invalid credentials , Code: 401"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from watson_developer_cloud import NaturalLanguageUnderstandingV1\n",
    "from watson_developer_cloud.natural_language_understanding_v1 \\\n",
    "    import Features, EntitiesOptions, KeywordsOptions\n",
    "\n",
    "naturalLanguageUnderstanding = NaturalLanguageUnderstandingV1(\n",
    "    version='2018-11-16',\n",
    "    username='wenjun song',\n",
    "    password='Ilove22*',\n",
    "    #iam_apikey='OAbro0YFtCjxCW5Z8EiHjBcKGHtm2qpl30rvUw9yDZJ1',\n",
    "    url='https://gateway-tok.watsonplatform.net/natural-language-understanding/api')\n",
    "\n",
    "response = naturalLanguageUnderstanding.analyze(\n",
    "    text=all_data_df_2type['text'].tolist()[0],\n",
    "    features=Features(\n",
    "        entities=EntitiesOptions(emotion=True, sentiment=True, limit=2),\n",
    "        keywords=KeywordsOptions(emotion=True, sentiment=True,\n",
    "                                 limit=2))).get_result()\n",
    "\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-api-python-client\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/e9/e8fb2e3a031cb69b9524b80a92b126665d9a17421700a219555e3233ab6a/google_api_python_client-1.7.8-py3-none-any.whl (56kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 1.8MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-python-client) (1.11.0)\n",
      "Collecting httplib2<1dev,>=0.9.2 (from google-api-python-client)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/d0/f213003c9deec99fb4f46e54580b93a3b121c487d9d6d888fc12267eb2a2/httplib2-0.12.1.tar.gz (218kB)\n",
      "\u001b[K    100% |████████████████████████████████| 225kB 6.6MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting uritemplate<4dev,>=3.0.0 (from google-api-python-client)\n",
      "  Downloading https://files.pythonhosted.org/packages/e5/7d/9d5a640c4f8bf2c8b1afc015e9a9d8de32e13c9016dcc4b0ec03481fb396/uritemplate-3.0.0-py2.py3-none-any.whl\n",
      "Collecting google-auth-httplib2>=0.0.3 (from google-api-python-client)\n",
      "  Downloading https://files.pythonhosted.org/packages/33/49/c814d6d438b823441552198f096fcd0377fd6c88714dbed34f1d3c8c4389/google_auth_httplib2-0.0.3-py2.py3-none-any.whl\n",
      "Collecting google-auth>=1.4.1 (from google-api-python-client)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/9b/ed0516cc1f7609fb0217e3057ff4f0f9f3e3ce79a369c6af4a6c5ca25664/google_auth-1.6.3-py2.py3-none-any.whl (73kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 6.4MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting cachetools>=2.0.0 (from google-auth>=1.4.1->google-api-python-client)\n",
      "  Downloading https://files.pythonhosted.org/packages/39/2b/d87fc2369242bd743883232c463f28205902b8579cb68dcf5b11eee1652f/cachetools-3.1.0-py2.py3-none-any.whl\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.4.1->google-api-python-client)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/98/8ddd9fa4d84065926832bcf2255a2b69f1d03330aa4d1c49cc7317ac888e/pyasn1_modules-0.2.4-py2.py3-none-any.whl (66kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 7.3MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting rsa>=3.1.4 (from google-auth>=1.4.1->google-api-python-client)\n",
      "  Downloading https://files.pythonhosted.org/packages/02/e5/38518af393f7c214357079ce67a317307936896e961e35450b70fad2a9cf/rsa-4.0-py2.py3-none-any.whl\n",
      "Collecting pyasn1<0.5.0,>=0.4.1 (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->google-api-python-client)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/7c/c9386b82a25115cccf1903441bba3cbadcfae7b678a20167347fa8ded34c/pyasn1-0.4.5-py2.py3-none-any.whl (73kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 8.0MB/s ta 0:00:011\n",
      "\u001b[?25hBuilding wheels for collected packages: httplib2\n",
      "  Running setup.py bdist_wheel for httplib2 ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/lovelife/Library/Caches/pip/wheels/98/82/0d/cfb126a5e40d487157e43fdb3332937713dde36b4d0e1e754d\n",
      "Successfully built httplib2\n",
      "Installing collected packages: httplib2, uritemplate, cachetools, pyasn1, pyasn1-modules, rsa, google-auth, google-auth-httplib2, google-api-python-client\n",
      "Successfully installed cachetools-3.1.0 google-api-python-client-1.7.8 google-auth-1.6.3 google-auth-httplib2-0.0.3 httplib2-0.12.1 pyasn1-0.4.5 pyasn1-modules-0.2.4 rsa-4.0 uritemplate-3.0.0\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Searching for google-api-python-client\n",
      "Reading https://pypi.org/simple/google-api-python-client/\n",
      "Downloading https://files.pythonhosted.org/packages/55/e9/e8fb2e3a031cb69b9524b80a92b126665d9a17421700a219555e3233ab6a/google_api_python_client-1.7.8-py3-none-any.whl#sha256=937eabdc3940977f712fa648a096a5142766b6d0a0f58bc603e2ac0687397ef0\n",
      "Best match: google-api-python-client 1.7.8\n",
      "Processing google_api_python_client-1.7.8-py3-none-any.whl\n",
      "Installing google_api_python_client-1.7.8-py3-none-any.whl to /Users/lovelife/anaconda3/lib/python3.6/site-packages\n",
      "writing requirements to /Users/lovelife/anaconda3/lib/python3.6/site-packages/google_api_python_client-1.7.8-py3.6.egg/EGG-INFO/requires.txt\n",
      "Adding google-api-python-client 1.7.8 to easy-install.pth file\n",
      "\n",
      "Installed /Users/lovelife/anaconda3/lib/python3.6/site-packages/google_api_python_client-1.7.8-py3.6.egg\n",
      "Processing dependencies for google-api-python-client\n",
      "Finished processing dependencies for google-api-python-client\n",
      "Collecting google-cloud-storage\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/e9/06d9bb394fddbc62bb9c645f5e1c927128930a249d0c6a7491c3f31a9ff4/google_cloud_storage-1.14.0-py2.py3-none-any.whl (60kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 1.9MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting google-resumable-media>=0.3.1 (from google-cloud-storage)\n",
      "  Downloading https://files.pythonhosted.org/packages/e2/5d/4bc5c28c252a62efe69ed1a1561da92bd5af8eca0cdcdf8e60354fae9b29/google_resumable_media-0.3.2-py2.py3-none-any.whl\n",
      "Collecting google-api-core<2.0.0dev,>=1.6.0 (from google-cloud-storage)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c4/71/23a234ee35117c2ed1ebd5a62ae07ef29f9f0bae9ea816b91312bad81646/google_api_core-1.8.1-py2.py3-none-any.whl (65kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 5.5MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting google-cloud-core<0.30dev,>=0.29.0 (from google-cloud-storage)\n",
      "  Downloading https://files.pythonhosted.org/packages/0c/f2/3c225e7a69cb27d283b68bff867722bd066bc1858611180197f711815ea5/google_cloud_core-0.29.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-resumable-media>=0.3.1->google-cloud-storage) (1.11.0)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage) (3.6.1)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=0.4.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage) (1.6.3)\n",
      "Requirement already satisfied: pytz in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage) (2018.4)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage) (2.21.0)\n",
      "Requirement already satisfied: setuptools>=34.0.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage) (39.1.0)\n",
      "Collecting googleapis-common-protos!=1.5.4,<2.0dev,>=1.5.3 (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage)\n",
      "  Downloading https://files.pythonhosted.org/packages/21/fd/0ea06fab3651857955f2240a20cf951a29c1cdfdc937c3d19d8575651a64/googleapis-common-protos-1.5.8.tar.gz\n",
      "Requirement already satisfied: cachetools>=2.0.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage) (3.1.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage) (0.2.4)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage) (4.0)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage) (1.22)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage) (2018.11.29)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage) (2.6)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage) (0.4.5)\n",
      "Building wheels for collected packages: googleapis-common-protos\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Running setup.py bdist_wheel for googleapis-common-protos ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/lovelife/Library/Caches/pip/wheels/51/ef/76/6ca53de13cc85eea40c641d75bb01355d97181ed64eb67bc8e\n",
      "Successfully built googleapis-common-protos\n",
      "Installing collected packages: google-resumable-media, googleapis-common-protos, google-api-core, google-cloud-core, google-cloud-storage\n",
      "Successfully installed google-api-core-1.8.1 google-cloud-core-0.29.1 google-cloud-storage-1.14.0 google-resumable-media-0.3.2 googleapis-common-protos-1.5.8\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting google-cloud-language\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/3a/6f5808421aea97363cb19a095f73ed6eed12bbaee1e67f2145af7125585d/google_cloud_language-1.1.1-py2.py3-none-any.whl (65kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 1.8MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.6.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-cloud-language) (1.8.1)\n",
      "Requirement already satisfied: setuptools>=34.0.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (39.1.0)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=0.4.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (1.6.3)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (1.11.0)\n",
      "Requirement already satisfied: googleapis-common-protos!=1.5.4,<2.0dev,>=1.5.3 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (1.5.8)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (2.21.0)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (3.6.1)\n",
      "Requirement already satisfied: pytz in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (2018.4)\n",
      "Requirement already satisfied: grpcio>=1.8.2; extra == \"grpc\" in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (1.16.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (0.2.4)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (4.0)\n",
      "Requirement already satisfied: cachetools>=2.0.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (2018.11.29)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (2.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (3.0.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (0.4.5)\n",
      "Installing collected packages: google-cloud-language\n",
      "Successfully installed google-cloud-language-1.1.1\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already up-to-date: google-cloud-language in /Users/lovelife/anaconda3/lib/python3.6/site-packages (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: google-api-core[grpc]<2.0.0dev,>=1.6.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-cloud-language) (1.8.1)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=34.0.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (39.1.0)\n",
      "Requirement already satisfied, skipping upgrade: requests<3.0.0dev,>=2.18.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (2.21.0)\n",
      "Requirement already satisfied, skipping upgrade: googleapis-common-protos!=1.5.4,<2.0dev,>=1.5.3 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (1.5.8)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2.0dev,>=0.4.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (2018.4)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (1.11.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.4.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (3.6.1)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.2; extra == \"grpc\" in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (1.16.1)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (1.22)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (2018.11.29)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (2.6)\n",
      "Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (0.2.4)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from rsa>=3.1.4->google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (0.4.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mYou are using pip version 18.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting google-auth-oauthlib\n",
      "  Downloading https://files.pythonhosted.org/packages/46/df/d1f94ee2cffe5a83721f262efe51f3b2dcdd3b616caf007b8490e824c550/google_auth_oauthlib-0.2.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: google-auth in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth-oauthlib) (1.6.3)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib)\n",
      "  Using cached https://files.pythonhosted.org/packages/c2/e2/9fd03d55ffb70fe51f587f20bcf407a6927eb121de86928b34d162f0b1ac/requests_oauthlib-1.2.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: cachetools>=2.0.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth->google-auth-oauthlib) (3.1.0)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth->google-auth-oauthlib) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth->google-auth-oauthlib) (0.2.4)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth->google-auth-oauthlib) (1.11.0)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib)\n",
      "  Using cached https://files.pythonhosted.org/packages/16/95/699466b05b72b94a41f662dc9edf87fda4289e3602ecd42d27fcaddf7b56/oauthlib-3.0.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: requests>=2.0.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (2.21.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from rsa>=3.1.4->google-auth->google-auth-oauthlib) (0.4.5)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (2.6)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (1.22)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (2018.11.29)\n",
      "Installing collected packages: oauthlib, requests-oauthlib, google-auth-oauthlib\n",
      "Successfully installed google-auth-oauthlib-0.2.0 oauthlib-3.0.1 requests-oauthlib-1.2.0\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade google-api-python-client\n",
    "!easy_install --upgrade google-api-python-client\n",
    "! pip install google-cloud-storage\n",
    "! pip install google-cloud-language\n",
    "! pip install --upgrade google-cloud-language\n",
    "import argparse\n",
    "import google.cloud\n",
    "from google.cloud import language\n",
    "from google.cloud import storage\n",
    "from google.cloud.language import enums\n",
    "from google.cloud.language import types\n",
    "import os\n",
    "from google.oauth2 import service_account\n",
    "!pip install google-auth-oauthlib\n",
    "from google_auth_oauthlib.flow import Flow\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "document_sentiment {\n",
       "  magnitude: 0.30000001192092896\n",
       "}\n",
       "language: \"en\"\n",
       "sentences {\n",
       "  text {\n",
       "    content: \"Can I ask just sort of quick one?\"\n",
       "    begin_offset: -1\n",
       "  }\n",
       "  sentiment {\n",
       "    magnitude: 0.20000000298023224\n",
       "    score: 0.20000000298023224\n",
       "  }\n",
       "}\n",
       "sentences {\n",
       "  text {\n",
       "    content: \"Just for Greg.\"\n",
       "    begin_offset: -1\n",
       "  }\n",
       "  sentiment {\n",
       "  }\n",
       "}\n",
       "sentences {\n",
       "  text {\n",
       "    content: \"Greg, when we think about the 727 engine versus the MAX, just for modeling purposes it\\'s going to review 90% MAXs this year.\"\n",
       "    begin_offset: -1\n",
       "  }\n",
       "  sentiment {\n",
       "  }\n",
       "}\n",
       "sentences {\n",
       "  text {\n",
       "    content: \"How do we think about the margin profile of one variant versus the other?\"\n",
       "    begin_offset: -1\n",
       "  }\n",
       "  sentiment {\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cred_file_loc = r'dogwood-dryad-235122-9721a66a61c1.json'\n",
    "cred = service_account.Credentials.from_service_account_file(cred_file_loc)\n",
    "Client = language.LanguageServiceClient(credentials=cred)\n",
    "paragraphs = all_data_df['text'].tolist()\n",
    "results = []\n",
    "for paragraph in paragraphs:\n",
    "    document = types.Document(content=paragraph, type=enums.Document.Type.PLAIN_TEXT)\n",
    "    result = Client.analyze_sentiment(document=document)\n",
    "    results.append(result)\n",
    "\n",
    "results[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_neg</th>\n",
       "      <th>predicted_neutral</th>\n",
       "      <th>predicted_pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_neg</th>\n",
       "      <td>23</td>\n",
       "      <td>105</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_neutral</th>\n",
       "      <td>56</td>\n",
       "      <td>639</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_pos</th>\n",
       "      <td>25</td>\n",
       "      <td>329</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              predicted_neg  predicted_neutral  predicted_pos\n",
       "                                                             \n",
       "true_neg                 23                105             27\n",
       "true_neutral             56                639            140\n",
       "true_pos                 25                329            300"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def classify_google(x):\n",
    "    if x['score']<=-0.10:\n",
    "        return 'negative'\n",
    "    elif x['score']>-0.10 and (x['score']<0.25):\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'positive'\n",
    "\n",
    "magnitudes=[]\n",
    "scores=[]\n",
    "for i in range(len(results)):\n",
    "    magnitudes.append(results[i].document_sentiment.magnitude)\n",
    "    scores.append(results[i].document_sentiment.score)\n",
    "google_sentiment=pd.DataFrame({'magnitude':magnitudes,'score':scores})\n",
    "google_sentiment['label_goog']=google_sentiment.apply(classify_google,axis=1)\n",
    "google_merged=pd.concat([all_data_df,google_sentiment],axis=1)\n",
    "test_confusion_matrix=pd.DataFrame(confusion_matrix(google_merged['sentiment'].tolist(), google_merged['label_goog'].tolist()))\n",
    "test_confusion_matrix.columns=confusion_columns=['predicted_neg','predicted_neutral','predicted_pos']\n",
    "test_confusion_matrix['index']=['true_neg','true_neutral','true_pos']\n",
    "test_confusion_matrix=test_confusion_matrix.set_index('index')\n",
    "test_confusion_matrix.index.name=''\n",
    "\n",
    "display(test_confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in all_data_df.iterrows():\n",
    "    text_file = open(\"Amazon/text_\"+str(index)+\".txt\", \"w\")\n",
    "    text_file.write(row['text'])\n",
    "    text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>mixed</th>\n",
       "      <th>label_amazon_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>0.008</td>\n",
       "      <td>2.155e-01</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.022</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.135</td>\n",
       "      <td>5.293e-04</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.002</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>0.340</td>\n",
       "      <td>3.178e-02</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.545</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1425</th>\n",
       "      <td>0.058</td>\n",
       "      <td>3.285e-02</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.007</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1644 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      positive   negative  neutral  mixed label_amazon_predicted\n",
       "985      0.008  2.155e-01    0.754  0.022                neutral\n",
       "437      0.135  5.293e-04    0.862  0.002                neutral\n",
       "...        ...        ...      ...    ...                    ...\n",
       "1638     0.340  3.178e-02    0.083  0.545               positive\n",
       "1425     0.058  3.285e-02    0.902  0.007                neutral\n",
       "\n",
       "[1644 rows x 5 columns]"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_predict=pd.read_csv('amazon_prediction.csv')\n",
    "amazon_predict['MyId']=amazon_predict['imagelocation'].apply(lambda x: int(x.split('_')[1].split('.')[0]))\n",
    "amazon_predict=amazon_predict.sort_values(['MyId'])\n",
    "amazon_predict=amazon_predict[['sentiment','positive','negative','neutral','mixed']]\n",
    "amazon_predict['label_amazon_predicted']=amazon_predict['sentiment'].apply(lambda x: x.lower())\n",
    "amazon_predict['label_amazon_predicted']=amazon_predict['label_amazon_predicted'].apply(lambda x: 'positive' if x=='mixed' else x)\n",
    "amazon_predict=amazon_predict.drop('sentiment',axis=1)\n",
    "amazon_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_neg</th>\n",
       "      <th>predicted_neutral</th>\n",
       "      <th>predicted_pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_neg</th>\n",
       "      <td>12</td>\n",
       "      <td>115</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_neutral</th>\n",
       "      <td>42</td>\n",
       "      <td>553</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_pos</th>\n",
       "      <td>41</td>\n",
       "      <td>524</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              predicted_neg  predicted_neutral  predicted_pos\n",
       "                                                             \n",
       "true_neg                 12                115             28\n",
       "true_neutral             42                553            240\n",
       "true_pos                 41                524             89"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "amzn_merged=pd.concat([all_data_df,amazon_predict],axis=1)\n",
    "test_confusion_matrix=pd.DataFrame(confusion_matrix(amzn_merged['sentiment'].tolist(), amzn_merged['label_amazon_predicted'].tolist()))\n",
    "test_confusion_matrix.columns=confusion_columns=['predicted_neg','predicted_neutral','predicted_pos']\n",
    "test_confusion_matrix['index']=['true_neg','true_neutral','true_pos']\n",
    "test_confusion_matrix=test_confusion_matrix.set_index('index')\n",
    "test_confusion_matrix.index.name=''\n",
    "\n",
    "display(test_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting auto-sklearn\n",
      "Requirement already satisfied: numpy<=1.14.5,>=1.9.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from auto-sklearn) (1.14.5)\n",
      "Requirement already satisfied: psutil in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from auto-sklearn) (5.4.5)\n",
      "Collecting smac==0.8 (from auto-sklearn)\n",
      "Requirement already satisfied: liac-arff in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from auto-sklearn) (2.4.0)\n",
      "Requirement already satisfied: nose in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from auto-sklearn) (1.3.7)\n",
      "Requirement already satisfied: pyyaml in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from auto-sklearn) (3.12)\n",
      "Requirement already satisfied: ConfigSpace<0.5,>=0.4.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from auto-sklearn) (0.4.9)\n",
      "Requirement already satisfied: pandas in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from auto-sklearn) (0.23.4)\n",
      "Collecting pyrfr<0.8,>=0.7 (from auto-sklearn)\n",
      "  Using cached https://files.pythonhosted.org/packages/c3/c6/c555cfa3c7d0078dded091d4901ed52344bbb925077aa70b871faf35fd58/pyrfr-0.7.4.tar.gz\n",
      "Requirement already satisfied: joblib in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from auto-sklearn) (0.13.2)\n",
      "Requirement already satisfied: lockfile in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from auto-sklearn) (0.12.2)\n",
      "Requirement already satisfied: scipy>=0.14.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from auto-sklearn) (1.2.0)\n",
      "Requirement already satisfied: pynisher>=0.4.2 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from auto-sklearn) (0.5.0)\n",
      "Requirement already satisfied: setuptools in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from auto-sklearn) (39.1.0)\n",
      "Requirement already satisfied: Cython in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from auto-sklearn) (0.28.2)\n",
      "Requirement already satisfied: scikit-learn<0.20,>=0.19 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from auto-sklearn) (0.19.2)\n",
      "Requirement already satisfied: xgboost>=0.80 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from auto-sklearn) (0.82)\n",
      "Requirement already satisfied: sphinx in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from smac==0.8->auto-sklearn) (1.7.4)\n",
      "Requirement already satisfied: typing in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from smac==0.8->auto-sklearn) (3.6.4)\n",
      "Requirement already satisfied: six in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from smac==0.8->auto-sklearn) (1.11.0)\n",
      "Collecting sphinx-rtd-theme (from smac==0.8->auto-sklearn)\n",
      "  Using cached https://files.pythonhosted.org/packages/60/b4/4df37087a1d36755e3a3bfd2a30263f358d2dea21938240fa02313d45f51/sphinx_rtd_theme-0.4.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pyparsing in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from ConfigSpace<0.5,>=0.4.0->auto-sklearn) (2.2.0)\n",
      "Requirement already satisfied: pytz>=2011k in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from pandas->auto-sklearn) (2018.4)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from pandas->auto-sklearn) (2.7.3)\n",
      "Requirement already satisfied: docutils>=0.3 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from pynisher>=0.4.2->auto-sklearn) (0.14)\n",
      "Requirement already satisfied: Jinja2>=2.3 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from sphinx->smac==0.8->auto-sklearn) (2.10)\n",
      "Requirement already satisfied: Pygments>=2.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from sphinx->smac==0.8->auto-sklearn) (2.2.0)\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from sphinx->smac==0.8->auto-sklearn) (1.2.1)\n",
      "Requirement already satisfied: babel!=2.0,>=1.3 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from sphinx->smac==0.8->auto-sklearn) (2.5.3)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from sphinx->smac==0.8->auto-sklearn) (0.7.10)\n",
      "Requirement already satisfied: imagesize in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from sphinx->smac==0.8->auto-sklearn) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from sphinx->smac==0.8->auto-sklearn) (2.21.0)\n",
      "Requirement already satisfied: packaging in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from sphinx->smac==0.8->auto-sklearn) (17.1)\n",
      "Requirement already satisfied: sphinxcontrib-websupport in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from sphinx->smac==0.8->auto-sklearn) (1.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from Jinja2>=2.3->sphinx->smac==0.8->auto-sklearn) (1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests>=2.0.0->sphinx->smac==0.8->auto-sklearn) (2018.11.29)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests>=2.0.0->sphinx->smac==0.8->auto-sklearn) (1.22)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests>=2.0.0->sphinx->smac==0.8->auto-sklearn) (2.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests>=2.0.0->sphinx->smac==0.8->auto-sklearn) (3.0.4)\n",
      "Building wheels for collected packages: pyrfr\n",
      "  Building wheel for pyrfr (setup.py) ... \u001b[?25lerror\n",
      "  Complete output from command /Users/lovelife/anaconda3/bin/python -u -c \"import setuptools, tokenize;__file__='/private/var/folders/h1/pcv8265963799lkgn7tjtctw0000gn/T/pip-install-01_0z54l/pyrfr/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d /private/var/folders/h1/pcv8265963799lkgn7tjtctw0000gn/T/pip-wheel-q344oxot --python-tag cp36:\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_ext\n",
      "  building 'pyrfr._regression' extension\n",
      "  swigging pyrfr/regression.i to pyrfr/regression_wrap.cpp\n",
      "  swig -python -c++ -modern -features nondynamic -I./include -o pyrfr/regression_wrap.cpp pyrfr/regression.i\n",
      "  creating build\n",
      "  creating build/temp.macosx-10.7-x86_64-3.6\n",
      "  creating build/temp.macosx-10.7-x86_64-3.6/pyrfr\n",
      "  gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/Users/lovelife/anaconda3/include -arch x86_64 -I/Users/lovelife/anaconda3/include -arch x86_64 -I./include -I/Users/lovelife/anaconda3/include/python3.6m -c pyrfr/regression_wrap.cpp -o build/temp.macosx-10.7-x86_64-3.6/pyrfr/regression_wrap.o -O2 -std=c++11\n",
      "  pyrfr/regression_wrap.cpp:3166:10: fatal error: 'random' file not found\n",
      "  #include <random>\n",
      "           ^~~~~~~~\n",
      "  1 error generated.\n",
      "  error: command 'gcc' failed with exit status 1\n",
      "  \n",
      "  ----------------------------------------\n",
      "\u001b[31m  Failed building wheel for pyrfr\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for pyrfr\n",
      "Failed to build pyrfr\n",
      "Installing collected packages: pyrfr, sphinx-rtd-theme, smac, auto-sklearn\n",
      "  Running setup.py install for pyrfr ... \u001b[?25lerror\n",
      "    Complete output from command /Users/lovelife/anaconda3/bin/python -u -c \"import setuptools, tokenize;__file__='/private/var/folders/h1/pcv8265963799lkgn7tjtctw0000gn/T/pip-install-01_0z54l/pyrfr/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /private/var/folders/h1/pcv8265963799lkgn7tjtctw0000gn/T/pip-record-kv1hqkrw/install-record.txt --single-version-externally-managed --compile:\n",
      "    running install\n",
      "    running build_ext\n",
      "    building 'pyrfr._regression' extension\n",
      "    swigging pyrfr/regression.i to pyrfr/regression_wrap.cpp\n",
      "    swig -python -c++ -modern -features nondynamic -I./include -o pyrfr/regression_wrap.cpp pyrfr/regression.i\n",
      "    creating build\n",
      "    creating build/temp.macosx-10.7-x86_64-3.6\n",
      "    creating build/temp.macosx-10.7-x86_64-3.6/pyrfr\n",
      "    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/Users/lovelife/anaconda3/include -arch x86_64 -I/Users/lovelife/anaconda3/include -arch x86_64 -I./include -I/Users/lovelife/anaconda3/include/python3.6m -c pyrfr/regression_wrap.cpp -o build/temp.macosx-10.7-x86_64-3.6/pyrfr/regression_wrap.o -O2 -std=c++11\n",
      "    pyrfr/regression_wrap.cpp:3166:10: fatal error: 'random' file not found\n",
      "    #include <random>\n",
      "             ^~~~~~~~\n",
      "    1 error generated.\n",
      "    error: command 'gcc' failed with exit status 1\n",
      "    \n",
      "    ----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mCommand \"/Users/lovelife/anaconda3/bin/python -u -c \"import setuptools, tokenize;__file__='/private/var/folders/h1/pcv8265963799lkgn7tjtctw0000gn/T/pip-install-01_0z54l/pyrfr/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /private/var/folders/h1/pcv8265963799lkgn7tjtctw0000gn/T/pip-record-kv1hqkrw/install-record.txt --single-version-externally-managed --compile\" failed with error code 1 in /private/var/folders/h1/pcv8265963799lkgn7tjtctw0000gn/T/pip-install-01_0z54l/pyrfr/\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "! pip install auto-sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/90/bfe484adb16cdad078967b2b480517ec6c1180137e26fb4b015bcb090226/scikit_learn-0.20.3-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (8.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 8.0MB 4.0MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=0.13.3 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.8.2 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from scikit-learn) (1.14.5)\n",
      "\u001b[31mautokeras 0.3.7 has requirement numpy==1.15.4, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
      "\u001b[31mautokeras 0.3.7 has requirement scikit-learn==0.20.2, but you'll have scikit-learn 0.20.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: scikit-learn\n",
      "  Found existing installation: scikit-learn 0.19.2\n",
      "    Uninstalling scikit-learn-0.19.2:\n",
      "      Successfully uninstalled scikit-learn-0.19.2\n",
      "Successfully installed scikit-learn-0.20.3\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/lovelife/anaconda3/lib/python3.6/site-packages (1.14.5)\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/f3/413bab4ff08e1fc4828dfc59996d721917df8e8583ea85385d51125dceff/pip-19.0.3-py2.py3-none-any.whl (1.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.4MB 5.9MB/s ta 0:00:011\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Found existing installation: pip 18.1\n",
      "    Uninstalling pip-18.1:\n",
      "      Successfully uninstalled pip-18.1\n",
      "Successfully installed pip-19.0.3\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/0e/30aaa357c3065957344b240482818eef31d4080f73dfa5f1ef7dcd8744d2/numpy-1.16.2-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (13.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 13.9MB 2.7MB/s ta 0:00:011\n",
      "\u001b[31mautokeras 0.3.7 has requirement numpy==1.15.4, but you'll have numpy 1.16.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mautokeras 0.3.7 has requirement scikit-learn==0.20.2, but you'll have scikit-learn 0.20.3 which is incompatible.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Found existing installation: numpy 1.14.5\n",
      "    Uninstalling numpy-1.14.5:\n",
      "      Successfully uninstalled numpy-1.14.5\n",
      "Successfully installed numpy-1.16.2\n"
     ]
    }
   ],
   "source": [
    "! pip install -U numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
