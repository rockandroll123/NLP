{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from IPython.display import display\n",
    "pd.set_option('display.max_rows',5)\n",
    "pd.set_option('precision',3)\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:100% !important;}</style>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_df(file_name):\n",
    "    #print(file_name)\n",
    "    with open(file_name, encoding='utf-8', errors='ignore') as f:\n",
    "        json_1 = json.load(f)\n",
    "    dict_1 = dict(json_1)\n",
    "    df_1 = pd.DataFrame.from_dict(dict_1)\n",
    "    return df_1\n",
    "def create_padded_docs(t,doc,max_length = 500):\n",
    "    encoded_docs = t.texts_to_sequences(doc)\n",
    "    #print(encoded_docs)\n",
    "    padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "    #print(padded_docs)\n",
    "    return padded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Greetings and welcome to the Microsoft Fiscal ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>With that as a backdrop, I want to highlight k...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>98</td>\n",
       "      <td>Thanks, Mark. Operator, can we please move to ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>99</td>\n",
       "      <td>The next question is coming from the line of K...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                               text sentiment   Id\n",
       "0       1  Greetings and welcome to the Microsoft Fiscal ...   neutral    0\n",
       "1      10  With that as a backdrop, I want to highlight k...  positive    1\n",
       "..    ...                                                ...       ...  ...\n",
       "176    98  Thanks, Mark. Operator, can we please move to ...   neutral  176\n",
       "177    99  The next question is coming from the line of K...   neutral  177\n",
       "\n",
       "[178 rows x 4 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_df['Id']=all_data_df.index\n",
    "all_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'all_group_data.pickle'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(all_data_df,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive' 'neutral' 'negative']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yeah. And on unit deceleration, I think the un...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>During this call, we may discuss certain non-G...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hello, and welcome to our Q4 2018 financial re...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Our comments and responses to your questions r...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text sentiment\n",
       "1   Yeah. And on unit deceleration, I think the un...  positive\n",
       "10  During this call, we may discuss certain non-G...   neutral\n",
       "..                                                ...       ...\n",
       "8   Hello, and welcome to our Q4 2018 financial re...   neutral\n",
       "9   Our comments and responses to your questions r...   neutral\n",
       "\n",
       "[54 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive' 'neutral' 'negative']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "      <th>text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yeah. And on unit deceleration, I think the un...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Yeah. Really, we're still evaluating the situa...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>So the AWS operating margins historically kin...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Yeah. Sure. Let me start with the AWS operatin...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>1030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text sentiment  label  \\\n",
       "1   Yeah. And on unit deceleration, I think the un...  positive      1   \n",
       "17  Yeah. Really, we're still evaluating the situa...  positive      1   \n",
       "..                                                ...       ...    ...   \n",
       "52   So the AWS operating margins historically kin...  negative      0   \n",
       "53  Yeah. Sure. Let me start with the AWS operatin...  positive      1   \n",
       "\n",
       "    text_len  \n",
       "1        487  \n",
       "17       490  \n",
       "..       ...  \n",
       "52       591  \n",
       "53      1030  \n",
       "\n",
       "[21 rows x 4 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data=[]\n",
    "for file in os.listdir():\n",
    "    \n",
    "    #if file == \"Team1_Google.json\":\n",
    "    if file == \"Team2_Amazon.json\":\n",
    "    #if file == \"Team3_Facebook.json\":\n",
    "    #if file == \"Team4_Netflix.json\":    \n",
    "    #if file == \"Team5_Microsoft.json\":\n",
    "    #if file == \"Team6_Tesla.json\":\n",
    "    #if file == \"Team7_Walmart.json\":\n",
    "    #if file == \"Team8_Kroger.json\":\n",
    "    #if file == \"Team9_GoldmanSachs.json\":\n",
    "    #if file == \"Team10_NVIDIA.json\":\n",
    "    #if file == \"Team11_Boeing.json\":\n",
    "    #if file == \"Team12_Chevron.json\":\n",
    "\n",
    "    #if file.startswith(\"Team\") and file.endswith(\".json\"):\n",
    "        df=json_to_df(file)\n",
    "        df.columns=['text','sentiment']\n",
    "        df['sentiment']=df['sentiment'].apply(lambda x: x.lower())\n",
    "        if sum(df.isnull().any(axis=1))>0:\n",
    "            display(df[pd.isnull(df['Sentiment'])])\n",
    "        else:\n",
    "            all_data.append(df)\n",
    "all_data_df=pd.concat(all_data)\n",
    "all_data_df['sentiment']=all_data_df['sentiment'].apply(lambda x: 'neutral' if x in ['neutra;','negetive','neural'] else x)\n",
    "all_data_df['sentiment']=all_data_df['sentiment'].apply(lambda x: 'positive' if x in ['postive','positivem'] else x)\n",
    "print(all_data_df['sentiment'].unique())\n",
    "display(all_data_df)\n",
    "all_data_df_2type=all_data_df[all_data_df['sentiment'].isin(['positive','negative'])].copy()\n",
    "all_data_df=all_data_df.reset_index()\n",
    "all_data_df_2type_neu=all_data_df[~all_data_df['sentiment'].isin(['positive','negative'])].copy()\n",
    "all_data_df_2type['label']=all_data_df_2type['sentiment'].apply(lambda x: 1 if x=='positive' else 0)\n",
    "all_data_df_2type['text_len']=all_data_df_2type['text'].apply(lambda x: len(x))\n",
    "all_data_df_2type_pos=all_data_df_2type[all_data_df_2type['sentiment']=='positive'].copy()\n",
    "all_data_df_2type_neg=all_data_df_2type[all_data_df_2type['sentiment']=='negative'].copy()\n",
    "print(all_data_df['sentiment'].unique())\n",
    "all_data_df_2type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "      <th>text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thank you, Ellen. We have a strong 2018, with ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Stock-based compensation totaled $2.3 billion....</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>I think, we’ve always approached M&amp;A as I thin...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>So the reason I started by laying out, I think...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text sentiment  label  \\\n",
       "1   Thank you, Ellen. We have a strong 2018, with ...  positive      1   \n",
       "10  Stock-based compensation totaled $2.3 billion....  positive      1   \n",
       "..                                                ...       ...    ...   \n",
       "90  I think, we’ve always approached M&A as I thin...  positive      1   \n",
       "92  So the reason I started by laying out, I think...  positive      1   \n",
       "\n",
       "    text_len  \n",
       "1        271  \n",
       "10       332  \n",
       "..       ...  \n",
       "90       458  \n",
       "92       594  \n",
       "\n",
       "[68 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_df_2type_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "      <th>text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>For the full-year 2018, Other Bets revenues we...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Google Al Lead, Jeff Dean recapped the results...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Let me start with a summary of Alphabet's cons...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>APAC revenues were $6.1 billion, up 29% versus...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text sentiment  label  \\\n",
       "19  For the full-year 2018, Other Bets revenues we...  negative      0   \n",
       "32  Google Al Lead, Jeff Dean recapped the results...  negative      0   \n",
       "4   Let me start with a summary of Alphabet's cons...  negative      0   \n",
       "6   APAC revenues were $6.1 billion, up 29% versus...  negative      0   \n",
       "\n",
       "    text_len  \n",
       "19       359  \n",
       "32       258  \n",
       "4        252  \n",
       "6        300  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_df_2type_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>Turning now to CapEx and operating cash flow. ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18</td>\n",
       "      <td>Let me now turn to and talk about Other Bets. ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>91</td>\n",
       "      <td>And real quick for Ruth, just the magnitude of...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>Ladies and gentlemen, thank you for participat...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text sentiment\n",
       "4     13  Turning now to CapEx and operating cash flow. ...   neutral\n",
       "9     18  Let me now turn to and talk about Other Bets. ...   neutral\n",
       "..   ...                                                ...       ...\n",
       "90    91  And real quick for Ruth, just the magnitude of...   neutral\n",
       "92    93  Ladies and gentlemen, thank you for participat...   neutral\n",
       "\n",
       "[21 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_df_2type_neu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      72.0\n",
       "mean      513.5\n",
       "          ...  \n",
       "75%       543.0\n",
       "max      1826.0\n",
       "Name: text_len, Length: 8, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_df_2type['text_len'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 100   |   vector length: 12\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 100, 12)           19080     \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1200)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 1201      \n",
      "=================================================================\n",
      "Total params: 20,281\n",
      "Trainable params: 20,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.6735 - acc: 0.7895\n",
      "Epoch 2/50\n",
      "57/57 [==============================] - 0s 124us/step - loss: 0.6197 - acc: 0.9474\n",
      "Epoch 3/50\n",
      "57/57 [==============================] - 0s 109us/step - loss: 0.5806 - acc: 0.9474\n",
      "Epoch 4/50\n",
      "57/57 [==============================] - 0s 102us/step - loss: 0.5454 - acc: 0.9474\n",
      "Epoch 5/50\n",
      "57/57 [==============================] - 0s 103us/step - loss: 0.5125 - acc: 0.9474\n",
      "Epoch 6/50\n",
      "57/57 [==============================] - 0s 137us/step - loss: 0.4815 - acc: 0.9474\n",
      "Epoch 7/50\n",
      "57/57 [==============================] - 0s 109us/step - loss: 0.4527 - acc: 0.9474\n",
      "Epoch 8/50\n",
      "57/57 [==============================] - 0s 115us/step - loss: 0.4252 - acc: 0.9474\n",
      "Epoch 9/50\n",
      "57/57 [==============================] - 0s 136us/step - loss: 0.3987 - acc: 0.9474\n",
      "Epoch 10/50\n",
      "57/57 [==============================] - 0s 110us/step - loss: 0.3736 - acc: 0.9474\n",
      "Epoch 11/50\n",
      "57/57 [==============================] - 0s 115us/step - loss: 0.3502 - acc: 0.9474\n",
      "Epoch 12/50\n",
      "57/57 [==============================] - 0s 104us/step - loss: 0.3279 - acc: 0.9474\n",
      "Epoch 13/50\n",
      "57/57 [==============================] - 0s 126us/step - loss: 0.3092 - acc: 0.9474\n",
      "Epoch 14/50\n",
      "57/57 [==============================] - 0s 123us/step - loss: 0.2914 - acc: 0.9474\n",
      "Epoch 15/50\n",
      "57/57 [==============================] - 0s 113us/step - loss: 0.2747 - acc: 0.9474\n",
      "Epoch 16/50\n",
      "57/57 [==============================] - 0s 116us/step - loss: 0.2593 - acc: 0.9474\n",
      "Epoch 17/50\n",
      "57/57 [==============================] - 0s 116us/step - loss: 0.2454 - acc: 0.9474\n",
      "Epoch 18/50\n",
      "57/57 [==============================] - 0s 118us/step - loss: 0.2316 - acc: 0.9474\n",
      "Epoch 19/50\n",
      "57/57 [==============================] - 0s 137us/step - loss: 0.2198 - acc: 0.9474\n",
      "Epoch 20/50\n",
      "57/57 [==============================] - 0s 89us/step - loss: 0.2089 - acc: 0.9474\n",
      "Epoch 21/50\n",
      "57/57 [==============================] - 0s 121us/step - loss: 0.1993 - acc: 0.9474\n",
      "Epoch 22/50\n",
      "57/57 [==============================] - 0s 124us/step - loss: 0.1910 - acc: 0.9474\n",
      "Epoch 23/50\n",
      "57/57 [==============================] - 0s 110us/step - loss: 0.1815 - acc: 0.9474\n",
      "Epoch 24/50\n",
      "57/57 [==============================] - 0s 110us/step - loss: 0.1750 - acc: 0.9474\n",
      "Epoch 25/50\n",
      "57/57 [==============================] - 0s 114us/step - loss: 0.1666 - acc: 0.9474\n",
      "Epoch 26/50\n",
      "57/57 [==============================] - 0s 128us/step - loss: 0.1594 - acc: 0.9474\n",
      "Epoch 27/50\n",
      "57/57 [==============================] - 0s 117us/step - loss: 0.1520 - acc: 0.9474\n",
      "Epoch 28/50\n",
      "57/57 [==============================] - 0s 137us/step - loss: 0.1461 - acc: 0.9474\n",
      "Epoch 29/50\n",
      "57/57 [==============================] - 0s 119us/step - loss: 0.1392 - acc: 0.9474\n",
      "Epoch 30/50\n",
      "57/57 [==============================] - 0s 125us/step - loss: 0.1328 - acc: 0.9474\n",
      "Epoch 31/50\n",
      "57/57 [==============================] - 0s 129us/step - loss: 0.1278 - acc: 0.9474\n",
      "Epoch 32/50\n",
      "57/57 [==============================] - 0s 96us/step - loss: 0.1212 - acc: 0.9474\n",
      "Epoch 33/50\n",
      "57/57 [==============================] - 0s 124us/step - loss: 0.1155 - acc: 0.9474\n",
      "Epoch 34/50\n",
      "57/57 [==============================] - 0s 109us/step - loss: 0.1099 - acc: 0.9474\n",
      "Epoch 35/50\n",
      "57/57 [==============================] - 0s 123us/step - loss: 0.1046 - acc: 0.9474\n",
      "Epoch 36/50\n",
      "57/57 [==============================] - 0s 153us/step - loss: 0.0999 - acc: 0.9474\n",
      "Epoch 37/50\n",
      "57/57 [==============================] - 0s 111us/step - loss: 0.0942 - acc: 0.9474\n",
      "Epoch 38/50\n",
      "57/57 [==============================] - 0s 131us/step - loss: 0.0898 - acc: 0.9649\n",
      "Epoch 39/50\n",
      "57/57 [==============================] - 0s 104us/step - loss: 0.0843 - acc: 0.9649\n",
      "Epoch 40/50\n",
      "57/57 [==============================] - 0s 99us/step - loss: 0.0794 - acc: 0.9649\n",
      "Epoch 41/50\n",
      "57/57 [==============================] - 0s 134us/step - loss: 0.0754 - acc: 0.9649\n",
      "Epoch 42/50\n",
      "57/57 [==============================] - 0s 126us/step - loss: 0.0704 - acc: 0.9649\n",
      "Epoch 43/50\n",
      "57/57 [==============================] - 0s 116us/step - loss: 0.0664 - acc: 0.9649\n",
      "Epoch 44/50\n",
      "57/57 [==============================] - 0s 115us/step - loss: 0.0626 - acc: 0.9825\n",
      "Epoch 45/50\n",
      "57/57 [==============================] - 0s 118us/step - loss: 0.0583 - acc: 0.9825\n",
      "Epoch 46/50\n",
      "57/57 [==============================] - 0s 120us/step - loss: 0.0548 - acc: 0.9825\n",
      "Epoch 47/50\n",
      "57/57 [==============================] - 0s 176us/step - loss: 0.0519 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "57/57 [==============================] - 0s 136us/step - loss: 0.0486 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "57/57 [==============================] - 0s 128us/step - loss: 0.0452 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "57/57 [==============================] - 0s 131us/step - loss: 0.0421 - acc: 1.0000\n",
      "Training Accuracy: 100.000000\n",
      "Testing Accuracy: 93.333334\n",
      "******************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(all_data_df_2type_pos[['text']], all_data_df_2type_pos[['label']], test_size=0.2, random_state=42)\n",
    "X_train_n, X_test_n, y_train_n, y_test_n = train_test_split(all_data_df_2type_neg[['text']], all_data_df_2type_neg[['label']], test_size=0.2, random_state=42)\n",
    "#display(X_train_p, X_test_p, y_train_p, y_test_p)\n",
    "#display(X_train_n, X_test_n, y_train_n, y_test_n)\n",
    "X_train=X_train_p.append(X_train_n).copy().reset_index(drop=True)\n",
    "X_test=X_test_p.append(X_test_n).copy().reset_index(drop=True)\n",
    "y_train=y_train_p.append(y_train_n).copy().reset_index(drop=True)\n",
    "y_test=y_test_p.append(y_test_n).copy().reset_index(drop=True)\n",
    "\n",
    "docs = all_data_df['text'].tolist()\n",
    "max_words = 10000 \n",
    "t = Tokenizer(num_words=max_words)\n",
    "t.fit_on_texts(docs)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "for vector_len in [12]:\n",
    "    for m_len in [100]:\n",
    "        print(\"max length: \"+str(m_len)+\"   |   vector length: \"+str(vector_len))\n",
    "        x_train_doc=create_padded_docs(t,X_train['text'].tolist(),m_len)\n",
    "        x_test_doc=create_padded_docs(t,X_test['text'].tolist(),m_len)\n",
    "        y_train_label=y_train['label'].tolist()\n",
    "        y_test_label=y_test['label'].tolist()\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(vocab_size, vector_len, input_length=m_len))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        # compile the model\n",
    "        model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "        # summarize the model\n",
    "        print(model.summary())\n",
    "        # fit the model\n",
    "        model.fit(x_train_doc, y_train_label, epochs=50)#,validation_split=0.1)\n",
    "        # evaluate the model\n",
    "        loss, accuracy = model.evaluate(x_train_doc, y_train_label, verbose=0)\n",
    "        print('Training Accuracy: %f' % (accuracy*100))\n",
    "        y_train_label_predicted=model.predict(x_train_doc)\n",
    "        y_test_label_predicted=model.predict(x_test_doc)\n",
    "        y_train_label_predicted=[1 if y>=0.5 else 0 for y in y_train_label_predicted]\n",
    "        y_test_label_predicted=[1 if y>=0.5 else 0 for y in y_test_label_predicted]\n",
    "        loss, accuracy = model.evaluate(x_test_doc, y_test_label, verbose=0)\n",
    "        print('Testing Accuracy: %f' % (accuracy*100))\n",
    "        print('***'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 72 entries, 1 to 92\n",
      "Data columns (total 4 columns):\n",
      "text         72 non-null object\n",
      "sentiment    72 non-null object\n",
      "label        72 non-null int64\n",
      "text_len     72 non-null int64\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 2.8+ KB\n"
     ]
    }
   ],
   "source": [
    "all_data_df_2type.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328.8"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1644*0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_neg</th>\n",
       "      <th>predicted_pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_neg</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_pos</th>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          predicted_neg  predicted_pos\n",
       "                                      \n",
       "true_neg              3              0\n",
       "true_pos              0             54"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_neg</th>\n",
       "      <th>predicted_pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_neg</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_pos</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          predicted_neg  predicted_pos\n",
       "                                      \n",
       "true_neg              0              1\n",
       "true_pos              0             14"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_columns=['predicted_neg','predicted_pos']\n",
    "confusion_rows=['true_neg','true_pos']\n",
    "train_confusion_matrix=pd.DataFrame(confusion_matrix(y_train_label, y_train_label_predicted))\n",
    "train_confusion_matrix.columns=confusion_columns\n",
    "train_confusion_matrix['index']=confusion_rows\n",
    "train_confusion_matrix=train_confusion_matrix.set_index('index')\n",
    "train_confusion_matrix.index.name=''\n",
    "\n",
    "test_confusion_matrix=pd.DataFrame(confusion_matrix(y_test_label, y_test_label_predicted))\n",
    "test_confusion_matrix.columns=confusion_columns\n",
    "test_confusion_matrix['index']=confusion_rows\n",
    "test_confusion_matrix=test_confusion_matrix.set_index('index')\n",
    "test_confusion_matrix.index.name=''\n",
    "\n",
    "display(train_confusion_matrix)\n",
    "display(test_confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "imdb_dir = 'aclImdb'\n",
    "def load_imdb_dir(imdb_dir,sub_folder):\n",
    "    train_dir = os.path.join(imdb_dir,sub_folder)\n",
    "    labels = []\n",
    "    texts = []\n",
    "    for label_type in ['neg', 'pos']:\n",
    "        dir_name = os.path.join(train_dir, label_type)\n",
    "        for fname in os.listdir(dir_name):\n",
    "            if fname[-4:] == '.txt':\n",
    "                f = open(os.path.join(dir_name, fname))\n",
    "                texts.append(f.read())\n",
    "                f.close()\n",
    "                if label_type == 'neg':\n",
    "                    labels.append(0)\n",
    "                else:\n",
    "                    labels.append(1)\n",
    "    return texts,labels\n",
    "x_train_imdb_raw,y_train_imdb_raw=load_imdb_dir(imdb_dir,\"train\")\n",
    "x_test_imdb_raw,y_test_imdb_raw=load_imdb_dir(imdb_dir,\"test\")\n",
    "\n",
    "\n",
    "x_train_imdb_raw_tot=x_train_imdb_raw+x_test_imdb_raw\n",
    "y_train_imdb_raw_tot=y_train_imdb_raw+y_test_imdb_raw\n",
    "\n",
    "max_words = 10000 \n",
    "docs = all_data_df_2type['text'].tolist()+x_train_imdb_raw_tot\n",
    "t = Tokenizer(num_words=max_words)\n",
    "t.fit_on_texts(docs)\n",
    "vocab_size = len(t.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 100   |   vector length: 12\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 100, 12)           1491816   \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1200)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 1201      \n",
      "=================================================================\n",
      "Total params: 1,493,017\n",
      "Trainable params: 1,493,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-654e1fa1aaf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_doc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;31m# evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_doc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2669\u001b[0m                                 \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2670\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2671\u001b[0;31m                                 session)\n\u001b[0m\u001b[1;32m   2672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_make_callable\u001b[0;34m(self, feed_arrays, feed_symbols, symbol_vals, session)\u001b[0m\n\u001b[1;32m   2621\u001b[0m             \u001b[0mcallable_opts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2622\u001b[0m         \u001b[0;31m# Create callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2623\u001b[0;31m         \u001b[0mcallable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable_from_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallable_opts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2624\u001b[0m         \u001b[0;31m# Cache parameters corresponding to the generated callable, so that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2625\u001b[0m         \u001b[0;31m# we can detect future mismatches and refresh the callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_make_callable_from_options\u001b[0;34m(self, callable_options)\u001b[0m\n\u001b[1;32m   1469\u001b[0m     \"\"\"\n\u001b[1;32m   1470\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1471\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mBaseSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallable_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session, callable_options)\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m           self._handle = tf_session.TF_SessionMakeCallable(\n\u001b[0;32m-> 1425\u001b[0;31m               session._session, options_ptr, status)\n\u001b[0m\u001b[1;32m   1426\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m         \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_DeleteBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for vector_len in [12]:\n",
    "    for m_len in [100]:\n",
    "        print(\"max length: \"+str(m_len)+\"   |   vector length: \"+str(vector_len))\n",
    "        x_train_doc=create_padded_docs(t,x_train_imdb_raw_tot,m_len)\n",
    "        x_test_doc=create_padded_docs(t,all_data_df_2type['text'].tolist(),m_len)\n",
    "        y_train_label=y_train_imdb_raw_tot\n",
    "        y_test_label=all_data_df_2type['label'].tolist()\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(vocab_size, vector_len, input_length=m_len))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        # compile the model\n",
    "        model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "        # summarize the model\n",
    "        print(model.summary())\n",
    "        # fit the model\n",
    "        model.fit(x_train_doc, y_train_label, epochs=5,validation_split=0.1)\n",
    "        # evaluate the model\n",
    "        loss, accuracy = model.evaluate(x_train_doc, y_train_label, verbose=0)\n",
    "        print('Training Accuracy: %f' % (accuracy*100))\n",
    "        y_train_label_predicted=model.predict(x_train_doc)\n",
    "        y_test_label_predicted=model.predict(x_test_doc)\n",
    "        y_train_label_predicted=[1 if y>=0.5 else 0 for y in y_train_label_predicted]\n",
    "        y_test_label_predicted=[1 if y>=0.5 else 0 for y in y_test_label_predicted]\n",
    "        loss, accuracy = model.evaluate(x_test_doc, y_test_label, verbose=0)\n",
    "        print('Testing Accuracy: %f' % (accuracy*100))\n",
    "        print('***'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_df_2type['y_predicted']=y_test_label_predicted\n",
    "all_data_df_2type['label_predicted']=all_data_df_2type['y_predicted'].apply(lambda x: 'positive' if x==1 else \"negative\")\n",
    "all_data_df_2type_neu['label_predicted']='neutral'\n",
    "all_data_df_2type=all_data_df_2type.drop('y_predicted',axis=1)\n",
    "ge_df=all_data_df_2type.append(all_data_df_2type_neu)\n",
    "ge_df.to_json('GE_predicted.json',orient='split')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output='''{\"text\":{'''\n",
    "senti='''},\"sentiment\":{'''\n",
    "for index, row in ge_df.iterrows():\n",
    "    output+='''\"'''+str(index)+'''\":\"'''+row['text']+'''\",'''\n",
    "    senti+='''\"'''+str(index)+'''\":\"'''+row['label_predicted']+'''\",'''\n",
    "output=output[:-1]\n",
    "senti=senti[:-1]+'}}'\n",
    "out_senti=output+senti\n",
    "out_senti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = open(\"GE_predicted.json\", \"w\")\n",
    "text_file.write(out_senti)\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_columns=['predicted_neg','predicted_pos']\n",
    "confusion_rows=['true_neg','true_pos']\n",
    "train_confusion_matrix=pd.DataFrame(confusion_matrix(y_train_label, y_train_label_predicted))\n",
    "train_confusion_matrix.columns=confusion_columns\n",
    "train_confusion_matrix['index']=confusion_rows\n",
    "train_confusion_matrix=train_confusion_matrix.set_index('index')\n",
    "train_confusion_matrix.index.name=''\n",
    "\n",
    "test_confusion_matrix=pd.DataFrame(confusion_matrix(y_test_label, y_test_label_predicted))\n",
    "test_confusion_matrix.columns=confusion_columns\n",
    "test_confusion_matrix['index']=confusion_rows\n",
    "test_confusion_matrix=test_confusion_matrix.set_index('index')\n",
    "test_confusion_matrix.index.name=''\n",
    "\n",
    "display(train_confusion_matrix)\n",
    "display(test_confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The URL shouldn't start or end with curly brackets or quotes. Be sure to remove any {} and \" characters surrounding your URL",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-d42a6fabdab0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0musername\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'{username}'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'{password}'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'{url}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/watson_developer_cloud/natural_language_understanding_v1.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, version, url, username, password, iam_apikey, iam_access_token, iam_url)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0miam_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miam_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0muse_vcap_services\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             display_name='Natural Language Understanding')\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/watson_developer_cloud/watson_service.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vcap_services_name, url, username, password, use_vcap_services, api_key, iam_apikey, iam_access_token, iam_url, display_name)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_has_bad_first_or_last_char\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             raise ValueError('The URL shouldn\\'t start or end with curly brackets or quotes. '\n\u001b[0m\u001b[1;32m    251\u001b[0m                              'Be sure to remove any {} and \\\" characters surrounding your URL')\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The URL shouldn't start or end with curly brackets or quotes. Be sure to remove any {} and \" characters surrounding your URL"
     ]
    }
   ],
   "source": [
    "from watson_developer_cloud import NaturalLanguageUnderstandingV1\n",
    "\n",
    "natural_language_understanding = NaturalLanguageUnderstandingV1(\n",
    "    version='{version}',\n",
    "    username='{username}',\n",
    "    password='{password}',\n",
    "    url='{url}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from watson_developer_cloud import NaturalLanguageUnderstandingV1\n",
    "from watson_developer_cloud.natural_language_understanding_v1 \\\n",
    "    import Features, EntitiesOptions, KeywordsOptions\n",
    "\n",
    "naturalLanguageUnderstanding = NaturalLanguageUnderstandingV1(\n",
    "    version='2018-11-16',\n",
    "    username='wenjun song',\n",
    "    password='Ilove22*',\n",
    "    #iam_apikey='OAbro0YFtCjxCW5Z8EiHjBcKGHtm2qpl30rvUw9yDZJ1',\n",
    "    url='https://gateway-tok.watsonplatform.net/natural-language-understanding/api')\n",
    "\n",
    "response = naturalLanguageUnderstanding.analyze(\n",
    "    text=all_data_df_2type['text'].tolist()[0],\n",
    "    features=Features(\n",
    "        entities=EntitiesOptions(emotion=True, sentiment=True, limit=2),\n",
    "        keywords=KeywordsOptions(emotion=True, sentiment=True,\n",
    "                                 limit=2))).get_result()\n",
    "\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: google-api-python-client in /Users/lovelife/anaconda3/lib/python3.6/site-packages (1.7.8)\n",
      "Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-python-client) (0.12.1)\n",
      "Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-python-client) (3.0.0)\n",
      "Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-python-client) (1.11.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-python-client) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-python-client) (0.0.3)\n",
      "Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth>=1.4.1->google-api-python-client) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.4)\n",
      "Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth>=1.4.1->google-api-python-client) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.5)\n",
      "Searching for google-api-python-client\n",
      "Reading https://pypi.org/simple/google-api-python-client/\n",
      "Downloading https://files.pythonhosted.org/packages/55/e9/e8fb2e3a031cb69b9524b80a92b126665d9a17421700a219555e3233ab6a/google_api_python_client-1.7.8-py3-none-any.whl#sha256=937eabdc3940977f712fa648a096a5142766b6d0a0f58bc603e2ac0687397ef0\n",
      "Best match: google-api-python-client 1.7.8\n",
      "Processing google_api_python_client-1.7.8-py3-none-any.whl\n",
      "removing '/Users/lovelife/anaconda3/lib/python3.6/site-packages/google_api_python_client-1.7.8-py3.6.egg' (and everything under it)\n",
      "Installing google_api_python_client-1.7.8-py3-none-any.whl to /Users/lovelife/anaconda3/lib/python3.6/site-packages\n",
      "writing requirements to /Users/lovelife/anaconda3/lib/python3.6/site-packages/google_api_python_client-1.7.8-py3.6.egg/EGG-INFO/requires.txt\n",
      "google-api-python-client 1.7.8 is already the active version in easy-install.pth\n",
      "\n",
      "Installed /Users/lovelife/anaconda3/lib/python3.6/site-packages/google_api_python_client-1.7.8-py3.6.egg\n",
      "Processing dependencies for google-api-python-client\n",
      "Finished processing dependencies for google-api-python-client\n",
      "Requirement already satisfied: google-cloud-storage in /Users/lovelife/anaconda3/lib/python3.6/site-packages (1.14.0)\n",
      "Requirement already satisfied: google-resumable-media>=0.3.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-cloud-storage) (0.3.2)\n",
      "Requirement already satisfied: google-api-core<2.0.0dev,>=1.6.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-cloud-storage) (1.8.1)\n",
      "Requirement already satisfied: google-cloud-core<0.30dev,>=0.29.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-cloud-storage) (0.29.1)\n",
      "Requirement already satisfied: six in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-resumable-media>=0.3.1->google-cloud-storage) (1.11.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage) (2.21.0)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage) (3.6.1)\n",
      "Requirement already satisfied: googleapis-common-protos!=1.5.4,<2.0dev,>=1.5.3 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage) (1.5.8)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=0.4.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage) (1.6.3)\n",
      "Requirement already satisfied: setuptools>=34.0.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage) (39.1.0)\n",
      "Requirement already satisfied: pytz in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage) (2018.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage) (1.22)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage) (2.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage) (2018.11.29)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage) (3.0.4)\n",
      "Requirement already satisfied: cachetools>=2.0.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage) (3.1.0)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage) (0.2.4)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from rsa>=3.1.4->google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage) (0.4.5)\n",
      "Requirement already satisfied: google-cloud-language in /Users/lovelife/anaconda3/lib/python3.6/site-packages (1.1.1)\n",
      "Requirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.6.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-cloud-language) (1.8.1)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (3.6.1)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (2.21.0)\n",
      "Requirement already satisfied: setuptools>=34.0.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (39.1.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (1.11.0)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=0.4.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (1.6.3)\n",
      "Requirement already satisfied: pytz in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (2018.4)\n",
      "Requirement already satisfied: googleapis-common-protos!=1.5.4,<2.0dev,>=1.5.3 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (1.5.8)\n",
      "Requirement already satisfied: grpcio>=1.8.2; extra == \"grpc\" in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (1.16.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (3.0.4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (2018.11.29)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (2.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (0.2.4)\n",
      "Requirement already satisfied: cachetools>=2.0.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (3.1.0)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (4.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (0.4.5)\n",
      "Requirement already up-to-date: google-cloud-language in /Users/lovelife/anaconda3/lib/python3.6/site-packages (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: google-api-core[grpc]<2.0.0dev,>=1.6.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-cloud-language) (1.8.1)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2.0dev,>=0.4.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.4.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (3.6.1)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=34.0.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (39.1.0)\n",
      "Requirement already satisfied, skipping upgrade: googleapis-common-protos!=1.5.4,<2.0dev,>=1.5.3 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (1.5.8)\n",
      "Requirement already satisfied, skipping upgrade: requests<3.0.0dev,>=2.18.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (2.21.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (1.11.0)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (2018.4)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.2; extra == \"grpc\" in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (1.16.1)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (0.2.4)\n",
      "Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (2018.11.29)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (2.6)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (1.22)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (0.4.5)\n",
      "Requirement already satisfied: google-auth-oauthlib in /Users/lovelife/anaconda3/lib/python3.6/site-packages (0.2.0)\n",
      "Requirement already satisfied: google-auth in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth-oauthlib) (1.6.3)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth-oauthlib) (1.2.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth->google-auth-oauthlib) (1.11.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth->google-auth-oauthlib) (0.2.4)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth->google-auth-oauthlib) (4.0)\n",
      "Requirement already satisfied: cachetools>=2.0.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth->google-auth-oauthlib) (3.1.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.0.1)\n",
      "Requirement already satisfied: requests>=2.0.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (2.21.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth->google-auth-oauthlib) (0.4.5)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (2.6)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (2018.11.29)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade google-api-python-client\n",
    "!easy_install --upgrade google-api-python-client\n",
    "! pip install google-cloud-storage\n",
    "! pip install google-cloud-language\n",
    "! pip install --upgrade google-cloud-language\n",
    "import argparse\n",
    "import google.cloud\n",
    "from google.cloud import language\n",
    "from google.cloud import storage\n",
    "from google.cloud.language import enums\n",
    "from google.cloud.language import types\n",
    "import os\n",
    "from google.oauth2 import service_account\n",
    "!pip install google-auth-oauthlib\n",
    "from google_auth_oauthlib.flow import Flow\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "document_sentiment {\n",
       "  magnitude: 2.200000047683716\n",
       "  score: 0.5\n",
       "}\n",
       "language: \"en\"\n",
       "sentences {\n",
       "  text {\n",
       "    content: \"We think it was a, Q4 in particular was a great quarter for customers that retail, there is a lot of strength in the retail part of the businesses, the teams here had done a great job, planning, preparing and then executing on the quarter.\"\n",
       "    begin_offset: -1\n",
       "  }\n",
       "  sentiment {\n",
       "    magnitude: 0.699999988079071\n",
       "    score: 0.699999988079071\n",
       "  }\n",
       "}\n",
       "sentences {\n",
       "  text {\n",
       "    content: \"AWS maintained a very strong growth rate and continued to deliver for customers.\"\n",
       "    begin_offset: -1\n",
       "  }\n",
       "  sentiment {\n",
       "    magnitude: 0.20000000298023224\n",
       "    score: 0.20000000298023224\n",
       "  }\n",
       "}\n",
       "sentences {\n",
       "  text {\n",
       "    content: \"We had a great Reinvent Conference in the quarter.\"\n",
       "    begin_offset: -1\n",
       "  }\n",
       "  sentiment {\n",
       "    magnitude: 0.5\n",
       "    score: 0.5\n",
       "  }\n",
       "}\n",
       "sentences {\n",
       "  text {\n",
       "    content: \"So we feel good about the growth in the quarter and also the total revenue and income.\"\n",
       "    begin_offset: -1\n",
       "  }\n",
       "  sentiment {\n",
       "    magnitude: 0.699999988079071\n",
       "    score: 0.699999988079071\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cred_file_loc = r'dogwood-dryad-235122-9721a66a61c1.json'\n",
    "cred = service_account.Credentials.from_service_account_file(cred_file_loc)\n",
    "Client = language.LanguageServiceClient(credentials=cred)\n",
    "paragraphs = all_data_df['text'].tolist()\n",
    "results = []\n",
    "for paragraph in paragraphs:\n",
    "    document = types.Document(content=paragraph, type=enums.Document.Type.PLAIN_TEXT)\n",
    "    result = Client.analyze_sentiment(document=document)\n",
    "    results.append(result)\n",
    "\n",
    "results[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_neg</th>\n",
       "      <th>predicted_neutral</th>\n",
       "      <th>predicted_pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_neg</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_neutral</th>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_pos</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              predicted_neg  predicted_neutral  predicted_pos\n",
       "                                                             \n",
       "true_neg                  1                  4              0\n",
       "true_neutral              3                 25              5\n",
       "true_pos                  0                  7              9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def classify_google(x):\n",
    "    if x['score']<=-0.10:\n",
    "        return 'negative'\n",
    "    elif x['score']>-0.10 and (x['score']<0.25):\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'positive'\n",
    "\n",
    "magnitudes=[]\n",
    "scores=[]\n",
    "for i in range(len(results)):\n",
    "    magnitudes.append(results[i].document_sentiment.magnitude)\n",
    "    scores.append(results[i].document_sentiment.score)\n",
    "google_sentiment=pd.DataFrame({'magnitude':magnitudes,'score':scores})\n",
    "google_sentiment['label_goog']=google_sentiment.apply(classify_google,axis=1)\n",
    "google_merged=pd.concat([all_data_df,google_sentiment],axis=1)\n",
    "test_confusion_matrix=pd.DataFrame(confusion_matrix(google_merged['sentiment'].tolist(), google_merged['label_goog'].tolist()))\n",
    "test_confusion_matrix.columns=confusion_columns=['predicted_neg','predicted_neutral','predicted_pos']\n",
    "test_confusion_matrix['index']=['true_neg','true_neutral','true_pos']\n",
    "test_confusion_matrix=test_confusion_matrix.set_index('index')\n",
    "test_confusion_matrix.index.name=''\n",
    "\n",
    "display(test_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4811435523114355"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(20+466+305)/1644"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in all_data_df.iterrows():\n",
    "    text_file = open(\"Amazon/text_\"+str(index)+\".txt\", \"w\")\n",
    "    text_file.write(row['text'])\n",
    "    text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>mixed</th>\n",
       "      <th>label_amazon_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>0.008</td>\n",
       "      <td>2.155e-01</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.022</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.135</td>\n",
       "      <td>5.293e-04</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.002</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>0.340</td>\n",
       "      <td>3.178e-02</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.545</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1425</th>\n",
       "      <td>0.058</td>\n",
       "      <td>3.285e-02</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.007</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1644 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      positive   negative  neutral  mixed label_amazon_predicted\n",
       "985      0.008  2.155e-01    0.754  0.022                neutral\n",
       "437      0.135  5.293e-04    0.862  0.002                neutral\n",
       "...        ...        ...      ...    ...                    ...\n",
       "1638     0.340  3.178e-02    0.083  0.545               positive\n",
       "1425     0.058  3.285e-02    0.902  0.007                neutral\n",
       "\n",
       "[1644 rows x 5 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_predict=pd.read_csv('amazon_prediction.csv')\n",
    "amazon_predict['MyId']=amazon_predict['imagelocation'].apply(lambda x: int(x.split('_')[1].split('.')[0]))\n",
    "amazon_predict=amazon_predict.sort_values(['MyId'])\n",
    "amazon_predict=amazon_predict[['sentiment','positive','negative','neutral','mixed']]\n",
    "amazon_predict['label_amazon_predicted']=amazon_predict['sentiment'].apply(lambda x: x.lower())\n",
    "amazon_predict['label_amazon_predicted']=amazon_predict['label_amazon_predicted'].apply(lambda x: 'positive' if x=='mixed' else x)\n",
    "amazon_predict=amazon_predict.drop('sentiment',axis=1)\n",
    "amazon_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_neg</th>\n",
       "      <th>predicted_neutral</th>\n",
       "      <th>predicted_pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_neg</th>\n",
       "      <td>12</td>\n",
       "      <td>115</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_neutral</th>\n",
       "      <td>42</td>\n",
       "      <td>553</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_pos</th>\n",
       "      <td>41</td>\n",
       "      <td>524</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              predicted_neg  predicted_neutral  predicted_pos\n",
       "                                                             \n",
       "true_neg                 12                115             28\n",
       "true_neutral             42                553            240\n",
       "true_pos                 41                524             89"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "amzn_merged=pd.concat([all_data_df,amazon_predict],axis=1)\n",
    "test_confusion_matrix=pd.DataFrame(confusion_matrix(amzn_merged['sentiment'].tolist(), amzn_merged['label_amazon_predicted'].tolist()))\n",
    "test_confusion_matrix.columns=confusion_columns=['predicted_neg','predicted_neutral','predicted_pos']\n",
    "test_confusion_matrix['index']=['true_neg','true_neutral','true_pos']\n",
    "test_confusion_matrix=test_confusion_matrix.set_index('index')\n",
    "test_confusion_matrix.index.name=''\n",
    "\n",
    "display(test_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>magnitude</th>\n",
       "      <th>score</th>\n",
       "      <th>label_goog</th>\n",
       "      <th>weighted_score_goog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Could you catch us up on your latest thinking ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>We continue to ramp up the activities for the ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>98</td>\n",
       "      <td>And so it's -- that one is a little bit toughe...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>99</td>\n",
       "      <td>Thanks, Simeon. Rob, next question please?</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1644 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                               text sentiment  \\\n",
       "0        1  Could you catch us up on your latest thinking ...   neutral   \n",
       "1       10  We continue to ramp up the activities for the ...   neutral   \n",
       "...    ...                                                ...       ...   \n",
       "1642    98  And so it's -- that one is a little bit toughe...  positive   \n",
       "1643    99         Thanks, Simeon. Rob, next question please?   neutral   \n",
       "\n",
       "      magnitude  score label_goog  weighted_score_goog  \n",
       "0           0.9   -0.1   negative               -0.029  \n",
       "1           2.4    0.4   positive                0.314  \n",
       "...         ...    ...        ...                  ...  \n",
       "1642        0.8    0.4   positive                0.105  \n",
       "1643        0.1    0.0    neutral                0.000  \n",
       "\n",
       "[1644 rows x 7 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_merged_p4=google_merged.copy()\n",
    "google_merged_p4['weighted_score_goog']=google_merged_p4['magnitude']*google_merged_p4['score']#[['']]\n",
    "mag=google_merged_p4['weighted_score_goog'].max()-google_merged_p4['weighted_score_goog'].min()\n",
    "google_merged_p4['weighted_score_goog']=google_merged_p4['weighted_score_goog']/(0.5*mag)\n",
    "google_merged_p4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>mixed</th>\n",
       "      <th>label_amazon_predicted</th>\n",
       "      <th>weighted_score_amzn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>0.008</td>\n",
       "      <td>2.155e-01</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.022</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.135</td>\n",
       "      <td>5.293e-04</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.002</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>0.340</td>\n",
       "      <td>3.178e-02</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.545</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1425</th>\n",
       "      <td>0.058</td>\n",
       "      <td>3.285e-02</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.007</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1644 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      positive   negative  neutral  mixed label_amazon_predicted  \\\n",
       "985      0.008  2.155e-01    0.754  0.022                neutral   \n",
       "437      0.135  5.293e-04    0.862  0.002                neutral   \n",
       "...        ...        ...      ...    ...                    ...   \n",
       "1638     0.340  3.178e-02    0.083  0.545               positive   \n",
       "1425     0.058  3.285e-02    0.902  0.007                neutral   \n",
       "\n",
       "      weighted_score_amzn  \n",
       "985                  0.00  \n",
       "437                  0.00  \n",
       "...                   ...  \n",
       "1638                 0.17  \n",
       "1425                 0.00  \n",
       "\n",
       "[1644 rows x 6 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_predict_p4=amazon_predict.copy()\n",
    "#amazon_predict_p4.ix['combined_score','label_amazon_predicted']\n",
    "amazon_predict_p4.loc[amazon_predict_p4['label_amazon_predicted']=='positive', 'weighted_score_amzn'] =amazon_predict_p4.loc[amazon_predict_p4['label_amazon_predicted']=='positive', 'positive']\n",
    "amazon_predict_p4.loc[amazon_predict_p4['label_amazon_predicted']=='negative', 'weighted_score_amzn'] =-amazon_predict_p4.loc[amazon_predict_p4['label_amazon_predicted']=='negative', 'negative']\n",
    "amazon_predict_p4.loc[amazon_predict_p4['label_amazon_predicted'].isin(['neutral','mixed']), 'weighted_score_amzn'] =0\n",
    "mag=amazon_predict_p4['weighted_score_amzn'].max()-amazon_predict_p4['weighted_score_amzn'].min()\n",
    "amazon_predict_p4['weighted_score_amzn']=amazon_predict_p4['weighted_score_amzn']/(mag)\n",
    "amazon_predict_p4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mircro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_neg</th>\n",
       "      <th>predicted_neutral</th>\n",
       "      <th>predicted_pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_neg</th>\n",
       "      <td>23</td>\n",
       "      <td>98</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_neutral</th>\n",
       "      <td>51</td>\n",
       "      <td>517</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_pos</th>\n",
       "      <td>51</td>\n",
       "      <td>358</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              predicted_neg  predicted_neutral  predicted_pos\n",
       "                                                             \n",
       "true_neg                 23                 98             34\n",
       "true_neutral             51                517            267\n",
       "true_pos                 51                358            245"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def classify_combined_score(x):\n",
    "    if x>=0.1:\n",
    "        return 'positive'\n",
    "    elif x>-0.01 and x<0.10:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'negative'\n",
    "all_merged=pd.concat([google_merged_p4[['text','sentiment','weighted_score_goog']],amazon_predict_p4[['weighted_score_amzn']]],axis=1)\n",
    "all_merged['combined_score']=all_merged[['weighted_score_goog','weighted_score_amzn']].mean(axis=1)\n",
    "all_merged['combined_sentiment']=all_merged['combined_score'].apply(classify_combined_score)\n",
    "all_merged.groupby(['combined_sentiment'])[['text']].count()\n",
    "test_confusion_matrix=pd.DataFrame(confusion_matrix(all_merged['sentiment'].tolist(), all_merged['combined_sentiment'].tolist()))\n",
    "test_confusion_matrix.columns=confusion_columns=['predicted_neg','predicted_neutral','predicted_pos']\n",
    "test_confusion_matrix['index']=['true_neg','true_neutral','true_pos']\n",
    "test_confusion_matrix=test_confusion_matrix.set_index('index')\n",
    "test_confusion_matrix.index.name=''\n",
    "\n",
    "display(test_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install auto-sklearn\n",
    "! pip install -U scikit-learn\n",
    "! pip install numpy\n",
    "! pip install -U numpy\n",
    "! pip install --upgrade pip"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
