{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from IPython.display import display\n",
    "pd.set_option('display.max_rows',5)\n",
    "pd.set_option('precision',3)\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:100% !important;}</style>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_df(file_name):\n",
    "    #print(file_name)\n",
    "    with open(file_name, encoding='utf-8', errors='ignore') as f:\n",
    "        json_1 = json.load(f)\n",
    "    dict_1 = dict(json_1)\n",
    "    df_1 = pd.DataFrame.from_dict(dict_1)\n",
    "    return df_1\n",
    "def create_padded_docs(t,doc,max_length = 500):\n",
    "    encoded_docs = t.texts_to_sequences(doc)\n",
    "    #print(encoded_docs)\n",
    "    padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "    #print(padded_docs)\n",
    "    return padded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Greetings and welcome to the Microsoft Fiscal ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>With that as a backdrop, I want to highlight k...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>98</td>\n",
       "      <td>Thanks, Mark. Operator, can we please move to ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>99</td>\n",
       "      <td>The next question is coming from the line of K...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                               text sentiment   Id\n",
       "0       1  Greetings and welcome to the Microsoft Fiscal ...   neutral    0\n",
       "1      10  With that as a backdrop, I want to highlight k...  positive    1\n",
       "..    ...                                                ...       ...  ...\n",
       "176    98  Thanks, Mark. Operator, can we please move to ...   neutral  176\n",
       "177    99  The next question is coming from the line of K...   neutral  177\n",
       "\n",
       "[178 rows x 4 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_df['Id']=all_data_df.index\n",
    "all_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'all_group_data.pickle'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(all_data_df,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neutral' 'negative' 'positive']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Could you catch us up on your latest thinking ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>We continue to ramp up the activities for the ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>And so it's -- that one is a little bit toughe...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Thanks, Simeon. Rob, next question please?</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1644 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text sentiment\n",
       "1   Could you catch us up on your latest thinking ...   neutral\n",
       "10  We continue to ramp up the activities for the ...   neutral\n",
       "..                                                ...       ...\n",
       "98  And so it's -- that one is a little bit toughe...  positive\n",
       "99         Thanks, Simeon. Rob, next question please?   neutral\n",
       "\n",
       "[1644 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neutral' 'negative' 'positive']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "      <th>text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Could you catch us up on your latest thinking ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>We continue to ramp up the activities for the ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>And so it's -- that one is a little bit toughe...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Thanks, Simeon. Rob, next question please?</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1644 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text sentiment  label  \\\n",
       "1   Could you catch us up on your latest thinking ...   neutral      1   \n",
       "10  We continue to ramp up the activities for the ...   neutral      1   \n",
       "..                                                ...       ...    ...   \n",
       "98  And so it's -- that one is a little bit toughe...  positive      2   \n",
       "99         Thanks, Simeon. Rob, next question please?   neutral      1   \n",
       "\n",
       "    text_len  \n",
       "1        305  \n",
       "10       560  \n",
       "..       ...  \n",
       "98       224  \n",
       "99        42  \n",
       "\n",
       "[1644 rows x 4 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data=[]\n",
    "for file in os.listdir():\n",
    "    \n",
    "    #if file == \"Team1_Google.json\":\n",
    "    #if file == \"Team2_Amazon.json\":\n",
    "    #if file == \"Team3_Facebook.json\":\n",
    "    #if file == \"Team4_Netflix.json\":    \n",
    "    #if file == \"Team5_Microsoft.json\":\n",
    "    #if file == \"Team6_Tesla.json\":\n",
    "    #if file == \"Team7_Walmart.json\":\n",
    "    #if file == \"Team8_Kroger.json\":\n",
    "    #if file == \"Team9_GoldmanSachs.json\":\n",
    "    #if file == \"Team10_NVIDIA.json\":\n",
    "    #if file == \"Team11_Boeing.json\":\n",
    "    #if file == \"Team12_Chevron.json\":\n",
    "\n",
    "    if file.startswith(\"Team\") and file.endswith(\".json\"):\n",
    "        df=json_to_df(file)\n",
    "        df.columns=['text','sentiment']\n",
    "        df['sentiment']=df['sentiment'].apply(lambda x: x.lower())\n",
    "        if sum(df.isnull().any(axis=1))>0:\n",
    "            display(df[pd.isnull(df['Sentiment'])])\n",
    "        else:\n",
    "            all_data.append(df)\n",
    "all_data_df=pd.concat(all_data)\n",
    "all_data_df['sentiment']=all_data_df['sentiment'].apply(lambda x: 'neutral' if x in ['neutra;','negetive','neural'] else x)\n",
    "all_data_df['sentiment']=all_data_df['sentiment'].apply(lambda x: 'positive' if x in ['postive','positivem'] else x)\n",
    "print(all_data_df['sentiment'].unique())\n",
    "display(all_data_df)\n",
    "all_data_df_2type=all_data_df[all_data_df['sentiment'].isin(['positive','negative'])].copy()\n",
    "all_data_df_2type=all_data_df.copy()\n",
    "\n",
    "all_data_df=all_data_df.reset_index()\n",
    "def encode(x):\n",
    "    if x=='positive':\n",
    "        return 2\n",
    "    elif x=='neutral':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "#all_data_df_2type_neu=all_data_df[~all_data_df['sentiment'].isin(['positive','negative'])].copy()\n",
    "all_data_df_2type['label']=all_data_df_2type['sentiment'].apply(lambda x:encode(x))\n",
    "all_data_df_2type['text_len']=all_data_df_2type['text'].apply(lambda x: len(x))\n",
    "all_data_df_2type_pos=all_data_df_2type[all_data_df_2type['sentiment']=='positive'].copy()\n",
    "all_data_df_2type_neg=all_data_df_2type[all_data_df_2type['sentiment']=='negative'].copy()\n",
    "all_data_df_2type_neutral=all_data_df_2type[all_data_df_2type['sentiment']=='neutral'].copy()\n",
    "print(all_data_df['sentiment'].unique())\n",
    "all_data_df_2type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "      <th>text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Could you catch us up on your latest thinking ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>We continue to ramp up the activities for the ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>So as we step back and we looked at everything...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Thanks, Simeon. Rob, next question please?</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>835 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text sentiment  label  \\\n",
       "1   Could you catch us up on your latest thinking ...   neutral      1   \n",
       "10  We continue to ramp up the activities for the ...   neutral      1   \n",
       "..                                                ...       ...    ...   \n",
       "97  So as we step back and we looked at everything...   neutral      1   \n",
       "99         Thanks, Simeon. Rob, next question please?   neutral      1   \n",
       "\n",
       "    text_len  \n",
       "1        305  \n",
       "10       560  \n",
       "..       ...  \n",
       "97       169  \n",
       "99        42  \n",
       "\n",
       "[835 rows x 4 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_df_2type_neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "      <th>text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Yes, it was sort of just how the conversation ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>No. Thanks. We got it.</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Thanks. Good morning, guys. And thanks for doi...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>The minority of the miss that was more operati...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text sentiment  label  \\\n",
       "100  Yes, it was sort of just how the conversation ...  negative      0   \n",
       "66                              No. Thanks. We got it.  negative      0   \n",
       "..                                                 ...       ...    ...   \n",
       "89   Thanks. Good morning, guys. And thanks for doi...  negative      0   \n",
       "91   The minority of the miss that was more operati...  negative      0   \n",
       "\n",
       "     text_len  \n",
       "100       310  \n",
       "66         22  \n",
       "..        ...  \n",
       "89        311  \n",
       "91        388  \n",
       "\n",
       "[155 rows x 4 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_df_2type_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>During this call, we may discuss certain non-G...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>Our guidance incorporates the order trends tha...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>8</td>\n",
       "      <td>Hello, and welcome to our Q4 2018 financial re...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>9</td>\n",
       "      <td>Our comments and responses to your questions r...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text sentiment\n",
       "1     10  During this call, we may discuss certain non-G...   neutral\n",
       "2     11  Our guidance incorporates the order trends tha...   neutral\n",
       "..   ...                                                ...       ...\n",
       "52     8  Hello, and welcome to our Q4 2018 financial re...   neutral\n",
       "53     9  Our comments and responses to your questions r...   neutral\n",
       "\n",
       "[33 rows x 3 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_df_2type_neu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    label\n",
       "0       2\n",
       "1       2\n",
       "..    ...\n",
       "40      1\n",
       "41      1\n",
       "\n",
       "[42 rows x 1 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train['label'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 100   |   vector length: 12\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, 100, 12)           76524     \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 1200)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 3)                 3603      \n",
      "=================================================================\n",
      "Total params: 80,127\n",
      "Trainable params: 80,127\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "1315/1315 [==============================] - 0s 290us/step - loss: 0.9240 - acc: 0.5460\n",
      "Epoch 2/50\n",
      "1315/1315 [==============================] - 0s 42us/step - loss: 0.8076 - acc: 0.6654\n",
      "Epoch 3/50\n",
      "1315/1315 [==============================] - 0s 44us/step - loss: 0.7537 - acc: 0.7042\n",
      "Epoch 4/50\n",
      "1315/1315 [==============================] - 0s 40us/step - loss: 0.7032 - acc: 0.7293\n",
      "Epoch 5/50\n",
      "1315/1315 [==============================] - 0s 41us/step - loss: 0.6486 - acc: 0.7764\n",
      "Epoch 6/50\n",
      "1315/1315 [==============================] - 0s 43us/step - loss: 0.5868 - acc: 0.8023\n",
      "Epoch 7/50\n",
      "1315/1315 [==============================] - 0s 46us/step - loss: 0.5261 - acc: 0.8297\n",
      "Epoch 8/50\n",
      "1315/1315 [==============================] - 0s 48us/step - loss: 0.4658 - acc: 0.8510\n",
      "Epoch 9/50\n",
      "1315/1315 [==============================] - 0s 49us/step - loss: 0.4079 - acc: 0.8738\n",
      "Epoch 10/50\n",
      "1315/1315 [==============================] - 0s 44us/step - loss: 0.3543 - acc: 0.9095\n",
      "Epoch 11/50\n",
      "1315/1315 [==============================] - 0s 46us/step - loss: 0.3033 - acc: 0.9293\n",
      "Epoch 12/50\n",
      "1315/1315 [==============================] - 0s 46us/step - loss: 0.2594 - acc: 0.9430\n",
      "Epoch 13/50\n",
      "1315/1315 [==============================] - 0s 44us/step - loss: 0.2173 - acc: 0.9627\n",
      "Epoch 14/50\n",
      "1315/1315 [==============================] - 0s 43us/step - loss: 0.1818 - acc: 0.9658\n",
      "Epoch 15/50\n",
      "1315/1315 [==============================] - 0s 41us/step - loss: 0.1515 - acc: 0.9734\n",
      "Epoch 16/50\n",
      "1315/1315 [==============================] - 0s 43us/step - loss: 0.1262 - acc: 0.9757\n",
      "Epoch 17/50\n",
      "1315/1315 [==============================] - 0s 44us/step - loss: 0.1051 - acc: 0.9817\n",
      "Epoch 18/50\n",
      "1315/1315 [==============================] - 0s 41us/step - loss: 0.0904 - acc: 0.9810\n",
      "Epoch 19/50\n",
      "1315/1315 [==============================] - 0s 42us/step - loss: 0.0765 - acc: 0.9848\n",
      "Epoch 20/50\n",
      "1315/1315 [==============================] - 0s 44us/step - loss: 0.0665 - acc: 0.9848\n",
      "Epoch 21/50\n",
      "1315/1315 [==============================] - 0s 44us/step - loss: 0.0587 - acc: 0.9848\n",
      "Epoch 22/50\n",
      "1315/1315 [==============================] - 0s 40us/step - loss: 0.0515 - acc: 0.9856\n",
      "Epoch 23/50\n",
      "1315/1315 [==============================] - 0s 39us/step - loss: 0.0463 - acc: 0.9856\n",
      "Epoch 24/50\n",
      "1315/1315 [==============================] - 0s 43us/step - loss: 0.0409 - acc: 0.9863\n",
      "Epoch 25/50\n",
      "1315/1315 [==============================] - 0s 41us/step - loss: 0.0372 - acc: 0.9886\n",
      "Epoch 26/50\n",
      "1315/1315 [==============================] - 0s 41us/step - loss: 0.0348 - acc: 0.9886\n",
      "Epoch 27/50\n",
      "1315/1315 [==============================] - 0s 49us/step - loss: 0.0309 - acc: 0.9901\n",
      "Epoch 28/50\n",
      "1315/1315 [==============================] - 0s 47us/step - loss: 0.0296 - acc: 0.9909\n",
      "Epoch 29/50\n",
      "1315/1315 [==============================] - 0s 44us/step - loss: 0.0269 - acc: 0.9901\n",
      "Epoch 30/50\n",
      "1315/1315 [==============================] - 0s 44us/step - loss: 0.0261 - acc: 0.9901\n",
      "Epoch 31/50\n",
      "1315/1315 [==============================] - 0s 41us/step - loss: 0.0241 - acc: 0.9901\n",
      "Epoch 32/50\n",
      "1315/1315 [==============================] - 0s 45us/step - loss: 0.0234 - acc: 0.9894\n",
      "Epoch 33/50\n",
      "1315/1315 [==============================] - 0s 42us/step - loss: 0.0217 - acc: 0.9916\n",
      "Epoch 34/50\n",
      "1315/1315 [==============================] - 0s 45us/step - loss: 0.0214 - acc: 0.9909\n",
      "Epoch 35/50\n",
      "1315/1315 [==============================] - 0s 42us/step - loss: 0.0190 - acc: 0.9916\n",
      "Epoch 36/50\n",
      "1315/1315 [==============================] - 0s 44us/step - loss: 0.0198 - acc: 0.9924\n",
      "Epoch 37/50\n",
      "1315/1315 [==============================] - 0s 44us/step - loss: 0.0187 - acc: 0.9924\n",
      "Epoch 38/50\n",
      "1315/1315 [==============================] - 0s 43us/step - loss: 0.0181 - acc: 0.9924\n",
      "Epoch 39/50\n",
      "1315/1315 [==============================] - 0s 46us/step - loss: 0.0173 - acc: 0.9909\n",
      "Epoch 40/50\n",
      "1315/1315 [==============================] - 0s 43us/step - loss: 0.0162 - acc: 0.9932\n",
      "Epoch 41/50\n",
      "1315/1315 [==============================] - 0s 44us/step - loss: 0.0157 - acc: 0.9932\n",
      "Epoch 42/50\n",
      "1315/1315 [==============================] - 0s 45us/step - loss: 0.0156 - acc: 0.9916\n",
      "Epoch 43/50\n",
      "1315/1315 [==============================] - 0s 45us/step - loss: 0.0150 - acc: 0.9916\n",
      "Epoch 44/50\n",
      "1315/1315 [==============================] - 0s 45us/step - loss: 0.0147 - acc: 0.9932\n",
      "Epoch 45/50\n",
      "1315/1315 [==============================] - 0s 48us/step - loss: 0.0139 - acc: 0.9939\n",
      "Epoch 46/50\n",
      "1315/1315 [==============================] - 0s 49us/step - loss: 0.0139 - acc: 0.9924\n",
      "Epoch 47/50\n",
      "1315/1315 [==============================] - 0s 44us/step - loss: 0.0136 - acc: 0.9916\n",
      "Epoch 48/50\n",
      "1315/1315 [==============================] - 0s 44us/step - loss: 0.0127 - acc: 0.9939\n",
      "Epoch 49/50\n",
      "1315/1315 [==============================] - 0s 47us/step - loss: 0.0127 - acc: 0.9932\n",
      "Epoch 50/50\n",
      "1315/1315 [==============================] - 0s 45us/step - loss: 0.0124 - acc: 0.9939\n",
      "Training Accuracy: 99.619772\n",
      "Testing Accuracy: 67.173252\n",
      "******************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(all_data_df_2type_pos[['text']], all_data_df_2type_pos[['label']], test_size=0.2, random_state=42)\n",
    "X_train_n, X_test_n, y_train_n, y_test_n = train_test_split(all_data_df_2type_neg[['text']], all_data_df_2type_neg[['label']], test_size=0.2, random_state=42)\n",
    "X_train_nu, X_test_nu, y_train_nu, y_test_nu = train_test_split(all_data_df_2type_neutral[['text']], all_data_df_2type_neutral[['label']], test_size=0.2, random_state=42)\n",
    "#display(X_train_p, X_test_p, y_train_p, y_test_p)\n",
    "#display(X_train_n, X_test_n, y_train_n, y_test_n)\n",
    "X_train=X_train_p.append(X_train_n).append(X_train_nu).copy().reset_index(drop=True)\n",
    "X_test=X_test_p.append(X_test_n).append(X_test_nu).copy().reset_index(drop=True)\n",
    "y_train=y_train_p.append(y_train_n).append(y_train_nu).copy().reset_index(drop=True)\n",
    "y_test=y_test_p.append(y_test_n).append(y_test_nu).copy().reset_index(drop=True)\n",
    "\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "y_train_code=to_categorical(y_train['label'])\n",
    "y_test_code=to_categorical(y_test['label']) \n",
    "\n",
    "docs = all_data_df['text'].tolist()\n",
    "max_words = 10000 \n",
    "t = Tokenizer(num_words=max_words)\n",
    "t.fit_on_texts(docs)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "for vector_len in [12]:\n",
    "    for m_len in [100]:\n",
    "        print(\"max length: \"+str(m_len)+\"   |   vector length: \"+str(vector_len))\n",
    "        x_train_doc=create_padded_docs(t,X_train['text'].tolist(),m_len)\n",
    "        x_test_doc=create_padded_docs(t,X_test['text'].tolist(),m_len)\n",
    "        y_train_label=y_train_code\n",
    "        y_test_label=y_test_code\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(vocab_size, vector_len, input_length=m_len))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(3, activation='softmax'))\n",
    "        # compile the model\n",
    "        model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "        # summarize the model\n",
    "        print(model.summary())\n",
    "        # fit the model\n",
    "        model.fit(x_train_doc, y_train_label, epochs=50)#,validation_split=0.1)\n",
    "        # evaluate the model\n",
    "        loss, accuracy = model.evaluate(x_train_doc, y_train_label, verbose=0)\n",
    "        print('Training Accuracy: %f' % (accuracy*100))\n",
    "        y_train_label_predicted=model.predict(x_train_doc)\n",
    "        y_test_label_predicted=model.predict(x_test_doc)\n",
    "        loss, accuracy = model.evaluate(x_test_doc, y_test_label, verbose=0)\n",
    "        print('Testing Accuracy: %f' % (accuracy*100))\n",
    "        print('***'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.688</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.535</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.911</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>0.476</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     negative  neutral  positive  predicted_label\n",
       "74      0.688    0.282     0.030                0\n",
       "83      0.535    0.098     0.368                0\n",
       "..        ...      ...       ...              ...\n",
       "197     0.911    0.004     0.086                0\n",
       "262     0.476    0.473     0.051                0\n",
       "\n",
       "[9 rows x 4 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_label(x):\n",
    "    if x['positive']>x['negative']:\n",
    "        if x['positive']>=x['neutral']:\n",
    "            return 2\n",
    "        else:\n",
    "            return 1\n",
    "    else:\n",
    "        if x['negative']>=x['neutral']:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "y_train_label_predicted_df=pd.DataFrame(y_train_label_predicted)\n",
    "y_train_label_predicted_df.columns=['negative','neutral','positive']        \n",
    "y_train_label_predicted_df['predicted_label']=y_train_label_predicted_df.apply(lambda x: find_label(x),axis=1)\n",
    "y_train_label_predicted_df[y_train_label_predicted_df['predicted_label']==0]\n",
    "\n",
    "y_test_label_predicted_df=pd.DataFrame(y_test_label_predicted)\n",
    "y_test_label_predicted_df.columns=['negative','neutral','positive']        \n",
    "y_test_label_predicted_df['predicted_label']=y_test_label_predicted_df.apply(lambda x: find_label(x),axis=1)\n",
    "y_test_label_predicted_df[y_test_label_predicted_df['predicted_label']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328.8"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1644*0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_neg</th>\n",
       "      <th>predicted_neutral</th>\n",
       "      <th>predicted_pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_neg</th>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_neutral</th>\n",
       "      <td>1</td>\n",
       "      <td>665</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_pos</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              predicted_neg  predicted_neutral  predicted_pos\n",
       "                                                             \n",
       "true_neg                123                  0              1\n",
       "true_neutral              1                665              2\n",
       "true_pos                  0                  1            522"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_neg</th>\n",
       "      <th>predicted_neutral</th>\n",
       "      <th>predicted_pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_neg</th>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_neutral</th>\n",
       "      <td>2</td>\n",
       "      <td>133</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_pos</th>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              predicted_neg  predicted_neutral  predicted_pos\n",
       "                                                             \n",
       "true_neg                  3                 14             14\n",
       "true_neutral              2                133             32\n",
       "true_pos                  4                 42             85"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_columns=['predicted_neg','predicted_neutral','predicted_pos']\n",
    "confusion_rows=['true_neg','true_neutral','true_pos']\n",
    "train_confusion_matrix=pd.DataFrame(confusion_matrix(y_train['label'].tolist(), y_train_label_predicted_df['predicted_label']))\n",
    "train_confusion_matrix.columns=confusion_columns\n",
    "train_confusion_matrix['index']=confusion_rows\n",
    "train_confusion_matrix=train_confusion_matrix.set_index('index')\n",
    "train_confusion_matrix.index.name=''\n",
    "\n",
    "test_confusion_matrix=pd.DataFrame(confusion_matrix(y_test['label'].tolist(), y_test_label_predicted_df['predicted_label']))\n",
    "test_confusion_matrix.columns=confusion_columns\n",
    "test_confusion_matrix['index']=confusion_rows\n",
    "test_confusion_matrix=test_confusion_matrix.set_index('index')\n",
    "test_confusion_matrix.index.name=''\n",
    "\n",
    "display(train_confusion_matrix)\n",
    "display(test_confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "imdb_dir = 'aclImdb'\n",
    "def load_imdb_dir(imdb_dir,sub_folder):\n",
    "    train_dir = os.path.join(imdb_dir,sub_folder)\n",
    "    labels = []\n",
    "    texts = []\n",
    "    for label_type in ['neg', 'pos']:\n",
    "        dir_name = os.path.join(train_dir, label_type)\n",
    "        for fname in os.listdir(dir_name):\n",
    "            if fname[-4:] == '.txt':\n",
    "                f = open(os.path.join(dir_name, fname))\n",
    "                texts.append(f.read())\n",
    "                f.close()\n",
    "                if label_type == 'neg':\n",
    "                    labels.append(0)\n",
    "                else:\n",
    "                    labels.append(1)\n",
    "    return texts,labels\n",
    "x_train_imdb_raw,y_train_imdb_raw=load_imdb_dir(imdb_dir,\"train\")\n",
    "x_test_imdb_raw,y_test_imdb_raw=load_imdb_dir(imdb_dir,\"test\")\n",
    "\n",
    "\n",
    "x_train_imdb_raw_tot=x_train_imdb_raw+x_test_imdb_raw\n",
    "y_train_imdb_raw_tot=y_train_imdb_raw+y_test_imdb_raw\n",
    "\n",
    "max_words = 10000 \n",
    "docs = all_data_df_2type['text'].tolist()+x_train_imdb_raw_tot\n",
    "t = Tokenizer(num_words=max_words)\n",
    "t.fit_on_texts(docs)\n",
    "vocab_size = len(t.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 100   |   vector length: 12\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 100, 12)           1491816   \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1200)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 1201      \n",
      "=================================================================\n",
      "Total params: 1,493,017\n",
      "Trainable params: 1,493,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-654e1fa1aaf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_doc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;31m# evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_doc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2669\u001b[0m                                 \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2670\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2671\u001b[0;31m                                 session)\n\u001b[0m\u001b[1;32m   2672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_make_callable\u001b[0;34m(self, feed_arrays, feed_symbols, symbol_vals, session)\u001b[0m\n\u001b[1;32m   2621\u001b[0m             \u001b[0mcallable_opts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2622\u001b[0m         \u001b[0;31m# Create callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2623\u001b[0;31m         \u001b[0mcallable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable_from_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallable_opts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2624\u001b[0m         \u001b[0;31m# Cache parameters corresponding to the generated callable, so that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2625\u001b[0m         \u001b[0;31m# we can detect future mismatches and refresh the callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_make_callable_from_options\u001b[0;34m(self, callable_options)\u001b[0m\n\u001b[1;32m   1469\u001b[0m     \"\"\"\n\u001b[1;32m   1470\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1471\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mBaseSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallable_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session, callable_options)\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m           self._handle = tf_session.TF_SessionMakeCallable(\n\u001b[0;32m-> 1425\u001b[0;31m               session._session, options_ptr, status)\n\u001b[0m\u001b[1;32m   1426\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m         \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_DeleteBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for vector_len in [12]:\n",
    "    for m_len in [100]:\n",
    "        print(\"max length: \"+str(m_len)+\"   |   vector length: \"+str(vector_len))\n",
    "        x_train_doc=create_padded_docs(t,x_train_imdb_raw_tot,m_len)\n",
    "        x_test_doc=create_padded_docs(t,all_data_df_2type['text'].tolist(),m_len)\n",
    "        y_train_label=y_train_imdb_raw_tot\n",
    "        y_test_label=all_data_df_2type['label'].tolist()\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(vocab_size, vector_len, input_length=m_len))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        # compile the model\n",
    "        model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "        # summarize the model\n",
    "        print(model.summary())\n",
    "        # fit the model\n",
    "        model.fit(x_train_doc, y_train_label, epochs=5,validation_split=0.1)\n",
    "        # evaluate the model\n",
    "        loss, accuracy = model.evaluate(x_train_doc, y_train_label, verbose=0)\n",
    "        print('Training Accuracy: %f' % (accuracy*100))\n",
    "        y_train_label_predicted=model.predict(x_train_doc)\n",
    "        y_test_label_predicted=model.predict(x_test_doc)\n",
    "        y_train_label_predicted=[1 if y>=0.5 else 0 for y in y_train_label_predicted]\n",
    "        y_test_label_predicted=[1 if y>=0.5 else 0 for y in y_test_label_predicted]\n",
    "        loss, accuracy = model.evaluate(x_test_doc, y_test_label, verbose=0)\n",
    "        print('Testing Accuracy: %f' % (accuracy*100))\n",
    "        print('***'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_df_2type['y_predicted']=y_test_label_predicted\n",
    "all_data_df_2type['label_predicted']=all_data_df_2type['y_predicted'].apply(lambda x: 'positive' if x==1 else \"negative\")\n",
    "all_data_df_2type_neu['label_predicted']='neutral'\n",
    "all_data_df_2type=all_data_df_2type.drop('y_predicted',axis=1)\n",
    "ge_df=all_data_df_2type.append(all_data_df_2type_neu)\n",
    "ge_df.to_json('GE_predicted.json',orient='split')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output='''{\"text\":{'''\n",
    "senti='''},\"sentiment\":{'''\n",
    "for index, row in ge_df.iterrows():\n",
    "    output+='''\"'''+str(index)+'''\":\"'''+row['text']+'''\",'''\n",
    "    senti+='''\"'''+str(index)+'''\":\"'''+row['label_predicted']+'''\",'''\n",
    "output=output[:-1]\n",
    "senti=senti[:-1]+'}}'\n",
    "out_senti=output+senti\n",
    "out_senti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = open(\"GE_predicted.json\", \"w\")\n",
    "text_file.write(out_senti)\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_columns=['predicted_neg','predicted_pos']\n",
    "confusion_rows=['true_neg','true_pos']\n",
    "train_confusion_matrix=pd.DataFrame(confusion_matrix(y_train_label, y_train_label_predicted))\n",
    "train_confusion_matrix.columns=confusion_columns\n",
    "train_confusion_matrix['index']=confusion_rows\n",
    "train_confusion_matrix=train_confusion_matrix.set_index('index')\n",
    "train_confusion_matrix.index.name=''\n",
    "\n",
    "test_confusion_matrix=pd.DataFrame(confusion_matrix(y_test_label, y_test_label_predicted))\n",
    "test_confusion_matrix.columns=confusion_columns\n",
    "test_confusion_matrix['index']=confusion_rows\n",
    "test_confusion_matrix=test_confusion_matrix.set_index('index')\n",
    "test_confusion_matrix.index.name=''\n",
    "\n",
    "display(train_confusion_matrix)\n",
    "display(test_confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: watson-developer-cloud>=2.5.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.3 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from watson-developer-cloud>=2.5.1) (2.7.3)\n",
      "Requirement already satisfied, skipping upgrade: websocket-client==0.48.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from watson-developer-cloud>=2.5.1) (0.48.0)\n",
      "Requirement already satisfied, skipping upgrade: requests<3.0,>=2.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from watson-developer-cloud>=2.5.1) (2.21.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from python-dateutil>=2.5.3->watson-developer-cloud>=2.5.1) (1.11.0)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests<3.0,>=2.0->watson-developer-cloud>=2.5.1) (2.6)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests<3.0,>=2.0->watson-developer-cloud>=2.5.1) (1.22)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests<3.0,>=2.0->watson-developer-cloud>=2.5.1) (2018.11.29)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests<3.0,>=2.0->watson-developer-cloud>=2.5.1) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade \"watson-developer-cloud>=2.5.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw = all_data_df['text'].tolist()\n",
    "y_raw = all_data_df['sentiment'].tolist()\n",
    "#y = keras.utils.to_categorical(y_raw, 3)\n",
    "X = str(' '.join(X_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "641170\n",
      "1644\n"
     ]
    }
   ],
   "source": [
    "print(len(X))\n",
    "print(len(X_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "ename": "WatsonApiException",
     "evalue": "Error: Unauthorized: Access is denied due to invalid credentials , Code: 401",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWatsonApiException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-247-cc261979191d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     response = natural_language_understanding.analyze(\n\u001b[1;32m     15\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         features=Features(sentiment=SentimentOptions(document = True))).get_result()\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/watson_developer_cloud/natural_language_understanding_v1.py\u001b[0m in \u001b[0;36manalyze\u001b[0;34m(self, features, text, html, url, clean, xpath, fallback_to_raw, return_analyzed_text, language, limit_text_characters, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             accept_json=True)\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/watson_developer_cloud/watson_service.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, accept_json, headers, params, json, data, files, **kwargs)\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0merror_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_error_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m             raise WatsonApiException(response.status_code, error_message,\n\u001b[0;32m--> 587\u001b[0;31m                                      info=error_info, httpResponse=response)\n\u001b[0m",
      "\u001b[0;31mWatsonApiException\u001b[0m: Error: Unauthorized: Access is denied due to invalid credentials , Code: 401"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import keras\n",
    "from watson_developer_cloud import NaturalLanguageUnderstandingV1\n",
    "from watson_developer_cloud.natural_language_understanding_v1 import Features, SentimentOptions\n",
    "\n",
    "\n",
    "natural_language_understanding = NaturalLanguageUnderstandingV1(\n",
    "    version='2018-11-16',\n",
    "    iam_apikey='JB9Bepy8qpZLVwVYSKobgClglbAcsHvkZRSzOHvm1CnM',\n",
    "    url='https://gateway-wdc.watsonplatform.net/natural-language-understanding/api')\n",
    "preds = []\n",
    "count = 0\n",
    "for x in X_raw:\n",
    "    response = natural_language_understanding.analyze(\n",
    "        text = str(x),\n",
    "        features=Features(sentiment=SentimentOptions(document = True))).get_result()\n",
    "    preds.append(list([count,list(response['sentiment'].values())]))\n",
    "    \n",
    "    count = count + 1;\n",
    "    print(count)\n",
    "    if count > 126:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from watson_developer_cloud import NaturalLanguageUnderstandingV1\n",
    "from watson_developer_cloud.natural_language_understanding_v1 \\\n",
    "    import Features, EntitiesOptions, KeywordsOptions\n",
    "\n",
    "naturalLanguageUnderstanding = NaturalLanguageUnderstandingV1(\n",
    "    version='2018-11-16',\n",
    "    username='wenjun song',\n",
    "    password='Ilove22*',\n",
    "    #iam_apikey='OAbro0YFtCjxCW5Z8EiHjBcKGHtm2qpl30rvUw9yDZJ1',\n",
    "    url='https://gateway-tok.watsonplatform.net/natural-language-understanding/api')\n",
    "\n",
    "response = naturalLanguageUnderstanding.analyze(\n",
    "    text=all_data_df_2type['text'].tolist()[0],\n",
    "    features=Features(\n",
    "        entities=EntitiesOptions(emotion=True, sentiment=True, limit=2),\n",
    "        keywords=KeywordsOptions(emotion=True, sentiment=True,\n",
    "                                 limit=2))).get_result()\n",
    "\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: google-api-python-client in /Users/lovelife/anaconda3/lib/python3.6/site-packages (1.7.8)\n",
      "Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-python-client) (0.12.1)\n",
      "Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-python-client) (3.0.0)\n",
      "Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-python-client) (1.11.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-python-client) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-python-client) (0.0.3)\n",
      "Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth>=1.4.1->google-api-python-client) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.4)\n",
      "Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth>=1.4.1->google-api-python-client) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.5)\n",
      "Searching for google-api-python-client\n",
      "Reading https://pypi.org/simple/google-api-python-client/\n",
      "Downloading https://files.pythonhosted.org/packages/55/e9/e8fb2e3a031cb69b9524b80a92b126665d9a17421700a219555e3233ab6a/google_api_python_client-1.7.8-py3-none-any.whl#sha256=937eabdc3940977f712fa648a096a5142766b6d0a0f58bc603e2ac0687397ef0\n",
      "Best match: google-api-python-client 1.7.8\n",
      "Processing google_api_python_client-1.7.8-py3-none-any.whl\n",
      "removing '/Users/lovelife/anaconda3/lib/python3.6/site-packages/google_api_python_client-1.7.8-py3.6.egg' (and everything under it)\n",
      "Installing google_api_python_client-1.7.8-py3-none-any.whl to /Users/lovelife/anaconda3/lib/python3.6/site-packages\n",
      "writing requirements to /Users/lovelife/anaconda3/lib/python3.6/site-packages/google_api_python_client-1.7.8-py3.6.egg/EGG-INFO/requires.txt\n",
      "google-api-python-client 1.7.8 is already the active version in easy-install.pth\n",
      "\n",
      "Installed /Users/lovelife/anaconda3/lib/python3.6/site-packages/google_api_python_client-1.7.8-py3.6.egg\n",
      "Processing dependencies for google-api-python-client\n",
      "Finished processing dependencies for google-api-python-client\n",
      "Requirement already satisfied: google-cloud-storage in /Users/lovelife/anaconda3/lib/python3.6/site-packages (1.14.0)\n",
      "Requirement already satisfied: google-resumable-media>=0.3.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-cloud-storage) (0.3.2)\n",
      "Requirement already satisfied: google-api-core<2.0.0dev,>=1.6.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-cloud-storage) (1.8.1)\n",
      "Requirement already satisfied: google-cloud-core<0.30dev,>=0.29.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-cloud-storage) (0.29.1)\n",
      "Requirement already satisfied: six in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-resumable-media>=0.3.1->google-cloud-storage) (1.11.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage) (2.21.0)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage) (3.6.1)\n",
      "Requirement already satisfied: googleapis-common-protos!=1.5.4,<2.0dev,>=1.5.3 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage) (1.5.8)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=0.4.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage) (1.6.3)\n",
      "Requirement already satisfied: setuptools>=34.0.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage) (39.1.0)\n",
      "Requirement already satisfied: pytz in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage) (2018.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage) (1.22)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage) (2.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage) (2018.11.29)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage) (3.0.4)\n",
      "Requirement already satisfied: cachetools>=2.0.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage) (3.1.0)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage) (0.2.4)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from rsa>=3.1.4->google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage) (0.4.5)\n",
      "Requirement already satisfied: google-cloud-language in /Users/lovelife/anaconda3/lib/python3.6/site-packages (1.1.1)\n",
      "Requirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.6.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-cloud-language) (1.8.1)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (3.6.1)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (2.21.0)\n",
      "Requirement already satisfied: setuptools>=34.0.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (39.1.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (1.11.0)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=0.4.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (1.6.3)\n",
      "Requirement already satisfied: pytz in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (2018.4)\n",
      "Requirement already satisfied: googleapis-common-protos!=1.5.4,<2.0dev,>=1.5.3 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (1.5.8)\n",
      "Requirement already satisfied: grpcio>=1.8.2; extra == \"grpc\" in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (1.16.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (3.0.4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (2018.11.29)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (2.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (0.2.4)\n",
      "Requirement already satisfied: cachetools>=2.0.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (3.1.0)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (4.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (0.4.5)\n",
      "Requirement already up-to-date: google-cloud-language in /Users/lovelife/anaconda3/lib/python3.6/site-packages (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: google-api-core[grpc]<2.0.0dev,>=1.6.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-cloud-language) (1.8.1)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2.0dev,>=0.4.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.4.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (3.6.1)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=34.0.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (39.1.0)\n",
      "Requirement already satisfied, skipping upgrade: googleapis-common-protos!=1.5.4,<2.0dev,>=1.5.3 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (1.5.8)\n",
      "Requirement already satisfied, skipping upgrade: requests<3.0.0dev,>=2.18.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (2.21.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (1.11.0)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (2018.4)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.2; extra == \"grpc\" in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (1.16.1)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (0.2.4)\n",
      "Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (2018.11.29)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (2.6)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (1.22)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-language) (0.4.5)\n",
      "Requirement already satisfied: google-auth-oauthlib in /Users/lovelife/anaconda3/lib/python3.6/site-packages (0.2.0)\n",
      "Requirement already satisfied: google-auth in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth-oauthlib) (1.6.3)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth-oauthlib) (1.2.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth->google-auth-oauthlib) (1.11.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth->google-auth-oauthlib) (0.2.4)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth->google-auth-oauthlib) (4.0)\n",
      "Requirement already satisfied: cachetools>=2.0.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from google-auth->google-auth-oauthlib) (3.1.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.0.1)\n",
      "Requirement already satisfied: requests>=2.0.0 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (2.21.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth->google-auth-oauthlib) (0.4.5)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (2.6)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (2018.11.29)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/lovelife/anaconda3/lib/python3.6/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade google-api-python-client\n",
    "!easy_install --upgrade google-api-python-client\n",
    "! pip install google-cloud-storage\n",
    "! pip install google-cloud-language\n",
    "! pip install --upgrade google-cloud-language\n",
    "import argparse\n",
    "import google.cloud\n",
    "from google.cloud import language\n",
    "from google.cloud import storage\n",
    "from google.cloud.language import enums\n",
    "from google.cloud.language import types\n",
    "import os\n",
    "from google.oauth2 import service_account\n",
    "!pip install google-auth-oauthlib\n",
    "from google_auth_oauthlib.flow import Flow\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "document_sentiment {\n",
       "  magnitude: 0.30000001192092896\n",
       "}\n",
       "language: \"en\"\n",
       "sentences {\n",
       "  text {\n",
       "    content: \"Can I ask just sort of quick one?\"\n",
       "    begin_offset: -1\n",
       "  }\n",
       "  sentiment {\n",
       "    magnitude: 0.20000000298023224\n",
       "    score: 0.20000000298023224\n",
       "  }\n",
       "}\n",
       "sentences {\n",
       "  text {\n",
       "    content: \"Just for Greg.\"\n",
       "    begin_offset: -1\n",
       "  }\n",
       "  sentiment {\n",
       "  }\n",
       "}\n",
       "sentences {\n",
       "  text {\n",
       "    content: \"Greg, when we think about the 727 engine versus the MAX, just for modeling purposes it\\'s going to review 90% MAXs this year.\"\n",
       "    begin_offset: -1\n",
       "  }\n",
       "  sentiment {\n",
       "  }\n",
       "}\n",
       "sentences {\n",
       "  text {\n",
       "    content: \"How do we think about the margin profile of one variant versus the other?\"\n",
       "    begin_offset: -1\n",
       "  }\n",
       "  sentiment {\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cred_file_loc = r'dogwood-dryad-235122-9721a66a61c1.json'\n",
    "cred = service_account.Credentials.from_service_account_file(cred_file_loc)\n",
    "Client = language.LanguageServiceClient(credentials=cred)\n",
    "paragraphs = all_data_df['text'].tolist()\n",
    "results = []\n",
    "for paragraph in paragraphs:\n",
    "    document = types.Document(content=paragraph, type=enums.Document.Type.PLAIN_TEXT)\n",
    "    result = Client.analyze_sentiment(document=document)\n",
    "    results.append(result)\n",
    "\n",
    "results[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_neg</th>\n",
       "      <th>predicted_neutral</th>\n",
       "      <th>predicted_pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_neg</th>\n",
       "      <td>23</td>\n",
       "      <td>105</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_neutral</th>\n",
       "      <td>56</td>\n",
       "      <td>639</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_pos</th>\n",
       "      <td>25</td>\n",
       "      <td>329</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              predicted_neg  predicted_neutral  predicted_pos\n",
       "                                                             \n",
       "true_neg                 23                105             27\n",
       "true_neutral             56                639            140\n",
       "true_pos                 25                329            300"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def classify_google(x):\n",
    "    if x['score']<=-0.10:\n",
    "        return 'negative'\n",
    "    elif x['score']>-0.10 and (x['score']<0.25):\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'positive'\n",
    "\n",
    "magnitudes=[]\n",
    "scores=[]\n",
    "for i in range(len(results)):\n",
    "    magnitudes.append(results[i].document_sentiment.magnitude)\n",
    "    scores.append(results[i].document_sentiment.score)\n",
    "google_sentiment=pd.DataFrame({'magnitude':magnitudes,'score':scores})\n",
    "google_sentiment['label_goog']=google_sentiment.apply(classify_google,axis=1)\n",
    "google_merged=pd.concat([all_data_df,google_sentiment],axis=1)\n",
    "test_confusion_matrix=pd.DataFrame(confusion_matrix(google_merged['sentiment'].tolist(), google_merged['label_goog'].tolist()))\n",
    "test_confusion_matrix.columns=confusion_columns=['predicted_neg','predicted_neutral','predicted_pos']\n",
    "test_confusion_matrix['index']=['true_neg','true_neutral','true_pos']\n",
    "test_confusion_matrix=test_confusion_matrix.set_index('index')\n",
    "test_confusion_matrix.index.name=''\n",
    "\n",
    "display(test_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>magnitude</th>\n",
       "      <th>score</th>\n",
       "      <th>label_goog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Could you catch us up on your latest thinking ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>We continue to ramp up the activities for the ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>98</td>\n",
       "      <td>And so it's -- that one is a little bit toughe...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>99</td>\n",
       "      <td>Thanks, Simeon. Rob, next question please?</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1644 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                               text sentiment  \\\n",
       "0        1  Could you catch us up on your latest thinking ...   neutral   \n",
       "1       10  We continue to ramp up the activities for the ...   neutral   \n",
       "...    ...                                                ...       ...   \n",
       "1642    98  And so it's -- that one is a little bit toughe...  positive   \n",
       "1643    99         Thanks, Simeon. Rob, next question please?   neutral   \n",
       "\n",
       "      magnitude  score label_goog  \n",
       "0           0.9   -0.1   negative  \n",
       "1           2.4    0.4   positive  \n",
       "...         ...    ...        ...  \n",
       "1642        0.8    0.4   positive  \n",
       "1643        0.1    0.0    neutral  \n",
       "\n",
       "[1644 rows x 6 columns]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_merged.to_csv('google_API.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4811435523114355"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(20+466+305)/1644"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in all_data_df.iterrows():\n",
    "    text_file = open(\"Amazon/text_\"+str(index)+\".txt\", \"w\")\n",
    "    text_file.write(row['text'])\n",
    "    text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>mixed</th>\n",
       "      <th>label_amazon_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>0.008</td>\n",
       "      <td>2.155e-01</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.022</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.135</td>\n",
       "      <td>5.293e-04</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.002</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>0.340</td>\n",
       "      <td>3.178e-02</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.545</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1425</th>\n",
       "      <td>0.058</td>\n",
       "      <td>3.285e-02</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.007</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1644 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      positive   negative  neutral  mixed label_amazon_predicted\n",
       "985      0.008  2.155e-01    0.754  0.022                neutral\n",
       "437      0.135  5.293e-04    0.862  0.002                neutral\n",
       "...        ...        ...      ...    ...                    ...\n",
       "1638     0.340  3.178e-02    0.083  0.545               positive\n",
       "1425     0.058  3.285e-02    0.902  0.007                neutral\n",
       "\n",
       "[1644 rows x 5 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_predict=pd.read_csv('amazon_prediction.csv')\n",
    "amazon_predict['MyId']=amazon_predict['imagelocation'].apply(lambda x: int(x.split('_')[1].split('.')[0]))\n",
    "amazon_predict=amazon_predict.sort_values(['MyId'])\n",
    "amazon_predict=amazon_predict[['sentiment','positive','negative','neutral','mixed']]\n",
    "amazon_predict['label_amazon_predicted']=amazon_predict['sentiment'].apply(lambda x: x.lower())\n",
    "amazon_predict['label_amazon_predicted']=amazon_predict['label_amazon_predicted'].apply(lambda x: 'positive' if x=='mixed' else x)\n",
    "amazon_predict=amazon_predict.drop('sentiment',axis=1)\n",
    "amazon_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_neg</th>\n",
       "      <th>predicted_neutral</th>\n",
       "      <th>predicted_pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_neg</th>\n",
       "      <td>12</td>\n",
       "      <td>115</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_neutral</th>\n",
       "      <td>42</td>\n",
       "      <td>553</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_pos</th>\n",
       "      <td>41</td>\n",
       "      <td>524</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              predicted_neg  predicted_neutral  predicted_pos\n",
       "                                                             \n",
       "true_neg                 12                115             28\n",
       "true_neutral             42                553            240\n",
       "true_pos                 41                524             89"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "amzn_merged=pd.concat([all_data_df,amazon_predict],axis=1)\n",
    "test_confusion_matrix=pd.DataFrame(confusion_matrix(amzn_merged['sentiment'].tolist(), amzn_merged['label_amazon_predicted'].tolist()))\n",
    "test_confusion_matrix.columns=confusion_columns=['predicted_neg','predicted_neutral','predicted_pos']\n",
    "test_confusion_matrix['index']=['true_neg','true_neutral','true_pos']\n",
    "test_confusion_matrix=test_confusion_matrix.set_index('index')\n",
    "test_confusion_matrix.index.name=''\n",
    "\n",
    "display(test_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>magnitude</th>\n",
       "      <th>score</th>\n",
       "      <th>label_goog</th>\n",
       "      <th>weighted_score_goog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Could you catch us up on your latest thinking ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>We continue to ramp up the activities for the ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>98</td>\n",
       "      <td>And so it's -- that one is a little bit toughe...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>99</td>\n",
       "      <td>Thanks, Simeon. Rob, next question please?</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1644 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                               text sentiment  \\\n",
       "0        1  Could you catch us up on your latest thinking ...   neutral   \n",
       "1       10  We continue to ramp up the activities for the ...   neutral   \n",
       "...    ...                                                ...       ...   \n",
       "1642    98  And so it's -- that one is a little bit toughe...  positive   \n",
       "1643    99         Thanks, Simeon. Rob, next question please?   neutral   \n",
       "\n",
       "      magnitude  score label_goog  weighted_score_goog  \n",
       "0           0.9   -0.1   negative               -0.029  \n",
       "1           2.4    0.4   positive                0.314  \n",
       "...         ...    ...        ...                  ...  \n",
       "1642        0.8    0.4   positive                0.105  \n",
       "1643        0.1    0.0    neutral                0.000  \n",
       "\n",
       "[1644 rows x 7 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_merged_p4=google_merged.copy()\n",
    "google_merged_p4['weighted_score_goog']=google_merged_p4['magnitude']*google_merged_p4['score']#[['']]\n",
    "mag=google_merged_p4['weighted_score_goog'].max()-google_merged_p4['weighted_score_goog'].min()\n",
    "google_merged_p4['weighted_score_goog']=google_merged_p4['weighted_score_goog']/(0.5*mag)\n",
    "google_merged_p4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>mixed</th>\n",
       "      <th>label_amazon_predicted</th>\n",
       "      <th>weighted_score_amzn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>0.008</td>\n",
       "      <td>2.155e-01</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.022</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.135</td>\n",
       "      <td>5.293e-04</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.002</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>0.340</td>\n",
       "      <td>3.178e-02</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.545</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1425</th>\n",
       "      <td>0.058</td>\n",
       "      <td>3.285e-02</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.007</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1644 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      positive   negative  neutral  mixed label_amazon_predicted  \\\n",
       "985      0.008  2.155e-01    0.754  0.022                neutral   \n",
       "437      0.135  5.293e-04    0.862  0.002                neutral   \n",
       "...        ...        ...      ...    ...                    ...   \n",
       "1638     0.340  3.178e-02    0.083  0.545               positive   \n",
       "1425     0.058  3.285e-02    0.902  0.007                neutral   \n",
       "\n",
       "      weighted_score_amzn  \n",
       "985                  0.00  \n",
       "437                  0.00  \n",
       "...                   ...  \n",
       "1638                 0.17  \n",
       "1425                 0.00  \n",
       "\n",
       "[1644 rows x 6 columns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_predict_p4=amazon_predict.copy()\n",
    "#amazon_predict_p4.ix['combined_score','label_amazon_predicted']\n",
    "amazon_predict_p4.loc[amazon_predict_p4['label_amazon_predicted']=='positive', 'weighted_score_amzn'] =amazon_predict_p4.loc[amazon_predict_p4['label_amazon_predicted']=='positive', 'positive']\n",
    "amazon_predict_p4.loc[amazon_predict_p4['label_amazon_predicted']=='negative', 'weighted_score_amzn'] =-amazon_predict_p4.loc[amazon_predict_p4['label_amazon_predicted']=='negative', 'negative']\n",
    "amazon_predict_p4.loc[amazon_predict_p4['label_amazon_predicted'].isin(['neutral','mixed']), 'weighted_score_amzn'] =0\n",
    "mag=amazon_predict_p4['weighted_score_amzn'].max()-amazon_predict_p4['weighted_score_amzn'].min()\n",
    "amazon_predict_p4['weighted_score_amzn']=amazon_predict_p4['weighted_score_amzn']/(mag)\n",
    "amazon_predict_p4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_predict_p4.to_csv('amazon_API.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mircro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_neg</th>\n",
       "      <th>predicted_neutral</th>\n",
       "      <th>predicted_pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_neg</th>\n",
       "      <td>23</td>\n",
       "      <td>98</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_neutral</th>\n",
       "      <td>51</td>\n",
       "      <td>517</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_pos</th>\n",
       "      <td>51</td>\n",
       "      <td>358</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              predicted_neg  predicted_neutral  predicted_pos\n",
       "                                                             \n",
       "true_neg                 23                 98             34\n",
       "true_neutral             51                517            267\n",
       "true_pos                 51                358            245"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def classify_combined_score(x):\n",
    "    if x>=0.1:\n",
    "        return 'positive'\n",
    "    elif x>-0.01 and x<0.10:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'negative'\n",
    "all_merged=pd.concat([google_merged_p4[['text','sentiment','weighted_score_goog']],amazon_predict_p4[['weighted_score_amzn']]],axis=1)\n",
    "all_merged['combined_score']=all_merged[['weighted_score_goog','weighted_score_amzn']].mean(axis=1)\n",
    "all_merged['combined_sentiment']=all_merged['combined_score'].apply(classify_combined_score)\n",
    "all_merged.groupby(['combined_sentiment'])[['text']].count()\n",
    "test_confusion_matrix=pd.DataFrame(confusion_matrix(all_merged['sentiment'].tolist(), all_merged['combined_sentiment'].tolist()))\n",
    "test_confusion_matrix.columns=confusion_columns=['predicted_neg','predicted_neutral','predicted_pos']\n",
    "test_confusion_matrix['index']=['true_neg','true_neutral','true_pos']\n",
    "test_confusion_matrix=test_confusion_matrix.set_index('index')\n",
    "test_confusion_matrix.index.name=''\n",
    "\n",
    "display(test_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install auto-sklearn\n",
    "! pip install -U scikit-learn\n",
    "! pip install numpy\n",
    "! pip install -U numpy\n",
    "! pip install --upgrade pip"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
